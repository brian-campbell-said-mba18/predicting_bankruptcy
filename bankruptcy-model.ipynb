{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: The Efficacy of Multilayer Perceptron Algorithms in Predicting Bankruptcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"#introduction\">INTRODUCTION</a></li>\n",
    "<li><a href=\"#Benchmark Logistic Regression\">Benchmark Logistic Regression</a></li>\n",
    "<li><a href=\"#MLP Model\">MLP Model</a></li>\n",
    "<li><a href=\"#assess\">Data Assessment</a></li>\n",
    "<li><a href=\"#cleaning\">Data Cleaning</a></li>\n",
    "<li><a href=\"#target\">Separation of Target Variables</a></li>\n",
    "<li><a href=\"#no nulls\">No Nulls Data</a></li>\n",
    "<li><a href=\"#one-hot null\">Creation of One-hot Null Variable</a></li>\n",
    "<li><a href=\"#Creation of Sum Null Variables\">Creation of Sum Null Variables</a></li>\n",
    "<li><a href=\"#PIVOT\">PIVOT</a></li>\n",
    "<li><a href=\"#Data Reorganization\">Data Reorganization</a></li>\n",
    "<li><a href=\"#Data Exploration - Descriptive Statistics\">Data Exploration - Descriptive Statistics</a></li>\n",
    "<li><a href=\"#Exploratory Visualization\">Exploratory Visualization</a></li>\n",
    "<li><a href=\"#Preprocessing\">Preprocessing</a></li>\n",
    "<li><a href=\"#Benchmark: Logistic Regression\">Benchmark: Logistic Regression</a></li>\n",
    "<li><a href=\"#originalMLP\">Origial MLP</a></li>\n",
    "<li><a href=\"#conclusion\">Conclusion</a></li> \n",
    "<li><a href=\"#references\">References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Benchmark Logistic Regression'></a>\n",
    "## Benchmark Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary libraries for the logistic regression models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# This imports the AUC score for scoring the models.\n",
    "# This comes from Reference 27 in References.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# These are libraries that will be needed to organize data,\n",
    "# graph data, and change the working directory.\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the no_nulls X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nonulls = pd.read_csv('no-peaking/Xtrain_nonulls.csv')\n",
    "Xtrain_nonulls = np.array(Xtrain_nonulls)\n",
    "Xtest_nonulls = pd.read_csv('no-peaking/Xtest_nonulls.csv')\n",
    "Xtest_nonulls = np.array(Xtest_nonulls)\n",
    "\n",
    "# This loads the no_nulls Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nonulls = pd.read_csv('no-peaking/Ytrain_nonulls.csv')\n",
    "Ytrain_nonulls = np.array(Ytrain_nonulls)\n",
    "Ytrain_nonulls = Ytrain_nonulls.ravel() \n",
    "Ytest_nonulls = pd.read_csv('no-peaking/Ytest_nonulls.csv')\n",
    "Ytest_nonulls = np.array(Ytest_nonulls)\n",
    "Ytest_nonulls = Ytest_nonulls.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Hold-out Cross-Validation on just the training set\n",
    "K-fold Cross-Validation is a standard method for preventing a logistic regression model from overfitting. However, because the testing set, the fifth year of the dataset, is arbitrarily chosen (not random), K-fold Cross-Validation cannot be applied to the dataset (Reference 3). K-fold Cross-Validation would corrupt the testing set with data leakage considering that the dataset is a time-series set (Reference 3). To prevent data leakage, Hold-out cross-Validation will only be applied to the training set (References 3 & 4). Hold-out Cross-Validation takes a percentage of the training set as a validation set to test the accuracy of the model during the training stage. This method of cross validation, like all methods, is used to prevent the overfitting of a model and poor accuracy performance when applying the testing data to the fitted model (Reference 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Nulls Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import train_test_split from sklearn.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the No Nulls dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nonulls, Xval_nonulls, Ytrain_nonulls, Yval_nonulls = train_test_split(\n",
    "                    Xtrain_nonulls, Ytrain_nonulls, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8506022247116249"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the No Nulls Dataset.\n",
    "log_nonulls = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_nonulls model with the training data.\n",
    "log_nonulls.fit(Xtrain_nonulls,Ytrain_nonulls)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nonulls = log_nonulls.predict(Xval_nonulls)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nonulls = roc_auc_score(Yval_nonulls, yval_pred_nonulls)\n",
    "VAL_auc_nonulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.3163.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nonulls = log_nonulls.predict(Xtest_nonulls)\n",
    "TEST_auc_nonulls = roc_auc_score(Ytest_nonulls, ytest_pred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_nonulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Nulls only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This loads the Nulls only training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nullsonly = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_nullsonly = Xtrain_nullsonly.drop(\n",
    "    Xtrain_nullsonly.columns[64], axis=1)\n",
    "Xtrain_nullsonly = np.array(Xtrain_nullsonly)\n",
    "Xtest_nullsonly = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_nullsonly = Xtest_nullsonly.drop(\n",
    "    Xtest_nullsonly.columns[64], axis=1)\n",
    "Xtest_nullsonly = np.array(Xtest_nullsonly)\n",
    "\n",
    "# This loads the Nulls only Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nullsonly = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_nullsonly = np.array(Ytrain_nullsonly)\n",
    "Ytrain_nullsonly = Ytrain_nullsonly.ravel() \n",
    "Ytest_nullsonly = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_nullsonly = np.array(Ytest_nullsonly)\n",
    "Ytest_nullsonly = Ytest_nullsonly.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls Only Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Sum dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nullsonly, Xval_nullsonly, Ytrain_nullsonly, Yval_nullsonly = train_test_split(\n",
    "                    Xtrain_nullsonly, Ytrain_nullsonly, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350826303765834"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the Nulls Only Dataset.\n",
    "log_nullsonly = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_nullsonly.fit(Xtrain_nullsonly,Ytrain_nullsonly)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nullsonly = log_nullsonly.predict(Xval_nullsonly)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nullsonly = roc_auc_score(Yval_nullsonly, yval_pred_nullsonly)\n",
    "VAL_auc_nullsonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 68.29 %\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nullsonly = log_nullsonly.predict(Xtest_nullsonly)\n",
    "TEST_auc_nullsonly = roc_auc_score(Ytest_nullsonly, ytest_pred_nullsonly)\n",
    "TEST_auc_nullsonly = TEST_auc_nullsonly * 100\n",
    "print(\"The AUC score for the model is %.2f\" % TEST_auc_nullsonly, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the one hot X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_onehot = pd.read_csv('no-peaking/Xtrain_onehot.csv')\n",
    "Xtrain_onehot = np.array(Xtrain_onehot)\n",
    "Xtest_onehot = pd.read_csv('no-peaking/Xtest_onehot.csv')\n",
    "Xtest_onehot = np.array(Xtest_onehot)\n",
    "\n",
    "# This loads the one hot Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_onehot = pd.read_csv('no-peaking/Ytrain_onehot.csv')\n",
    "Ytrain_onehot = np.array(Ytrain_onehot)\n",
    "Ytrain_onehot = Ytrain_onehot.ravel() \n",
    "Ytest_onehot = pd.read_csv('no-peaking/Ytest_onehot.csv')\n",
    "Ytest_onehot = np.array(Ytest_onehot)\n",
    "Ytest_onehot = Ytest_onehot.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the One Hot dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_onehot, Xval_onehot, Ytrain_onehot, Yval_onehot = train_test_split(\n",
    "                    Xtrain_onehot, Ytrain_onehot, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8647068328667264"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the One Hot Dataset.\n",
    "log_onehot = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_onehot.fit(Xtrain_onehot,Ytrain_onehot)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_onehot = log_onehot.predict(Xval_onehot)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_onehot = roc_auc_score(Yval_onehot, yval_pred_onehot)\n",
    "VAL_auc_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6406.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_onehot = log_onehot.predict(Xtest_onehot)\n",
    "TEST_auc_onehot = roc_auc_score(Ytest_onehot, ytest_pred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the SUM X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_sum = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_sum = np.array(Xtrain_sum)\n",
    "Xtest_sum = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_sum = np.array(Xtest_sum)\n",
    "\n",
    "# This loads the no_nulls Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_sum = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_sum = np.array(Ytrain_sum)\n",
    "Ytrain_sum = Ytrain_sum.ravel() \n",
    "Ytest_sum = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_sum = np.array(Ytest_sum)\n",
    "Ytest_sum = Ytest_sum.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Sum dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_sum, Xval_sum, Ytrain_sum, Yval_sum = train_test_split(\n",
    "                    Xtrain_sum, Ytrain_sum, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7437902237728553"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the One Hot Dataset.\n",
    "log_sum = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_sum.fit(Xtrain_sum,Ytrain_sum)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.c\n",
    "yval_pred_sum = log_sum.predict(Xval_sum)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_sum = roc_auc_score(Yval_sum, yval_pred_sum)\n",
    "VAL_auc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6606.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_sum = log_sum.predict(Xtest_sum)\n",
    "TEST_auc_sum = roc_auc_score(Ytest_sum, ytest_pred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MLP Model'></a>\n",
    "## MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'saved_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-0e0cd0986d66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This creates a directory to save the best models for the MLP.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'saved_models'"
     ]
    }
   ],
   "source": [
    "# This creates a directory to save the best models for the MLP.\n",
    "os.mkdir('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary libraries for the MLP.\n",
    "\n",
    "# This imports the sequential model, the layers,\n",
    "# the SGD optimizer, the regularizers from keras.\n",
    "# This comes from Reference 5 in Referenes.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Nadam\n",
    "from keras import regularizers\n",
    "\n",
    "# This imports checkpointer, which records the best weights\n",
    "# for the algorithm.\n",
    "# This comes from Reference 6 in References.\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This sets the random seeds for reproducible results.\n",
    "# This comes from reference 10 of references.\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(drop_rate, l2_factor, first_dense, second_dense,\n",
    "                third_dense, hidden_act, out_act, x):\n",
    "    dim_int = int(np.size(x,1))\n",
    "    # This defines the model as a sequential model.\n",
    "    # This comes from References 1 in References.\n",
    "    model = Sequential()\n",
    "\n",
    "    # This is the input layer.\n",
    "    # This comes from References 1 & 3 in References.\n",
    "    model.add(Dense(first_dense, activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor),\n",
    "        input_dim = dim_int))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the first hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(second_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "    \n",
    "    # This creates the second hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(third_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the output layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(1, activation=out_act))\n",
    "    # This returns the model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_nonulls = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nonulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nonulls.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nonulls.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11018 samples, validate on 2755 samples\n",
      "Epoch 1/100\n",
      "11018/11018 [==============================] - 5s 427us/step - loss: 0.8007 - acc: 0.5077 - val_loss: 0.7505 - val_acc: 0.6650\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75053, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 2/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.7898 - acc: 0.5230 - val_loss: 0.7485 - val_acc: 0.6650\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75053 to 0.74853, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 3/100\n",
      "11018/11018 [==============================] - 1s 86us/step - loss: 0.7858 - acc: 0.5197 - val_loss: 0.7468 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74853 to 0.74682, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 4/100\n",
      "11018/11018 [==============================] - 1s 97us/step - loss: 0.7775 - acc: 0.5286 - val_loss: 0.7451 - val_acc: 0.6584\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.74682 to 0.74515, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 5/100\n",
      "11018/11018 [==============================] - 1s 86us/step - loss: 0.7787 - acc: 0.5276 - val_loss: 0.7436 - val_acc: 0.6613\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74515 to 0.74359, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 6/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.7739 - acc: 0.5320 - val_loss: 0.7423 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74359 to 0.74227, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 7/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.7770 - acc: 0.5380 - val_loss: 0.7411 - val_acc: 0.6711\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.74227 to 0.74113, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 8/100\n",
      "11018/11018 [==============================] - 1s 98us/step - loss: 0.7711 - acc: 0.5371 - val_loss: 0.7399 - val_acc: 0.6770\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.74113 to 0.73993, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 9/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.7656 - acc: 0.5413 - val_loss: 0.7386 - val_acc: 0.6799\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.73993 to 0.73860, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 10/100\n",
      "11018/11018 [==============================] - 1s 90us/step - loss: 0.7642 - acc: 0.5463 - val_loss: 0.7374 - val_acc: 0.6835\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.73860 to 0.73741, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 11/100\n",
      "11018/11018 [==============================] - 1s 93us/step - loss: 0.7584 - acc: 0.5487 - val_loss: 0.7362 - val_acc: 0.6875\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.73741 to 0.73621, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 12/100\n",
      "11018/11018 [==============================] - 1s 104us/step - loss: 0.7613 - acc: 0.5501 - val_loss: 0.7349 - val_acc: 0.6929\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.73621 to 0.73490, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 13/100\n",
      "11018/11018 [==============================] - 1s 95us/step - loss: 0.7579 - acc: 0.5503 - val_loss: 0.7338 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.73490 to 0.73380, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 14/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.7583 - acc: 0.5515 - val_loss: 0.7326 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.73380 to 0.73263, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 15/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.7575 - acc: 0.5512 - val_loss: 0.7316 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.73263 to 0.73162, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 16/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.7556 - acc: 0.5559 - val_loss: 0.7302 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.73162 to 0.73022, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 17/100\n",
      "11018/11018 [==============================] - 1s 100us/step - loss: 0.7502 - acc: 0.5626 - val_loss: 0.7290 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.73022 to 0.72901, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 18/100\n",
      "11018/11018 [==============================] - 1s 90us/step - loss: 0.7463 - acc: 0.5709 - val_loss: 0.7275 - val_acc: 0.7129\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.72901 to 0.72754, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 19/100\n",
      "11018/11018 [==============================] - 1s 97us/step - loss: 0.7442 - acc: 0.5735 - val_loss: 0.7259 - val_acc: 0.7147\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.72754 to 0.72594, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 20/100\n",
      "11018/11018 [==============================] - 1s 84us/step - loss: 0.7455 - acc: 0.5672 - val_loss: 0.7245 - val_acc: 0.7162\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.72594 to 0.72449, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 21/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7455 - acc: 0.5712 - val_loss: 0.7232 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72449 to 0.72318, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 22/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7430 - acc: 0.5742 - val_loss: 0.7218 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72318 to 0.72176, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 23/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7378 - acc: 0.5765 - val_loss: 0.7202 - val_acc: 0.7216\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.72176 to 0.72018, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 24/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7394 - acc: 0.5706 - val_loss: 0.7186 - val_acc: 0.7241\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.72018 to 0.71860, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 25/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7346 - acc: 0.5801 - val_loss: 0.7168 - val_acc: 0.7263\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.71860 to 0.71680, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 26/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7402 - acc: 0.5751 - val_loss: 0.7153 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.71680 to 0.71532, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 27/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7391 - acc: 0.5763 - val_loss: 0.7137 - val_acc: 0.7307\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.71532 to 0.71372, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 28/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7357 - acc: 0.5841 - val_loss: 0.7120 - val_acc: 0.7328\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.71372 to 0.71200, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 29/100\n",
      "11018/11018 [==============================] - 1s 84us/step - loss: 0.7333 - acc: 0.5848 - val_loss: 0.7102 - val_acc: 0.7354\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.71200 to 0.71018, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 30/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7318 - acc: 0.5920 - val_loss: 0.7083 - val_acc: 0.7361\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.71018 to 0.70833, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 31/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7330 - acc: 0.5870 - val_loss: 0.7065 - val_acc: 0.7372\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.70833 to 0.70647, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 32/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7340 - acc: 0.5848 - val_loss: 0.7050 - val_acc: 0.7387\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.70647 to 0.70500, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7302 - acc: 0.5926 - val_loss: 0.7031 - val_acc: 0.7416\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.70500 to 0.70313, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 34/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7316 - acc: 0.5870 - val_loss: 0.7012 - val_acc: 0.7441\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.70313 to 0.70124, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 35/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7206 - acc: 0.5869 - val_loss: 0.6993 - val_acc: 0.7445\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.70124 to 0.69934, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 36/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7343 - acc: 0.5843 - val_loss: 0.6982 - val_acc: 0.7448\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.69934 to 0.69818, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 37/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7255 - acc: 0.6002 - val_loss: 0.6965 - val_acc: 0.7463\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.69818 to 0.69647, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 38/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7225 - acc: 0.5969 - val_loss: 0.6946 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.69647 to 0.69457, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 39/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7176 - acc: 0.6066 - val_loss: 0.6924 - val_acc: 0.7495\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.69457 to 0.69236, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 40/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7212 - acc: 0.5999 - val_loss: 0.6908 - val_acc: 0.7492\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.69236 to 0.69076, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 41/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7169 - acc: 0.6067 - val_loss: 0.6886 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.69076 to 0.68861, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 42/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7158 - acc: 0.6141 - val_loss: 0.6867 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.68861 to 0.68671, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 43/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7147 - acc: 0.6086 - val_loss: 0.6844 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.68671 to 0.68441, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 44/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.7187 - acc: 0.6099 - val_loss: 0.6824 - val_acc: 0.7550\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.68441 to 0.68239, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 45/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7126 - acc: 0.6134 - val_loss: 0.6806 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.68239 to 0.68060, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 46/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7093 - acc: 0.6117 - val_loss: 0.6786 - val_acc: 0.7561\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.68060 to 0.67859, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 47/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7128 - acc: 0.6190 - val_loss: 0.6767 - val_acc: 0.7557\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.67859 to 0.67672, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 48/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7149 - acc: 0.6151 - val_loss: 0.6753 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.67672 to 0.67531, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 49/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7083 - acc: 0.6182 - val_loss: 0.6734 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.67531 to 0.67338, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 50/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7023 - acc: 0.6185 - val_loss: 0.6715 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.67338 to 0.67155, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 51/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7012 - acc: 0.6262 - val_loss: 0.6696 - val_acc: 0.7583\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.67155 to 0.66965, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 52/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.7052 - acc: 0.6265 - val_loss: 0.6679 - val_acc: 0.7575\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.66965 to 0.66791, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 53/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7063 - acc: 0.6195 - val_loss: 0.6662 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.66791 to 0.66618, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 54/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7013 - acc: 0.6283 - val_loss: 0.6643 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.66618 to 0.66434, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 55/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7019 - acc: 0.6210 - val_loss: 0.6626 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.66434 to 0.66256, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 56/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.7029 - acc: 0.6284 - val_loss: 0.6610 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.66256 to 0.66102, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 57/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6965 - acc: 0.6410 - val_loss: 0.6590 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.66102 to 0.65902, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 58/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7028 - acc: 0.6312 - val_loss: 0.6574 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.65902 to 0.65737, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 59/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.6988 - acc: 0.6329 - val_loss: 0.6557 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.65737 to 0.65575, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 60/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.6961 - acc: 0.6372 - val_loss: 0.6541 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.65575 to 0.65408, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 61/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.6944 - acc: 0.6398 - val_loss: 0.6523 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.65408 to 0.65227, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 62/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.6904 - acc: 0.6432 - val_loss: 0.6504 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.65227 to 0.65039, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 63/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.6905 - acc: 0.6427 - val_loss: 0.6486 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.65039 to 0.64863, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 64/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.6940 - acc: 0.6380 - val_loss: 0.6469 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.64863 to 0.64694, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6886 - acc: 0.6477 - val_loss: 0.6452 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.64694 to 0.64523, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 66/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6859 - acc: 0.6484 - val_loss: 0.6436 - val_acc: 0.7623\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.64523 to 0.64357, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 67/100\n",
      "11018/11018 [==============================] - 1s 84us/step - loss: 0.6884 - acc: 0.6449 - val_loss: 0.6419 - val_acc: 0.7623\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.64357 to 0.64195, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 68/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6789 - acc: 0.6562 - val_loss: 0.6399 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.64195 to 0.63990, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 69/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6824 - acc: 0.6540 - val_loss: 0.6383 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.63990 to 0.63825, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 70/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6813 - acc: 0.6510 - val_loss: 0.6367 - val_acc: 0.7619\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.63825 to 0.63668, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 71/100\n",
      "11018/11018 [==============================] - 1s 85us/step - loss: 0.6811 - acc: 0.6556 - val_loss: 0.6348 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.63668 to 0.63481, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 72/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6808 - acc: 0.6583 - val_loss: 0.6331 - val_acc: 0.7633\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.63481 to 0.63306, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 73/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6811 - acc: 0.6585 - val_loss: 0.6315 - val_acc: 0.7637\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.63306 to 0.63151, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 74/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6768 - acc: 0.6640 - val_loss: 0.6299 - val_acc: 0.7633\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.63151 to 0.62995, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 75/100\n",
      "11018/11018 [==============================] - 1s 100us/step - loss: 0.6791 - acc: 0.6615 - val_loss: 0.6287 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.62995 to 0.62873, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 76/100\n",
      "11018/11018 [==============================] - 1s 90us/step - loss: 0.6785 - acc: 0.6599 - val_loss: 0.6273 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.62873 to 0.62734, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 77/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6781 - acc: 0.6620 - val_loss: 0.6261 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.62734 to 0.62615, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 78/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6771 - acc: 0.6614 - val_loss: 0.6248 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.62615 to 0.62480, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 79/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6722 - acc: 0.6684 - val_loss: 0.6233 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.62480 to 0.62327, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 80/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6694 - acc: 0.6763 - val_loss: 0.6217 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.62327 to 0.62169, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 81/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6760 - acc: 0.6718 - val_loss: 0.6205 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.62169 to 0.62051, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 82/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6679 - acc: 0.6750 - val_loss: 0.6191 - val_acc: 0.7641\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.62051 to 0.61911, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 83/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6729 - acc: 0.6694 - val_loss: 0.6180 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.61911 to 0.61796, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 84/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6700 - acc: 0.6749 - val_loss: 0.6164 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.61796 to 0.61642, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 85/100\n",
      "11018/11018 [==============================] - 1s 105us/step - loss: 0.6713 - acc: 0.6701 - val_loss: 0.6153 - val_acc: 0.7659\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.61642 to 0.61532, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 86/100\n",
      "11018/11018 [==============================] - 1s 102us/step - loss: 0.6661 - acc: 0.6772 - val_loss: 0.6139 - val_acc: 0.7659\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.61532 to 0.61389, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 87/100\n",
      "11018/11018 [==============================] - 1s 116us/step - loss: 0.6695 - acc: 0.6712 - val_loss: 0.6128 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.61389 to 0.61277, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 88/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6643 - acc: 0.6765 - val_loss: 0.6115 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.61277 to 0.61152, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 89/100\n",
      "11018/11018 [==============================] - 1s 99us/step - loss: 0.6643 - acc: 0.6816 - val_loss: 0.6103 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.61152 to 0.61026, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 90/100\n",
      "11018/11018 [==============================] - 1s 106us/step - loss: 0.6630 - acc: 0.6773 - val_loss: 0.6091 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.61026 to 0.60907, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 91/100\n",
      "11018/11018 [==============================] - 1s 101us/step - loss: 0.6623 - acc: 0.6864 - val_loss: 0.6078 - val_acc: 0.7670\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.60907 to 0.60782, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 92/100\n",
      "11018/11018 [==============================] - 1s 95us/step - loss: 0.6654 - acc: 0.6809 - val_loss: 0.6066 - val_acc: 0.7670\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.60782 to 0.60658, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 93/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6542 - acc: 0.6889 - val_loss: 0.6050 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.60658 to 0.60504, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 94/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6641 - acc: 0.6893 - val_loss: 0.6039 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.60504 to 0.60395, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 95/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6569 - acc: 0.6895 - val_loss: 0.6027 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.60395 to 0.60274, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 96/100\n",
      "11018/11018 [==============================] - 1s 93us/step - loss: 0.6567 - acc: 0.6911 - val_loss: 0.6014 - val_acc: 0.7695\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.60274 to 0.60143, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6510 - acc: 0.6930 - val_loss: 0.6000 - val_acc: 0.7702\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.60143 to 0.60004, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 98/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6537 - acc: 0.6928 - val_loss: 0.5988 - val_acc: 0.7706\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.60004 to 0.59875, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 99/100\n",
      "11018/11018 [==============================] - 1s 91us/step - loss: 0.6528 - acc: 0.6977 - val_loss: 0.5976 - val_acc: 0.7710\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.59875 to 0.59755, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 100/100\n",
      "11018/11018 [==============================] - 1s 97us/step - loss: 0.6548 - acc: 0.6936 - val_loss: 0.5964 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.59755 to 0.59645, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efd11c5a90>"
      ]
     },
     "execution_count": 356,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nonulls.fit(Xtrain_nonulls, Ytrain_nonulls, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nonulls.load_weights('saved_models/weights.best.mlp_nonulls.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 85.5092%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nonulls.evaluate(Xtest_nonulls, Ytest_nonulls, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.5504.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nonulls = mlp_nonulls.predict(Xtest_nonulls)\n",
    "mlp_nonulls_ROC = roc_auc_score(Ytest_nonulls, Ypred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nonulls_ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Nulls Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_nullsonly = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nullsonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nullsonly.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nullsonly.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 8s 169us/step - loss: 0.7686 - acc: 0.5644 - val_loss: 0.7395 - val_acc: 0.6666\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73955, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 4s 91us/step - loss: 0.7558 - acc: 0.6195 - val_loss: 0.7317 - val_acc: 0.6829\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73955 to 0.73169, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.7489 - acc: 0.6370 - val_loss: 0.7235 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73169 to 0.72352, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.7402 - acc: 0.6434 - val_loss: 0.7162 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.72352 to 0.71625, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7370 - acc: 0.6483 - val_loss: 0.7091 - val_acc: 0.6911\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71625 to 0.70908, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.7340 - acc: 0.6486 - val_loss: 0.7041 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.70908 to 0.70407, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.7296 - acc: 0.6511 - val_loss: 0.6996 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.70407 to 0.69960, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.7250 - acc: 0.6523 - val_loss: 0.6951 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.69960 to 0.69510, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.7264 - acc: 0.6518 - val_loss: 0.6923 - val_acc: 0.6926\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.69510 to 0.69234, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7219 - acc: 0.6550 - val_loss: 0.6902 - val_acc: 0.6926\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.69234 to 0.69018, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.7191 - acc: 0.6552 - val_loss: 0.6884 - val_acc: 0.6931\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.69018 to 0.68838, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.7195 - acc: 0.6551 - val_loss: 0.6868 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.68838 to 0.68675, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7174 - acc: 0.6563 - val_loss: 0.6850 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68675 to 0.68502, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.7121 - acc: 0.6593 - val_loss: 0.6830 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68502 to 0.68299, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7127 - acc: 0.6596 - val_loss: 0.6817 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.68299 to 0.68174, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.7112 - acc: 0.6585 - val_loss: 0.6805 - val_acc: 0.6938\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.68174 to 0.68055, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7083 - acc: 0.6612 - val_loss: 0.6792 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.68055 to 0.67916, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.7086 - acc: 0.6603 - val_loss: 0.6784 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.67916 to 0.67836, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.7095 - acc: 0.6613 - val_loss: 0.6776 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.67836 to 0.67763, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7059 - acc: 0.6623 - val_loss: 0.6763 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.67763 to 0.67629, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 4s 91us/step - loss: 0.7055 - acc: 0.6617 - val_loss: 0.6755 - val_acc: 0.6943\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.67629 to 0.67548, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.7042 - acc: 0.6608 - val_loss: 0.6750 - val_acc: 0.6943\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.67548 to 0.67500, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.7007 - acc: 0.6648 - val_loss: 0.6739 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.67500 to 0.67388, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7011 - acc: 0.6641 - val_loss: 0.6731 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.67388 to 0.67309, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.7003 - acc: 0.6651 - val_loss: 0.6720 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.67309 to 0.67205, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6993 - acc: 0.6673 - val_loss: 0.6712 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67205 to 0.67124, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6988 - acc: 0.6671 - val_loss: 0.6699 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.67124 to 0.66992, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6972 - acc: 0.6659 - val_loss: 0.6691 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.66992 to 0.66908, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6953 - acc: 0.6679 - val_loss: 0.6678 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.66908 to 0.66783, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6955 - acc: 0.6656 - val_loss: 0.6672 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.66783 to 0.66716, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6950 - acc: 0.6673 - val_loss: 0.6663 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.66716 to 0.66634, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6944 - acc: 0.6682 - val_loss: 0.6655 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.66634 to 0.66549, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6945 - acc: 0.6681 - val_loss: 0.6650 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.66549 to 0.66497, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6923 - acc: 0.6694 - val_loss: 0.6640 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.66497 to 0.66402, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6918 - acc: 0.6710 - val_loss: 0.6631 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.66402 to 0.66309, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6903 - acc: 0.6707 - val_loss: 0.6623 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.66309 to 0.66228, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6917 - acc: 0.6701 - val_loss: 0.6620 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.66228 to 0.66200, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.6902 - acc: 0.6706 - val_loss: 0.6611 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.66200 to 0.66115, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6890 - acc: 0.6709 - val_loss: 0.6605 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.66115 to 0.66049, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 40/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6893 - acc: 0.6701 - val_loss: 0.6598 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.66049 to 0.65975, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6860 - acc: 0.6707 - val_loss: 0.6588 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.65975 to 0.65875, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6874 - acc: 0.6733 - val_loss: 0.6581 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.65875 to 0.65814, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6849 - acc: 0.6729 - val_loss: 0.6573 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.65814 to 0.65731, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6861 - acc: 0.6709 - val_loss: 0.6567 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.65731 to 0.65669, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 6s 140us/step - loss: 0.6839 - acc: 0.6726 - val_loss: 0.6558 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.65669 to 0.65577, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6816 - acc: 0.6740 - val_loss: 0.6548 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.65577 to 0.65479, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 6s 125us/step - loss: 0.6852 - acc: 0.6736 - val_loss: 0.6544 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.65479 to 0.65440, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.6838 - acc: 0.6733 - val_loss: 0.6537 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.65440 to 0.65373, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6839 - acc: 0.6725 - val_loss: 0.6534 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.65373 to 0.65344, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6824 - acc: 0.6725 - val_loss: 0.6528 - val_acc: 0.6944\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.65344 to 0.65280, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 8s 164us/step - loss: 0.6810 - acc: 0.6753 - val_loss: 0.6522 - val_acc: 0.6948\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.65280 to 0.65223, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6786 - acc: 0.6753 - val_loss: 0.6512 - val_acc: 0.6949\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.65223 to 0.65122, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.6813 - acc: 0.6754 - val_loss: 0.6508 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.65122 to 0.65085, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6801 - acc: 0.6756 - val_loss: 0.6501 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.65085 to 0.65005, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.6773 - acc: 0.6771 - val_loss: 0.6490 - val_acc: 0.6959\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.65005 to 0.64900, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6772 - acc: 0.6771 - val_loss: 0.6485 - val_acc: 0.6962\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.64900 to 0.64851, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6756 - acc: 0.6783 - val_loss: 0.6475 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.64851 to 0.64748, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6762 - acc: 0.6780 - val_loss: 0.6466 - val_acc: 0.6968\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.64748 to 0.64665, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6760 - acc: 0.6781 - val_loss: 0.6462 - val_acc: 0.6968\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.64665 to 0.64616, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6744 - acc: 0.6783 - val_loss: 0.6455 - val_acc: 0.6968\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.64616 to 0.64547, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6750 - acc: 0.6773 - val_loss: 0.6450 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.64547 to 0.64503, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.6734 - acc: 0.6776 - val_loss: 0.6443 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.64503 to 0.64433, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6755 - acc: 0.6784 - val_loss: 0.6440 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.64433 to 0.64400, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 64/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6729 - acc: 0.6786 - val_loss: 0.6431 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.64400 to 0.64314, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6728 - acc: 0.6797 - val_loss: 0.6422 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.64314 to 0.64221, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 66/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6718 - acc: 0.6789 - val_loss: 0.6417 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.64221 to 0.64165, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.6718 - acc: 0.6778 - val_loss: 0.6410 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.64165 to 0.64100, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.6721 - acc: 0.6779 - val_loss: 0.6404 - val_acc: 0.6968\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.64100 to 0.64041, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6705 - acc: 0.6790 - val_loss: 0.6396 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.64041 to 0.63963, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6711 - acc: 0.6805 - val_loss: 0.6387 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.63963 to 0.63870, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 8s 164us/step - loss: 0.6739 - acc: 0.6793 - val_loss: 0.6382 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.63870 to 0.63823, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.6679 - acc: 0.6798 - val_loss: 0.6372 - val_acc: 0.6973\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.63823 to 0.63725, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6679 - acc: 0.6821 - val_loss: 0.6366 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.63725 to 0.63655, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6695 - acc: 0.6808 - val_loss: 0.6362 - val_acc: 0.6976\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.63655 to 0.63620, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6678 - acc: 0.6808 - val_loss: 0.6352 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.63620 to 0.63522, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6674 - acc: 0.6822 - val_loss: 0.6349 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.63522 to 0.63489, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.6653 - acc: 0.6820 - val_loss: 0.6342 - val_acc: 0.6981\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.63489 to 0.63416, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6649 - acc: 0.6832 - val_loss: 0.6335 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.63416 to 0.63348, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6655 - acc: 0.6820 - val_loss: 0.6327 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.63348 to 0.63270, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6684 - acc: 0.6821 - val_loss: 0.6323 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.63270 to 0.63231, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6647 - acc: 0.6828 - val_loss: 0.6318 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.63231 to 0.63180, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 82/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6645 - acc: 0.6840 - val_loss: 0.6312 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.63180 to 0.63115, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6657 - acc: 0.6827 - val_loss: 0.6307 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.63115 to 0.63069, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 6s 128us/step - loss: 0.6620 - acc: 0.6855 - val_loss: 0.6298 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.63069 to 0.62982, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 8s 166us/step - loss: 0.6613 - acc: 0.6859 - val_loss: 0.6289 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.62982 to 0.62889, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6630 - acc: 0.6848 - val_loss: 0.6283 - val_acc: 0.6993\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.62889 to 0.62829, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6610 - acc: 0.6855 - val_loss: 0.6278 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.62829 to 0.62777, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6612 - acc: 0.6864 - val_loss: 0.6273 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.62777 to 0.62727, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6608 - acc: 0.6859 - val_loss: 0.6267 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.62727 to 0.62666, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6617 - acc: 0.6863 - val_loss: 0.6260 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.62666 to 0.62597, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6612 - acc: 0.6870 - val_loss: 0.6256 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.62597 to 0.62560, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6581 - acc: 0.6866 - val_loss: 0.6251 - val_acc: 0.7003\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.62560 to 0.62507, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6590 - acc: 0.6879 - val_loss: 0.6246 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.62507 to 0.62464, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6595 - acc: 0.6857 - val_loss: 0.6241 - val_acc: 0.7004\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.62464 to 0.62408, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6592 - acc: 0.6874 - val_loss: 0.6233 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.62408 to 0.62329, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 96/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6576 - acc: 0.6893 - val_loss: 0.6226 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.62329 to 0.62262, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.6554 - acc: 0.6878 - val_loss: 0.6219 - val_acc: 0.7002\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.62262 to 0.62191, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6537 - acc: 0.6889 - val_loss: 0.6212 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.62191 to 0.62122, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 99/100\n",
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.6569 - acc: 0.6888 - val_loss: 0.6205 - val_acc: 0.7014\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.62122 to 0.62055, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6549 - acc: 0.6909 - val_loss: 0.6200 - val_acc: 0.7016\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.62055 to 0.61995, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efca0269e8>"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nullsonly.fit(Xtrain_nullsonly, Ytrain_nullsonly, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nullsonly.load_weights('saved_models/weights.best.mlp_nullsonly.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 56.9616%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nullsonly.evaluate(Xtest_nullsonly, Ytest_nullsonly, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6142.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nullsonly= mlp_nullsonly.predict(Xtest_nullsonly)\n",
    "mlp_nullsonly_ROC = roc_auc_score(Ytest_nullsonly, Ypred_nullsonly)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nullsonly_ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_onehot = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=64,\n",
    "                             second_dense=32,\n",
    "                             third_dense=16,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_onehot.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_onehot.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 10s 222us/step - loss: 0.8830 - acc: 0.5230 - val_loss: 0.7933 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79333, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.8345 - acc: 0.5857 - val_loss: 0.7752 - val_acc: 0.7940\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79333 to 0.77520, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.8141 - acc: 0.6359 - val_loss: 0.7637 - val_acc: 0.7908\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77520 to 0.76375, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.7964 - acc: 0.6778 - val_loss: 0.7537 - val_acc: 0.7722\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76375 to 0.75372, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.7850 - acc: 0.6978 - val_loss: 0.7453 - val_acc: 0.7737\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75372 to 0.74532, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.7757 - acc: 0.7079 - val_loss: 0.7351 - val_acc: 0.7744\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74532 to 0.73509, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.7708 - acc: 0.7154 - val_loss: 0.7277 - val_acc: 0.7758\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73509 to 0.72774, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.7572 - acc: 0.7250 - val_loss: 0.7181 - val_acc: 0.7765\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72774 to 0.71814, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.7505 - acc: 0.7288 - val_loss: 0.7105 - val_acc: 0.7773\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71814 to 0.71047, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 8s 166us/step - loss: 0.7467 - acc: 0.7307 - val_loss: 0.7041 - val_acc: 0.7785\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.71047 to 0.70414, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.7405 - acc: 0.7338 - val_loss: 0.6976 - val_acc: 0.7792\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.70414 to 0.69758, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.7315 - acc: 0.7401 - val_loss: 0.6894 - val_acc: 0.7861\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.69758 to 0.68936, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7293 - acc: 0.7412 - val_loss: 0.6826 - val_acc: 0.7993\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.68936 to 0.68256, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.7216 - acc: 0.7453 - val_loss: 0.6755 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.68256 to 0.67555, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.7172 - acc: 0.7485 - val_loss: 0.6678 - val_acc: 0.8213\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.67555 to 0.66781, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.7074 - acc: 0.7554 - val_loss: 0.6593 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.66781 to 0.65927, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.7067 - acc: 0.7544 - val_loss: 0.6535 - val_acc: 0.8206\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.65927 to 0.65346, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6967 - acc: 0.7612 - val_loss: 0.6463 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.65346 to 0.64634, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.6891 - acc: 0.7651 - val_loss: 0.6372 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.64634 to 0.63718, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6861 - acc: 0.7658 - val_loss: 0.6316 - val_acc: 0.8188\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.63718 to 0.63161, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 6s 132us/step - loss: 0.6842 - acc: 0.7670 - val_loss: 0.6256 - val_acc: 0.8177\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.63161 to 0.62562, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 6s 124us/step - loss: 0.6759 - acc: 0.7714 - val_loss: 0.6201 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.62562 to 0.62008, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.6699 - acc: 0.7759 - val_loss: 0.6132 - val_acc: 0.8166\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.62008 to 0.61320, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 6s 124us/step - loss: 0.6631 - acc: 0.7794 - val_loss: 0.6082 - val_acc: 0.8156\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.61320 to 0.60821, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 6s 138us/step - loss: 0.6616 - acc: 0.7787 - val_loss: 0.6027 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.60821 to 0.60272, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 7s 143us/step - loss: 0.6568 - acc: 0.7794 - val_loss: 0.5977 - val_acc: 0.8157\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.60272 to 0.59766, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 8s 176us/step - loss: 0.6564 - acc: 0.7796 - val_loss: 0.5940 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.59766 to 0.59401, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 7s 145us/step - loss: 0.6510 - acc: 0.7820 - val_loss: 0.5894 - val_acc: 0.8158\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.59401 to 0.58939, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 6s 134us/step - loss: 0.6477 - acc: 0.7849 - val_loss: 0.5861 - val_acc: 0.8160\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.58939 to 0.58607, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 6s 122us/step - loss: 0.6460 - acc: 0.7863 - val_loss: 0.5824 - val_acc: 0.8162\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.58607 to 0.58237, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 9s 189us/step - loss: 0.6430 - acc: 0.7886 - val_loss: 0.5798 - val_acc: 0.8165\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.58237 to 0.57982, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 11s 245us/step - loss: 0.6366 - acc: 0.7887 - val_loss: 0.5753 - val_acc: 0.8167\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.57982 to 0.57531, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 10s 211us/step - loss: 0.6346 - acc: 0.7903 - val_loss: 0.5721 - val_acc: 0.8172\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.57531 to 0.57212, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 8s 185us/step - loss: 0.6301 - acc: 0.7953 - val_loss: 0.5704 - val_acc: 0.8200\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.57212 to 0.57037, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 9s 206us/step - loss: 0.6296 - acc: 0.7930 - val_loss: 0.5649 - val_acc: 0.8222\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.57037 to 0.56490, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 9s 205us/step - loss: 0.6252 - acc: 0.7955 - val_loss: 0.5624 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.56490 to 0.56239, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 10s 208us/step - loss: 0.6226 - acc: 0.7972 - val_loss: 0.5610 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.56239 to 0.56096, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 8s 166us/step - loss: 0.6198 - acc: 0.7975 - val_loss: 0.5573 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.56096 to 0.55735, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.6185 - acc: 0.7993 - val_loss: 0.5551 - val_acc: 0.8234\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.55735 to 0.55514, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 40/100\n",
      "45858/45858 [==============================] - 6s 132us/step - loss: 0.6180 - acc: 0.7987 - val_loss: 0.5541 - val_acc: 0.8235\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.55514 to 0.55409, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.6133 - acc: 0.8001 - val_loss: 0.5508 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.55409 to 0.55081, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.6080 - acc: 0.8029 - val_loss: 0.5464 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.55081 to 0.54637, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.6078 - acc: 0.8020 - val_loss: 0.5440 - val_acc: 0.8249\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.54637 to 0.54402, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 6s 132us/step - loss: 0.6015 - acc: 0.8061 - val_loss: 0.5417 - val_acc: 0.8262\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.54402 to 0.54170, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 6s 133us/step - loss: 0.6033 - acc: 0.8039 - val_loss: 0.5392 - val_acc: 0.8261\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.54170 to 0.53921, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.6042 - acc: 0.8044 - val_loss: 0.5378 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.53921 to 0.53776, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 6s 134us/step - loss: 0.5979 - acc: 0.8063 - val_loss: 0.5343 - val_acc: 0.8290\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.53776 to 0.53433, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 7s 142us/step - loss: 0.5934 - acc: 0.8062 - val_loss: 0.5314 - val_acc: 0.8303\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.53433 to 0.53137, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 7s 152us/step - loss: 0.5913 - acc: 0.8083 - val_loss: 0.5287 - val_acc: 0.8319\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.53137 to 0.52874, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 7s 146us/step - loss: 0.5927 - acc: 0.8082 - val_loss: 0.5277 - val_acc: 0.8329\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.52874 to 0.52771, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 6s 140us/step - loss: 0.5886 - acc: 0.8092 - val_loss: 0.5254 - val_acc: 0.8360\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.52771 to 0.52539, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5882 - acc: 0.8103 - val_loss: 0.5224 - val_acc: 0.8396\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.52539 to 0.52243, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5790 - acc: 0.8149 - val_loss: 0.5195 - val_acc: 0.8454\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.52243 to 0.51953, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5785 - acc: 0.8133 - val_loss: 0.5172 - val_acc: 0.8486\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.51953 to 0.51722, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5792 - acc: 0.8146 - val_loss: 0.5158 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.51722 to 0.51576, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 7s 145us/step - loss: 0.5761 - acc: 0.8153 - val_loss: 0.5134 - val_acc: 0.8494\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.51576 to 0.51338, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 6s 138us/step - loss: 0.5742 - acc: 0.8141 - val_loss: 0.5094 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.51338 to 0.50939, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5718 - acc: 0.8178 - val_loss: 0.5087 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.50939 to 0.50875, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.5703 - acc: 0.8152 - val_loss: 0.5064 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.50875 to 0.50641, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.5732 - acc: 0.8132 - val_loss: 0.5046 - val_acc: 0.8480\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.50641 to 0.50459, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.5702 - acc: 0.8151 - val_loss: 0.5042 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.50459 to 0.50422, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 6s 140us/step - loss: 0.5672 - acc: 0.8166 - val_loss: 0.5012 - val_acc: 0.8479\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.50422 to 0.50116, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 6s 138us/step - loss: 0.5636 - acc: 0.8193 - val_loss: 0.4997 - val_acc: 0.8478\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.50116 to 0.49966, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 64/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.5651 - acc: 0.8169 - val_loss: 0.4978 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.49966 to 0.49783, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5627 - acc: 0.8177 - val_loss: 0.4965 - val_acc: 0.8476\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.49783 to 0.49653, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 66/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.5625 - acc: 0.8162 - val_loss: 0.4953 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.49653 to 0.49534, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5603 - acc: 0.8192 - val_loss: 0.4926 - val_acc: 0.8490\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.49534 to 0.49260, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5544 - acc: 0.8208 - val_loss: 0.4906 - val_acc: 0.8489\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.49260 to 0.49058, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 6s 129us/step - loss: 0.5539 - acc: 0.8210 - val_loss: 0.4884 - val_acc: 0.8482\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.49058 to 0.48836, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 6s 129us/step - loss: 0.5523 - acc: 0.8216 - val_loss: 0.4877 - val_acc: 0.8481\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.48836 to 0.48773, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5529 - acc: 0.8207 - val_loss: 0.4862 - val_acc: 0.8491\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.48773 to 0.48623, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.5513 - acc: 0.8217 - val_loss: 0.4839 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.48623 to 0.48387, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.5483 - acc: 0.8222 - val_loss: 0.4829 - val_acc: 0.8492\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.48387 to 0.48291, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 6s 132us/step - loss: 0.5491 - acc: 0.8215 - val_loss: 0.4822 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.48291 to 0.48222, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.5458 - acc: 0.8212 - val_loss: 0.4800 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.48222 to 0.47996, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 6s 133us/step - loss: 0.5462 - acc: 0.8235 - val_loss: 0.4791 - val_acc: 0.8495\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.47996 to 0.47910, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5425 - acc: 0.8249 - val_loss: 0.4769 - val_acc: 0.8498\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.47910 to 0.47687, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5418 - acc: 0.8239 - val_loss: 0.4747 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.47687 to 0.47473, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5398 - acc: 0.8244 - val_loss: 0.4744 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.47473 to 0.47440, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.5419 - acc: 0.8263 - val_loss: 0.4727 - val_acc: 0.8502\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.47440 to 0.47267, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.5374 - acc: 0.8260 - val_loss: 0.4709 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.47267 to 0.47090, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 82/100\n",
      "45858/45858 [==============================] - 7s 143us/step - loss: 0.5356 - acc: 0.8273 - val_loss: 0.4692 - val_acc: 0.8506\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.47090 to 0.46919, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 6s 138us/step - loss: 0.5368 - acc: 0.8261 - val_loss: 0.4676 - val_acc: 0.8512\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.46919 to 0.46757, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 6s 123us/step - loss: 0.5312 - acc: 0.8277 - val_loss: 0.4662 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.46757 to 0.46618, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 11s 235us/step - loss: 0.5330 - acc: 0.8263 - val_loss: 0.4650 - val_acc: 0.8509\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.46618 to 0.46503, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 8s 177us/step - loss: 0.5329 - acc: 0.8283 - val_loss: 0.4647 - val_acc: 0.8514\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.46503 to 0.46471, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 7s 147us/step - loss: 0.5285 - acc: 0.8300 - val_loss: 0.4635 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.46471 to 0.46348, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 6s 138us/step - loss: 0.5306 - acc: 0.8261 - val_loss: 0.4624 - val_acc: 0.8520\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.46348 to 0.46244, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 6s 139us/step - loss: 0.5334 - acc: 0.8269 - val_loss: 0.4618 - val_acc: 0.8525\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.46244 to 0.46176, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 6s 133us/step - loss: 0.5290 - acc: 0.8297 - val_loss: 0.4604 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.46176 to 0.46040, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.5253 - acc: 0.8303 - val_loss: 0.4590 - val_acc: 0.8533\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.46040 to 0.45899, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 6s 135us/step - loss: 0.5247 - acc: 0.8287 - val_loss: 0.4572 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.45899 to 0.45725, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 6s 140us/step - loss: 0.5233 - acc: 0.8310 - val_loss: 0.4568 - val_acc: 0.8527\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.45725 to 0.45680, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 7s 144us/step - loss: 0.5225 - acc: 0.8310 - val_loss: 0.4562 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.45680 to 0.45623, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 6s 136us/step - loss: 0.5215 - acc: 0.8303 - val_loss: 0.4549 - val_acc: 0.8529\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.45623 to 0.45487, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 96/100\n",
      "45858/45858 [==============================] - 6s 141us/step - loss: 0.5235 - acc: 0.8312 - val_loss: 0.4538 - val_acc: 0.8534\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.45487 to 0.45384, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.5186 - acc: 0.8317 - val_loss: 0.4526 - val_acc: 0.8541\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.45384 to 0.45257, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.5197 - acc: 0.8326 - val_loss: 0.4521 - val_acc: 0.8546\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.45257 to 0.45207, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 99/100\n",
      "45858/45858 [==============================] - 6s 126us/step - loss: 0.5182 - acc: 0.8318 - val_loss: 0.4504 - val_acc: 0.8550\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.45207 to 0.45045, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 6s 126us/step - loss: 0.5159 - acc: 0.8333 - val_loss: 0.4500 - val_acc: 0.8556\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.45045 to 0.44999, saving model to saved_models/weights.best.mlp_onehot.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efdb525c88>"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_onehot.fit(Xtrain_onehot, Ytrain_onehot, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_onehot.load_weights('saved_models/weights.best.mlp_onehot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 68.4140%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_onehot.evaluate(Xtest_onehot, Ytest_onehot, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.7289.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_onehot = mlp_onehot.predict(Xtest_onehot)\n",
    "ROC_mlp_onehot = roc_auc_score(Ytest_onehot, Ypred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_sum = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_sum.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_sum.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 9s 202us/step - loss: 0.7687 - acc: 0.5385 - val_loss: 0.7297 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.72967, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.7535 - acc: 0.5654 - val_loss: 0.7168 - val_acc: 0.6913\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.72967 to 0.71679, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.7441 - acc: 0.5816 - val_loss: 0.7069 - val_acc: 0.6928\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.71679 to 0.70694, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.7390 - acc: 0.5955 - val_loss: 0.6996 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.70694 to 0.69959, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.7367 - acc: 0.6041 - val_loss: 0.6938 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.69959 to 0.69380, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.7344 - acc: 0.6110 - val_loss: 0.6895 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69380 to 0.68948, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.7296 - acc: 0.6176 - val_loss: 0.6850 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68948 to 0.68497, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.7250 - acc: 0.6224 - val_loss: 0.6817 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68497 to 0.68171, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.7232 - acc: 0.6280 - val_loss: 0.6789 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.68171 to 0.67893, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7205 - acc: 0.6297 - val_loss: 0.6765 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.67893 to 0.67651, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7166 - acc: 0.6321 - val_loss: 0.6743 - val_acc: 0.6937\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67651 to 0.67434, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7172 - acc: 0.6362 - val_loss: 0.6718 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.67434 to 0.67183, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.7166 - acc: 0.6351 - val_loss: 0.6710 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.67183 to 0.67098, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 6s 123us/step - loss: 0.7129 - acc: 0.6383 - val_loss: 0.6697 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.67098 to 0.66969, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.7113 - acc: 0.6386 - val_loss: 0.6687 - val_acc: 0.6946\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.66969 to 0.66865, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.7108 - acc: 0.6414 - val_loss: 0.6669 - val_acc: 0.6962\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.66865 to 0.66693, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.7073 - acc: 0.6460 - val_loss: 0.6657 - val_acc: 0.6958\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.66693 to 0.66571, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 6s 123us/step - loss: 0.7109 - acc: 0.6439 - val_loss: 0.6648 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.66571 to 0.66479, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.7058 - acc: 0.6480 - val_loss: 0.6636 - val_acc: 0.6971\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.66479 to 0.66363, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7062 - acc: 0.6473 - val_loss: 0.6632 - val_acc: 0.6973\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.66363 to 0.66322, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.7065 - acc: 0.6470 - val_loss: 0.6623 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.66322 to 0.66231, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.7025 - acc: 0.6503 - val_loss: 0.6613 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.66231 to 0.66128, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.7008 - acc: 0.6516 - val_loss: 0.6601 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.66128 to 0.66007, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6987 - acc: 0.6541 - val_loss: 0.6590 - val_acc: 0.6993\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.66007 to 0.65899, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.7000 - acc: 0.6508 - val_loss: 0.6579 - val_acc: 0.6994\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.65899 to 0.65785, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 6s 124us/step - loss: 0.6983 - acc: 0.6530 - val_loss: 0.6570 - val_acc: 0.7004\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.65785 to 0.65705, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 6s 122us/step - loss: 0.6986 - acc: 0.6520 - val_loss: 0.6563 - val_acc: 0.7011\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.65705 to 0.65631, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 6s 122us/step - loss: 0.6984 - acc: 0.6559 - val_loss: 0.6556 - val_acc: 0.7015\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.65631 to 0.65555, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6968 - acc: 0.6539 - val_loss: 0.6547 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.65555 to 0.65469, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6959 - acc: 0.6535 - val_loss: 0.6539 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.65469 to 0.65393, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6934 - acc: 0.6565 - val_loss: 0.6524 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.65393 to 0.65240, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6930 - acc: 0.6564 - val_loss: 0.6513 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.65240 to 0.65126, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 33/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6936 - acc: 0.6562 - val_loss: 0.6508 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.65126 to 0.65083, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6928 - acc: 0.6594 - val_loss: 0.6505 - val_acc: 0.7049\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.65083 to 0.65053, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6897 - acc: 0.6590 - val_loss: 0.6494 - val_acc: 0.7051\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.65053 to 0.64936, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6877 - acc: 0.6602 - val_loss: 0.6480 - val_acc: 0.7059\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.64936 to 0.64804, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6874 - acc: 0.6642 - val_loss: 0.6466 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.64804 to 0.64663, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6883 - acc: 0.6584 - val_loss: 0.6460 - val_acc: 0.7068\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.64663 to 0.64598, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6882 - acc: 0.6576 - val_loss: 0.6453 - val_acc: 0.7067\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.64598 to 0.64532, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 40/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6873 - acc: 0.6608 - val_loss: 0.6447 - val_acc: 0.7077\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.64532 to 0.64475, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6848 - acc: 0.6603 - val_loss: 0.6439 - val_acc: 0.7079\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.64475 to 0.64389, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6836 - acc: 0.6641 - val_loss: 0.6428 - val_acc: 0.7076\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.64389 to 0.64284, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6834 - acc: 0.6619 - val_loss: 0.6419 - val_acc: 0.7080\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.64284 to 0.64190, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.6837 - acc: 0.6620 - val_loss: 0.6414 - val_acc: 0.7086\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.64190 to 0.64143, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.6858 - acc: 0.6589 - val_loss: 0.6412 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.64143 to 0.64117, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.6825 - acc: 0.6670 - val_loss: 0.6403 - val_acc: 0.7097\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.64117 to 0.64033, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6848 - acc: 0.6627 - val_loss: 0.6403 - val_acc: 0.7102\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.64033 to 0.64027, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6803 - acc: 0.6666 - val_loss: 0.6386 - val_acc: 0.7104\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.64027 to 0.63863, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6813 - acc: 0.6664 - val_loss: 0.6379 - val_acc: 0.7104\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.63863 to 0.63790, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6797 - acc: 0.6688 - val_loss: 0.6375 - val_acc: 0.7115\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.63790 to 0.63749, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6795 - acc: 0.6643 - val_loss: 0.6367 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.63749 to 0.63667, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6793 - acc: 0.6628 - val_loss: 0.6364 - val_acc: 0.7123\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.63667 to 0.63641, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6778 - acc: 0.6656 - val_loss: 0.6354 - val_acc: 0.7130\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.63641 to 0.63540, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6778 - acc: 0.6640 - val_loss: 0.6344 - val_acc: 0.7138\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.63540 to 0.63444, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6760 - acc: 0.6656 - val_loss: 0.6336 - val_acc: 0.7148\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.63444 to 0.63358, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6742 - acc: 0.6677 - val_loss: 0.6324 - val_acc: 0.7152\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.63358 to 0.63239, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6756 - acc: 0.6657 - val_loss: 0.6319 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.63239 to 0.63189, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6761 - acc: 0.6688 - val_loss: 0.6315 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.63189 to 0.63149, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6761 - acc: 0.6660 - val_loss: 0.6304 - val_acc: 0.7201\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.63149 to 0.63040, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 6s 136us/step - loss: 0.6706 - acc: 0.6690 - val_loss: 0.6295 - val_acc: 0.7203\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.63040 to 0.62953, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 7s 142us/step - loss: 0.6729 - acc: 0.6672 - val_loss: 0.6289 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.62953 to 0.62888, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 6s 123us/step - loss: 0.6705 - acc: 0.6694 - val_loss: 0.6281 - val_acc: 0.7212\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.62888 to 0.62813, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 6s 130us/step - loss: 0.6709 - acc: 0.6704 - val_loss: 0.6275 - val_acc: 0.7217\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.62813 to 0.62746, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 64/100\n",
      "45858/45858 [==============================] - 6s 131us/step - loss: 0.6708 - acc: 0.6707 - val_loss: 0.6267 - val_acc: 0.7238\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.62746 to 0.62675, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 65/100\n",
      "45858/45858 [==============================] - 6s 123us/step - loss: 0.6688 - acc: 0.6680 - val_loss: 0.6258 - val_acc: 0.7246\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.62675 to 0.62578, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6671 - acc: 0.6693 - val_loss: 0.6250 - val_acc: 0.7246\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.62578 to 0.62499, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6670 - acc: 0.6681 - val_loss: 0.6243 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.62499 to 0.62425, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6655 - acc: 0.6723 - val_loss: 0.6229 - val_acc: 0.7270\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.62425 to 0.62293, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6669 - acc: 0.6726 - val_loss: 0.6223 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.62293 to 0.62228, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6685 - acc: 0.6726 - val_loss: 0.6220 - val_acc: 0.7303\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.62228 to 0.62200, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6666 - acc: 0.6721 - val_loss: 0.6213 - val_acc: 0.7304\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.62200 to 0.62127, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6620 - acc: 0.6763 - val_loss: 0.6202 - val_acc: 0.7314\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.62127 to 0.62017, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6601 - acc: 0.6771 - val_loss: 0.6191 - val_acc: 0.7317\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.62017 to 0.61909, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6655 - acc: 0.6741 - val_loss: 0.6189 - val_acc: 0.7321\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.61909 to 0.61887, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6621 - acc: 0.6752 - val_loss: 0.6182 - val_acc: 0.7340\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.61887 to 0.61819, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6635 - acc: 0.6734 - val_loss: 0.6179 - val_acc: 0.7332\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.61819 to 0.61790, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6624 - acc: 0.6770 - val_loss: 0.6176 - val_acc: 0.7363\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.61790 to 0.61759, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 5s 115us/step - loss: 0.6612 - acc: 0.6741 - val_loss: 0.6170 - val_acc: 0.7355\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.61759 to 0.61699, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6586 - acc: 0.6789 - val_loss: 0.6155 - val_acc: 0.7380\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.61699 to 0.61553, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6580 - acc: 0.6763 - val_loss: 0.6143 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.61553 to 0.61428, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6570 - acc: 0.6784 - val_loss: 0.6134 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.61428 to 0.61339, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 82/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.6601 - acc: 0.6766 - val_loss: 0.6131 - val_acc: 0.7396\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.61339 to 0.61312, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.6580 - acc: 0.6783 - val_loss: 0.6127 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.61312 to 0.61270, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6572 - acc: 0.6774 - val_loss: 0.6121 - val_acc: 0.7389\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.61270 to 0.61213, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6589 - acc: 0.6754 - val_loss: 0.6121 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.61213 to 0.61213, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.6552 - acc: 0.6801 - val_loss: 0.6113 - val_acc: 0.7399\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.61213 to 0.61127, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.6551 - acc: 0.6771 - val_loss: 0.6105 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.61127 to 0.61047, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 6s 136us/step - loss: 0.6539 - acc: 0.6790 - val_loss: 0.6093 - val_acc: 0.7429\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.61047 to 0.60934, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6553 - acc: 0.6786 - val_loss: 0.6085 - val_acc: 0.7424\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.60934 to 0.60846, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 5s 120us/step - loss: 0.6542 - acc: 0.6793 - val_loss: 0.6083 - val_acc: 0.7437\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.60846 to 0.60829, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 5s 120us/step - loss: 0.6532 - acc: 0.6788 - val_loss: 0.6079 - val_acc: 0.7436\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.60829 to 0.60790, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 5s 120us/step - loss: 0.6520 - acc: 0.6808 - val_loss: 0.6065 - val_acc: 0.7444\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.60790 to 0.60652, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 5s 120us/step - loss: 0.6526 - acc: 0.6847 - val_loss: 0.6064 - val_acc: 0.7449\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.60652 to 0.60636, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6500 - acc: 0.6865 - val_loss: 0.6055 - val_acc: 0.7455\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.60636 to 0.60548, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6521 - acc: 0.6849 - val_loss: 0.6046 - val_acc: 0.7451\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.60548 to 0.60460, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 96/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6489 - acc: 0.6869 - val_loss: 0.6042 - val_acc: 0.7467\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.60460 to 0.60422, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 97/100\n",
      "45858/45858 [==============================] - 5s 120us/step - loss: 0.6489 - acc: 0.6868 - val_loss: 0.6037 - val_acc: 0.7468\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.60422 to 0.60367, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 6s 121us/step - loss: 0.6488 - acc: 0.6871 - val_loss: 0.6031 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.60367 to 0.60309, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6489 - acc: 0.6876 - val_loss: 0.6027 - val_acc: 0.7471\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.60309 to 0.60270, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.6499 - acc: 0.6904 - val_loss: 0.6023 - val_acc: 0.7477\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.60270 to 0.60233, saving model to saved_models/weights.best.mlp_sum.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efa5dbe080>"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_sum.fit(Xtrain_sum, Ytrain_sum, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_sum.load_weights('saved_models/weights.best.mlp_sum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 74.1569%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_sum.evaluate(Xtest_sum, Ytest_sum, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.7452.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_sum = mlp_sum.predict(Xtest_sum)\n",
    "ROC_mlp_sum = roc_auc_score(Ytest_sum, Ypred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "3. https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "4. https://dziganto.github.io/cross-validation/data%20science/machine%20learning/model%20tuning/python/Model-Tuning-with-Validation-and-Cross-Validation/\n",
    "5. https://keras.io/getting-started/sequential-model-guide/\n",
    "6. Udacity Machine Learning Engineer Nanodegree Program, Semester 2, Brian Campbell - Dog Breed Classifier Project\n",
    "7. https://keras.io/getting-started/sequential-model-guide/\n",
    "8. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ma.size.html\n",
    "9. https://keras.io/models/sequential/\n",
    "10. https://machinelearningmastery.com/reproducible-results-neural-networks-keras/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
