{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: The Efficacy of Multilayer Perceptron Algorithms in Predicting Bankruptcy, The Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"#DISCLOSURE\">DISCLOSURE</a></li>\n",
    "<li><a href=\"#introduction\">INTRODUCTION</a></li>\n",
    "<li><a href=\"#Benchmark Logistic Regression\">Benchmark Logistic Regression</a></li>\n",
    "<li><a href=\"#MLP Model\">MLP Model</a></li>\n",
    "<li><a href=\"#references\">References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DISCLOSURE'></a>\n",
    "## DISCLOSURE\n",
    "Please note, that this notebook, \"bankruptcy-model.ipynb\" ONLY COVERS the modeling of the data. Simply, the jupyter notebook, \"bankruptcy-data.ipynb\" was too big to include the models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## INTRODUCTION\n",
    "This part of the analyis loads the preprocessed data: a dataset with no null values (\"No Nulls\"), a dataset with imputed null values (\"Nulls Only'), a dataset that has a dummy variable for each feature variable that signals whether a value in the feature column is null (\"One Hot\"), and a dataset with imputed null values and a variable that counts the number of null values in a given row of data (\"Sum\"). Logistic regression models are applied to these four datasets as the benchmark models. Next, Multi Layer Perceptron (MLP) models are made for the four datasets. The AUC scores are calculated for all the models. The conclusion compares the AUC scores of the MLP models to the Logistic Regression models, and offers additional insight into these models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Benchmark Logistic Regression'></a>\n",
    "## Benchmark Logistic Regression\n",
    "Logistic regression servers as a good benchmark model for predicting bankruptcies. It's a basic model that analyzes a binary target variable (bankrupt vs not bankrupt)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary libraries for the logistic regression models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# This imports the AUC score for scoring the models.\n",
    "# This comes from Reference 27 in References.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# These are libraries that will be needed to organize data,\n",
    "# graph data, and change the working directory.\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the no_nulls X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nonulls = pd.read_csv('no-peaking/Xtrain_nonulls.csv')\n",
    "Xtrain_nonulls = np.array(Xtrain_nonulls)\n",
    "Xtest_nonulls = pd.read_csv('no-peaking/Xtest_nonulls.csv')\n",
    "Xtest_nonulls = np.array(Xtest_nonulls)\n",
    "\n",
    "# This loads the no_nulls Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nonulls = pd.read_csv('no-peaking/Ytrain_nonulls.csv')\n",
    "Ytrain_nonulls = np.array(Ytrain_nonulls)\n",
    "Ytrain_nonulls = Ytrain_nonulls.ravel() \n",
    "Ytest_nonulls = pd.read_csv('no-peaking/Ytest_nonulls.csv')\n",
    "Ytest_nonulls = np.array(Ytest_nonulls)\n",
    "Ytest_nonulls = Ytest_nonulls.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Hold-out Cross-Validation on just the training set\n",
    "K-fold Cross-Validation is a standard method for preventing a logistic regression model from overfitting. However, because the testing set, the fifth year of the dataset, is arbitrarily chosen (not random), K-fold Cross-Validation cannot be applied to the dataset (Reference 3). K-fold Cross-Validation would corrupt the testing set with data leakage considering that the dataset is a time-series set (Reference 3). To prevent data leakage, Hold-out cross-Validation will only be applied to the training set (References 3 & 4). Hold-out Cross-Validation takes a percentage of the training set as a validation set to test the accuracy of the model during the training stage. This method of cross validation, like all methods, is used to prevent the overfitting of a model and poor accuracy performance when applying the testing data to the fitted model (Reference 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Nulls Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import train_test_split from sklearn.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the No Nulls dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nonulls, Xval_nonulls, Ytrain_nonulls, Yval_nonulls = train_test_split(\n",
    "                    Xtrain_nonulls, Ytrain_nonulls, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8493093121316346"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the No Nulls Dataset.\n",
    "log_nonulls = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_nonulls model with the training data.\n",
    "log_nonulls.fit(Xtrain_nonulls,Ytrain_nonulls)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nonulls = log_nonulls.predict(Xval_nonulls)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nonulls = roc_auc_score(Yval_nonulls, yval_pred_nonulls)\n",
    "VAL_auc_nonulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.3675.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nonulls = log_nonulls.predict(Xtest_nonulls)\n",
    "TEST_auc_nonulls = roc_auc_score(Ytest_nonulls, ytest_pred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_nonulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Nulls only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the Nulls only training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nullsonly = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_nullsonly = Xtrain_nullsonly.drop(\n",
    "    Xtrain_nullsonly.columns[64], axis=1)\n",
    "Xtrain_nullsonly = np.array(Xtrain_nullsonly)\n",
    "Xtest_nullsonly = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_nullsonly = Xtest_nullsonly.drop(\n",
    "    Xtest_nullsonly.columns[64], axis=1)\n",
    "Xtest_nullsonly = np.array(Xtest_nullsonly)\n",
    "\n",
    "# This loads the Nulls only Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nullsonly = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_nullsonly = np.array(Ytrain_nullsonly)\n",
    "Ytrain_nullsonly = Ytrain_nullsonly.ravel() \n",
    "Ytest_nullsonly = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_nullsonly = np.array(Ytest_nullsonly)\n",
    "Ytest_nullsonly = Ytest_nullsonly.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls Only Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Nulls Only dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nullsonly, Xval_nullsonly, Ytrain_nullsonly, Yval_nullsonly = train_test_split(\n",
    "                    Xtrain_nullsonly, Ytrain_nullsonly, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7335101563282769"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the Nulls Only Dataset.\n",
    "log_nullsonly = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the Log_nullsonly model with the training data.\n",
    "log_nullsonly.fit(Xtrain_nullsonly,Ytrain_nullsonly)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nullsonly = log_nullsonly.predict(Xval_nullsonly)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nullsonly = roc_auc_score(Yval_nullsonly, yval_pred_nullsonly)\n",
    "VAL_auc_nullsonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6903.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nullsonly = log_nullsonly.predict(Xtest_nullsonly)\n",
    "TEST_auc_nullsonly = roc_auc_score(Ytest_nullsonly, ytest_pred_nullsonly)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_nullsonly)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the one hot X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_onehot = pd.read_csv('no-peaking/Xtrain_onehot.csv')\n",
    "Xtrain_onehot = np.array(Xtrain_onehot)\n",
    "Xtest_onehot = pd.read_csv('no-peaking/Xtest_onehot.csv')\n",
    "Xtest_onehot = np.array(Xtest_onehot)\n",
    "\n",
    "# This loads the one hot Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_onehot = pd.read_csv('no-peaking/Ytrain_onehot.csv')\n",
    "Ytrain_onehot = np.array(Ytrain_onehot)\n",
    "Ytrain_onehot = Ytrain_onehot.ravel() \n",
    "Ytest_onehot = pd.read_csv('no-peaking/Ytest_onehot.csv')\n",
    "Ytest_onehot = np.array(Ytest_onehot)\n",
    "Ytest_onehot = Ytest_onehot.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the One Hot dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_onehot, Xval_onehot, Ytrain_onehot, Yval_onehot = train_test_split(\n",
    "                    Xtrain_onehot, Ytrain_onehot, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.866889447207181"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the One Hot Dataset.\n",
    "log_onehot = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_onehot.fit(Xtrain_onehot,Ytrain_onehot)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_onehot = log_onehot.predict(Xval_onehot)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_onehot = roc_auc_score(Yval_onehot, yval_pred_onehot)\n",
    "VAL_auc_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6872.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_onehot = log_onehot.predict(Xtest_onehot)\n",
    "TEST_auc_onehot = roc_auc_score(Ytest_onehot, ytest_pred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the SUM X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_sum = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_sum = np.array(Xtrain_sum)\n",
    "Xtest_sum = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_sum = np.array(Xtest_sum)\n",
    "\n",
    "# This loads the SUM Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_sum = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_sum = np.array(Ytrain_sum)\n",
    "Ytrain_sum = Ytrain_sum.ravel() \n",
    "Ytest_sum = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_sum = np.array(Ytest_sum)\n",
    "Ytest_sum = Ytest_sum.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Sum dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_sum, Xval_sum, Ytrain_sum, Yval_sum = train_test_split(\n",
    "                    Xtrain_sum, Ytrain_sum, test_size = 0.2, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7454176998689093"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the Sum Dataset.\n",
    "log_sum = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_sun model with the training data.\n",
    "log_sum.fit(Xtrain_sum,Ytrain_sum)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.c\n",
    "yval_pred_sum = log_sum.predict(Xval_sum)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_sum = roc_auc_score(Yval_sum, yval_pred_sum)\n",
    "VAL_auc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6822.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_sum = log_sum.predict(Xtest_sum)\n",
    "TEST_auc_sum = roc_auc_score(Ytest_sum, ytest_pred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MLP Model'></a>\n",
    "## MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists.\n"
     ]
    }
   ],
   "source": [
    "# This creates a directory to save the best models for the MLP.\n",
    "# This comes from Reference 13 in References.\n",
    "import os\n",
    "if not os.path.exists('saved_models'):\n",
    "    os.mkdir('saved_models')\n",
    "else:\n",
    "    print(\"Directory already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# This imports the necessary libraries for the MLP.\n",
    "\n",
    "# This imports the sequential model, the layers,\n",
    "# the SGD optimizer, the regularizers from keras.\n",
    "# This comes from Reference 5 in Referenes.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Nadam\n",
    "from keras import regularizers\n",
    "\n",
    "# This imports checkpointer, which records the best weights\n",
    "# for the algorithm.\n",
    "# This comes from Reference 6 in References.\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(drop_rate, l2_factor, first_dense, second_dense,\n",
    "                third_dense, hidden_act, out_act, x):\n",
    "    dim_int = int(np.size(x,1))\n",
    "    # This defines the model as a sequential model.\n",
    "    # This comes from References 1 in References.\n",
    "    model = Sequential()\n",
    "\n",
    "    # This is the input layer.\n",
    "    # This comes from References 1 & 3 in References.\n",
    "    model.add(Dense(first_dense, activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor),\n",
    "        input_dim = dim_int))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the first hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(second_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "    \n",
    "    # This creates the second hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(third_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the output layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(1, activation=out_act))\n",
    "    # This returns the model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP NO Nulls, default learning rate in Stochastic Loss Optimizer\n",
    "This is a comparison MLP model that uses the default learning rate of 0.01 to descend down the loss gradient in an attempt to find the global minimum (Reference 14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "DEFAULT_stochastic = SGD()\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for No NULLS.\n",
    "mlp_nonulls_DEFAULT = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nonulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Nulls data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nonulls_DEFAULT.compile(loss='binary_crossentropy',\n",
    "              optimizer= DEFAULT_stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12592 samples, validate on 3148 samples\n",
      "Epoch 1/75\n",
      "12592/12592 [==============================] - 3s 248us/step - loss: 0.8101 - acc: 0.5098 - val_loss: 0.7591 - val_acc: 0.5743\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75911, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 2/75\n",
      "12592/12592 [==============================] - 1s 69us/step - loss: 0.7705 - acc: 0.5314 - val_loss: 0.7473 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75911 to 0.74732, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 3/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.7572 - acc: 0.5441 - val_loss: 0.7323 - val_acc: 0.7456\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74732 to 0.73229, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 4/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.7433 - acc: 0.5570 - val_loss: 0.7154 - val_acc: 0.7678\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73229 to 0.71539, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 5/75\n",
      "12592/12592 [==============================] - 1s 74us/step - loss: 0.7249 - acc: 0.5747 - val_loss: 0.6928 - val_acc: 0.7649\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.71539 to 0.69282, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 6/75\n",
      "12592/12592 [==============================] - 1s 72us/step - loss: 0.7084 - acc: 0.5906 - val_loss: 0.6691 - val_acc: 0.7633\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.69282 to 0.66910, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 7/75\n",
      "12592/12592 [==============================] - 1s 74us/step - loss: 0.6985 - acc: 0.6008 - val_loss: 0.6486 - val_acc: 0.7678\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.66910 to 0.64861, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 8/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.6911 - acc: 0.6221 - val_loss: 0.6339 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.64861 to 0.63387, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 9/75\n",
      "12592/12592 [==============================] - 1s 73us/step - loss: 0.6805 - acc: 0.6430 - val_loss: 0.6165 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.63387 to 0.61650, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 10/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.6630 - acc: 0.6620 - val_loss: 0.5969 - val_acc: 0.7821\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61650 to 0.59692, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 11/75\n",
      "12592/12592 [==============================] - 1s 69us/step - loss: 0.6556 - acc: 0.6691 - val_loss: 0.5816 - val_acc: 0.7881\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.59692 to 0.58163, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 12/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6441 - acc: 0.6842 - val_loss: 0.5673 - val_acc: 0.7935\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.58163 to 0.56734, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 13/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.6280 - acc: 0.7023 - val_loss: 0.5526 - val_acc: 0.7992\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.56734 to 0.55261, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 14/75\n",
      "12592/12592 [==============================] - 1s 69us/step - loss: 0.6274 - acc: 0.7044 - val_loss: 0.5394 - val_acc: 0.8059\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.55261 to 0.53936, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 15/75\n",
      "12592/12592 [==============================] - 1s 77us/step - loss: 0.6092 - acc: 0.7162 - val_loss: 0.5247 - val_acc: 0.8116\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.53936 to 0.52467, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 16/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.6054 - acc: 0.7182 - val_loss: 0.5151 - val_acc: 0.8129\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.52467 to 0.51509, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 17/75\n",
      "12592/12592 [==============================] - 1s 72us/step - loss: 0.5974 - acc: 0.7273 - val_loss: 0.5037 - val_acc: 0.8202\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.51509 to 0.50373, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 18/75\n",
      "12592/12592 [==============================] - 1s 68us/step - loss: 0.5776 - acc: 0.7421 - val_loss: 0.4886 - val_acc: 0.8240\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.50373 to 0.48859, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 19/75\n",
      "12592/12592 [==============================] - 1s 73us/step - loss: 0.5748 - acc: 0.7432 - val_loss: 0.4757 - val_acc: 0.8291\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.48859 to 0.47568, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 20/75\n",
      "12592/12592 [==============================] - 1s 74us/step - loss: 0.5622 - acc: 0.7515 - val_loss: 0.4667 - val_acc: 0.8297\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.47568 to 0.46666, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 21/75\n",
      "12592/12592 [==============================] - 1s 68us/step - loss: 0.5540 - acc: 0.7582 - val_loss: 0.4583 - val_acc: 0.8304\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.46666 to 0.45826, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 22/75\n",
      "12592/12592 [==============================] - 1s 71us/step - loss: 0.5510 - acc: 0.7555 - val_loss: 0.4517 - val_acc: 0.8355\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.45826 to 0.45175, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 23/75\n",
      "12592/12592 [==============================] - 1s 72us/step - loss: 0.5416 - acc: 0.7644 - val_loss: 0.4425 - val_acc: 0.8351\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.45175 to 0.44252, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 24/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.5344 - acc: 0.7651 - val_loss: 0.4381 - val_acc: 0.8358\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.44252 to 0.43813, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 25/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.5319 - acc: 0.7697 - val_loss: 0.4295 - val_acc: 0.8440\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.43813 to 0.42948, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 26/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.5222 - acc: 0.7733 - val_loss: 0.4245 - val_acc: 0.8475\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.42948 to 0.42449, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 27/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.5178 - acc: 0.7776 - val_loss: 0.4192 - val_acc: 0.8466\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.42449 to 0.41920, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 28/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.5112 - acc: 0.7819 - val_loss: 0.4138 - val_acc: 0.8513\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.41920 to 0.41378, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 29/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.5085 - acc: 0.7849 - val_loss: 0.4086 - val_acc: 0.8507\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.41378 to 0.40861, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 30/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.4975 - acc: 0.7921 - val_loss: 0.4063 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.40861 to 0.40630, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 31/75\n",
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.4878 - acc: 0.7945 - val_loss: 0.3993 - val_acc: 0.8583\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.40630 to 0.39930, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 32/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12592/12592 [==============================] - 1s 66us/step - loss: 0.4943 - acc: 0.7888 - val_loss: 0.3956 - val_acc: 0.8621\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.39930 to 0.39560, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 33/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.4873 - acc: 0.7957 - val_loss: 0.3924 - val_acc: 0.8602\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.39560 to 0.39245, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 34/75\n",
      "12592/12592 [==============================] - 1s 72us/step - loss: 0.4857 - acc: 0.8008 - val_loss: 0.3925 - val_acc: 0.8567\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.39245\n",
      "Epoch 35/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.4784 - acc: 0.8065 - val_loss: 0.3870 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.39245 to 0.38702, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 36/75\n",
      "12592/12592 [==============================] - 1s 70us/step - loss: 0.4734 - acc: 0.8049 - val_loss: 0.3855 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.38702 to 0.38547, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 37/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.4724 - acc: 0.8051 - val_loss: 0.3829 - val_acc: 0.8644\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.38547 to 0.38292, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 38/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.4687 - acc: 0.8073 - val_loss: 0.3774 - val_acc: 0.8707\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.38292 to 0.37743, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 39/75\n",
      "12592/12592 [==============================] - 1s 67us/step - loss: 0.4663 - acc: 0.8132 - val_loss: 0.3742 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.37743 to 0.37420, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 40/75\n",
      "12592/12592 [==============================] - 1s 71us/step - loss: 0.4601 - acc: 0.8132 - val_loss: 0.3731 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.37420 to 0.37306, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 41/75\n",
      "12592/12592 [==============================] - 1s 73us/step - loss: 0.4573 - acc: 0.8154 - val_loss: 0.3716 - val_acc: 0.8688\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.37306 to 0.37159, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 42/75\n",
      "12592/12592 [==============================] - 1s 68us/step - loss: 0.4563 - acc: 0.8193 - val_loss: 0.3702 - val_acc: 0.8701\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.37159 to 0.37017, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 43/75\n",
      "12592/12592 [==============================] - 1s 68us/step - loss: 0.4589 - acc: 0.8186 - val_loss: 0.3667 - val_acc: 0.8742\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.37017 to 0.36668, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 44/75\n",
      "12592/12592 [==============================] - 1s 73us/step - loss: 0.4474 - acc: 0.8260 - val_loss: 0.3650 - val_acc: 0.8729\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.36668 to 0.36505, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 45/75\n",
      "12592/12592 [==============================] - 1s 72us/step - loss: 0.4413 - acc: 0.8266 - val_loss: 0.3623 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.36505 to 0.36230, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 46/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.4435 - acc: 0.8253 - val_loss: 0.3638 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.36230\n",
      "Epoch 47/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.4348 - acc: 0.8303 - val_loss: 0.3616 - val_acc: 0.8704\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.36230 to 0.36158, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 48/75\n",
      "12592/12592 [==============================] - 1s 74us/step - loss: 0.4339 - acc: 0.8264 - val_loss: 0.3507 - val_acc: 0.8809\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.36158 to 0.35070, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 49/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.4335 - acc: 0.8294 - val_loss: 0.3541 - val_acc: 0.8787\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.35070\n",
      "Epoch 50/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.4309 - acc: 0.8323 - val_loss: 0.3504 - val_acc: 0.8771\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.35070 to 0.35043, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 51/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.4274 - acc: 0.8326 - val_loss: 0.3507 - val_acc: 0.8799\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.35043\n",
      "Epoch 52/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.4256 - acc: 0.8342 - val_loss: 0.3463 - val_acc: 0.8818\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.35043 to 0.34628, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 53/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.4241 - acc: 0.8331 - val_loss: 0.3462 - val_acc: 0.8834\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.34628 to 0.34615, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 54/75\n",
      "12592/12592 [==============================] - 1s 85us/step - loss: 0.4189 - acc: 0.8384 - val_loss: 0.3389 - val_acc: 0.8942\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.34615 to 0.33887, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 55/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.4213 - acc: 0.8398 - val_loss: 0.3383 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.33887 to 0.33832, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 56/75\n",
      "12592/12592 [==============================] - 1s 89us/step - loss: 0.4206 - acc: 0.8400 - val_loss: 0.3439 - val_acc: 0.8815\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.33832\n",
      "Epoch 57/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.4144 - acc: 0.8411 - val_loss: 0.3330 - val_acc: 0.8936\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.33832 to 0.33295, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 58/75\n",
      "12592/12592 [==============================] - 1s 77us/step - loss: 0.4106 - acc: 0.8479 - val_loss: 0.3340 - val_acc: 0.8914\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33295\n",
      "Epoch 59/75\n",
      "12592/12592 [==============================] - 1s 73us/step - loss: 0.4110 - acc: 0.8408 - val_loss: 0.3329 - val_acc: 0.8869\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.33295 to 0.33288, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 60/75\n",
      "12592/12592 [==============================] - 1s 83us/step - loss: 0.4052 - acc: 0.8417 - val_loss: 0.3326 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.33288 to 0.33255, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 61/75\n",
      "12592/12592 [==============================] - 1s 82us/step - loss: 0.4071 - acc: 0.8438 - val_loss: 0.3276 - val_acc: 0.8926\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.33255 to 0.32756, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 62/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.4086 - acc: 0.8421 - val_loss: 0.3266 - val_acc: 0.8898\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.32756 to 0.32665, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 63/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.4018 - acc: 0.8474 - val_loss: 0.3267 - val_acc: 0.8882\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32665\n",
      "Epoch 64/75\n",
      "12592/12592 [==============================] - 1s 81us/step - loss: 0.3981 - acc: 0.8520 - val_loss: 0.3220 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.32665 to 0.32200, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 65/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.3987 - acc: 0.8450 - val_loss: 0.3238 - val_acc: 0.8907\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32200\n",
      "Epoch 66/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.3967 - acc: 0.8486 - val_loss: 0.3194 - val_acc: 0.8929\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.32200 to 0.31942, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 67/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.3941 - acc: 0.8517 - val_loss: 0.3203 - val_acc: 0.8920\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.31942\n",
      "Epoch 68/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.3924 - acc: 0.8528 - val_loss: 0.3157 - val_acc: 0.8990\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.31942 to 0.31573, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 69/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.3919 - acc: 0.8547 - val_loss: 0.3167 - val_acc: 0.8971\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.31573\n",
      "Epoch 70/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.3937 - acc: 0.8497 - val_loss: 0.3128 - val_acc: 0.9003\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.31573 to 0.31277, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 71/75\n",
      "12592/12592 [==============================] - 1s 83us/step - loss: 0.3885 - acc: 0.8548 - val_loss: 0.3083 - val_acc: 0.9012\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.31277 to 0.30832, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n",
      "Epoch 72/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.3876 - acc: 0.8529 - val_loss: 0.3101 - val_acc: 0.8996\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.30832\n",
      "Epoch 73/75\n",
      "12592/12592 [==============================] - 1s 83us/step - loss: 0.3860 - acc: 0.8548 - val_loss: 0.3108 - val_acc: 0.8949\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.30832\n",
      "Epoch 74/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.3867 - acc: 0.8559 - val_loss: 0.3092 - val_acc: 0.9009\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.30832\n",
      "Epoch 75/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.3876 - acc: 0.8518 - val_loss: 0.3032 - val_acc: 0.9079\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.30832 to 0.30324, saving model to saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b85563048>"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nonulls_DEFAULT.fit(Xtrain_nonulls, Ytrain_nonulls, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nonulls_DEFAULT.load_weights('saved_models/weights.best.mlp_nonulls_DEFAULT.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 96.6277%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nonulls_DEFAULT.evaluate(Xtest_nonulls, Ytest_nonulls, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.5000.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nonulls_DEFAULT = mlp_nonulls_DEFAULT.predict(Xtest_nonulls)\n",
    "mlp_nonulls_ROC_DEFAULT = roc_auc_score(Ytest_nonulls, Ypred_nonulls_DEFAULT)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nonulls_ROC_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary library for the ROC Curve.\n",
    "from sklearn import metrics\n",
    "\n",
    "def roc_plot(model, x_test, y_test, title):\n",
    "    '''\n",
    "    This function plots ROC curves. It takes in\n",
    "    the model, title, x_test, y_test as arguments.\n",
    "    '''\n",
    "    # This sets the size of the plot\n",
    "    # This comes from Reference 12 in References\n",
    "    plt.figure(figsize=(6.0,6.0))\n",
    "    \n",
    "    # This finds the predicted values of y from the x_test\n",
    "    # data.\n",
    "    # This comes from Reference 11 in References.\n",
    "    pred_probs = model.predict_proba(x_test)\n",
    "    \n",
    "    # This finds the false and true positive rates for\n",
    "    # the ROC Curve.\n",
    "    # This comes from Reference 11 in References.\n",
    "    fpr, tpr, _ = metrics.roc_curve(y_test, pred_probs)\n",
    "    \n",
    "    # This finds the AUC score.\n",
    "    # This comes from Reference 11 in References.\n",
    "    auc = metrics.roc_auc_score(y_test, pred_probs)\n",
    "    auc = str(auc)\n",
    "    auc = auc[0:6]\n",
    "    \n",
    "    # This plots the ROC Curve with the AUC label.\n",
    "    plt.plot(fpr,tpr,label='auc: ' + auc)\n",
    "    plt.legend(loc=4)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_nonulls_DEFAULT, x_test=Xtest_nonulls,\n",
    "        y_test=Ytest_nonulls,title=\"ROC: MLP No Nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model No Nulls Final\n",
    "This model is the final MLP No Nulls Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for No NULLS.\n",
    "mlp_nonulls = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nonulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Nulls data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nonulls.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nonulls.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12592 samples, validate on 3148 samples\n",
      "Epoch 1/75\n",
      "12592/12592 [==============================] - 3s 267us/step - loss: 0.8004 - acc: 0.5268 - val_loss: 0.7558 - val_acc: 0.5915\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.75576, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 2/75\n",
      "12592/12592 [==============================] - 1s 81us/step - loss: 0.7943 - acc: 0.5328 - val_loss: 0.7526 - val_acc: 0.6064\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.75576 to 0.75262, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 3/75\n",
      "12592/12592 [==============================] - 1s 90us/step - loss: 0.7837 - acc: 0.5361 - val_loss: 0.7505 - val_acc: 0.6172\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.75262 to 0.75054, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 4/75\n",
      "12592/12592 [==============================] - 1s 96us/step - loss: 0.7823 - acc: 0.5417 - val_loss: 0.7489 - val_acc: 0.6223\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.75054 to 0.74894, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 5/75\n",
      "12592/12592 [==============================] - 1s 93us/step - loss: 0.7737 - acc: 0.5462 - val_loss: 0.7472 - val_acc: 0.6321\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74894 to 0.74721, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 6/75\n",
      "12592/12592 [==============================] - 1s 86us/step - loss: 0.7780 - acc: 0.5392 - val_loss: 0.7458 - val_acc: 0.6391\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74721 to 0.74575, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 7/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.7704 - acc: 0.5574 - val_loss: 0.7442 - val_acc: 0.6464\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.74575 to 0.74416, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 8/75\n",
      "12592/12592 [==============================] - 1s 84us/step - loss: 0.7682 - acc: 0.5470 - val_loss: 0.7430 - val_acc: 0.6537\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.74416 to 0.74302, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 9/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.7676 - acc: 0.5572 - val_loss: 0.7419 - val_acc: 0.6630\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.74302 to 0.74185, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 10/75\n",
      "12592/12592 [==============================] - 1s 82us/step - loss: 0.7620 - acc: 0.5549 - val_loss: 0.7406 - val_acc: 0.6680\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.74185 to 0.74057, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 11/75\n",
      "12592/12592 [==============================] - 1s 85us/step - loss: 0.7620 - acc: 0.5566 - val_loss: 0.7394 - val_acc: 0.6773\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.74057 to 0.73939, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 12/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.7597 - acc: 0.5673 - val_loss: 0.7383 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.73939 to 0.73828, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 13/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7595 - acc: 0.5643 - val_loss: 0.7372 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.73828 to 0.73724, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 14/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7511 - acc: 0.5753 - val_loss: 0.7358 - val_acc: 0.6903\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.73724 to 0.73578, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 15/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.7511 - acc: 0.5777 - val_loss: 0.7343 - val_acc: 0.6938\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.73578 to 0.73433, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 16/75\n",
      "12592/12592 [==============================] - 1s 84us/step - loss: 0.7481 - acc: 0.5723 - val_loss: 0.7329 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.73433 to 0.73285, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 17/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.7504 - acc: 0.5858 - val_loss: 0.7314 - val_acc: 0.7024\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.73285 to 0.73143, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 18/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7525 - acc: 0.5823 - val_loss: 0.7300 - val_acc: 0.7052\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.73143 to 0.73003, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 19/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7486 - acc: 0.5898 - val_loss: 0.7286 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.73003 to 0.72863, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 20/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7477 - acc: 0.5882 - val_loss: 0.7271 - val_acc: 0.7106\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.72863 to 0.72708, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 21/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7455 - acc: 0.5898 - val_loss: 0.7255 - val_acc: 0.7147\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.72708 to 0.72550, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 22/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.7459 - acc: 0.5951 - val_loss: 0.7241 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.72550 to 0.72406, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 23/75\n",
      "12592/12592 [==============================] - ETA: 0s - loss: 0.7453 - acc: 0.591 - 1s 76us/step - loss: 0.7454 - acc: 0.5913 - val_loss: 0.7227 - val_acc: 0.7192\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.72406 to 0.72268, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 24/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7381 - acc: 0.5955 - val_loss: 0.7209 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.72268 to 0.72085, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 25/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7387 - acc: 0.6003 - val_loss: 0.7192 - val_acc: 0.7195\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.72085 to 0.71916, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 26/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7400 - acc: 0.5951 - val_loss: 0.7175 - val_acc: 0.7236\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.71916 to 0.71749, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 27/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7364 - acc: 0.6032 - val_loss: 0.7155 - val_acc: 0.7233\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.71749 to 0.71554, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 28/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7332 - acc: 0.6082 - val_loss: 0.7134 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.71554 to 0.71343, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 29/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7337 - acc: 0.6123 - val_loss: 0.7117 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.71343 to 0.71170, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 30/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7340 - acc: 0.6108 - val_loss: 0.7097 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.71170 to 0.70971, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 31/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7309 - acc: 0.6090 - val_loss: 0.7079 - val_acc: 0.7284\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.70971 to 0.70792, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 32/75\n",
      "12592/12592 [==============================] - 1s 83us/step - loss: 0.7311 - acc: 0.6190 - val_loss: 0.7062 - val_acc: 0.7287\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.70792 to 0.70619, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/75\n",
      "12592/12592 [==============================] - 1s 93us/step - loss: 0.7296 - acc: 0.6105 - val_loss: 0.7045 - val_acc: 0.7316\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.70619 to 0.70451, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 34/75\n",
      "12592/12592 [==============================] - 1s 85us/step - loss: 0.7258 - acc: 0.6139 - val_loss: 0.7027 - val_acc: 0.7360\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.70451 to 0.70272, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 35/75\n",
      "12592/12592 [==============================] - 1s 90us/step - loss: 0.7259 - acc: 0.6207 - val_loss: 0.7008 - val_acc: 0.7370\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.70272 to 0.70080, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 36/75\n",
      "12592/12592 [==============================] - 1s 84us/step - loss: 0.7232 - acc: 0.6201 - val_loss: 0.6987 - val_acc: 0.7386\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.70080 to 0.69873, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 37/75\n",
      "12592/12592 [==============================] - 1s 82us/step - loss: 0.7198 - acc: 0.6244 - val_loss: 0.6966 - val_acc: 0.7392\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.69873 to 0.69655, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 38/75\n",
      "12592/12592 [==============================] - 1s 86us/step - loss: 0.7229 - acc: 0.6247 - val_loss: 0.6945 - val_acc: 0.7408\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.69655 to 0.69454, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 39/75\n",
      "12592/12592 [==============================] - 1s 88us/step - loss: 0.7220 - acc: 0.6209 - val_loss: 0.6929 - val_acc: 0.7421\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.69454 to 0.69289, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 40/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7205 - acc: 0.6228 - val_loss: 0.6907 - val_acc: 0.7411\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.69289 to 0.69070, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 41/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7185 - acc: 0.6252 - val_loss: 0.6888 - val_acc: 0.7430\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.69070 to 0.68880, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 42/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7134 - acc: 0.6292 - val_loss: 0.6864 - val_acc: 0.7424\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.68880 to 0.68645, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 43/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7134 - acc: 0.6373 - val_loss: 0.6844 - val_acc: 0.7443\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.68645 to 0.68436, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 44/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7131 - acc: 0.6315 - val_loss: 0.6822 - val_acc: 0.7462\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.68436 to 0.68219, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 45/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7098 - acc: 0.6345 - val_loss: 0.6801 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.68219 to 0.68011, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 46/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7056 - acc: 0.6372 - val_loss: 0.6779 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.68011 to 0.67787, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 47/75\n",
      "12592/12592 [==============================] - 1s 74us/step - loss: 0.7068 - acc: 0.6344 - val_loss: 0.6756 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.67787 to 0.67556, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 48/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7132 - acc: 0.6337 - val_loss: 0.6737 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.67556 to 0.67370, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 49/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7031 - acc: 0.6386 - val_loss: 0.6711 - val_acc: 0.7487\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.67370 to 0.67108, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 50/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7030 - acc: 0.6391 - val_loss: 0.6688 - val_acc: 0.7494\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.67108 to 0.66878, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 51/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.7044 - acc: 0.6456 - val_loss: 0.6669 - val_acc: 0.7487\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.66878 to 0.66691, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 52/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6988 - acc: 0.6406 - val_loss: 0.6648 - val_acc: 0.7484\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.66691 to 0.66476, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 53/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6993 - acc: 0.6452 - val_loss: 0.6625 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.66476 to 0.66249, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 54/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.7032 - acc: 0.6477 - val_loss: 0.6606 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.66249 to 0.66064, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 55/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6981 - acc: 0.6466 - val_loss: 0.6588 - val_acc: 0.7516\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.66064 to 0.65884, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 56/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.6961 - acc: 0.6525 - val_loss: 0.6567 - val_acc: 0.7522\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.65884 to 0.65674, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 57/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6958 - acc: 0.6513 - val_loss: 0.6549 - val_acc: 0.7535\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.65674 to 0.65489, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 58/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6925 - acc: 0.6590 - val_loss: 0.6528 - val_acc: 0.7541\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.65489 to 0.65279, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 59/75\n",
      "12592/12592 [==============================] - 1s 78us/step - loss: 0.6902 - acc: 0.6542 - val_loss: 0.6509 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.65279 to 0.65090, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 60/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.6944 - acc: 0.6539 - val_loss: 0.6495 - val_acc: 0.7564\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.65090 to 0.64948, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 61/75\n",
      "12592/12592 [==============================] - 1s 76us/step - loss: 0.6909 - acc: 0.6556 - val_loss: 0.6473 - val_acc: 0.7570\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.64948 to 0.64733, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 62/75\n",
      "12592/12592 [==============================] - 1s 75us/step - loss: 0.6860 - acc: 0.6541 - val_loss: 0.6451 - val_acc: 0.7567\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.64733 to 0.64514, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 63/75\n",
      "12592/12592 [==============================] - 1s 77us/step - loss: 0.6843 - acc: 0.6597 - val_loss: 0.6431 - val_acc: 0.7557\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.64514 to 0.64305, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 64/75\n",
      "12592/12592 [==============================] - 1s 77us/step - loss: 0.6826 - acc: 0.6606 - val_loss: 0.6411 - val_acc: 0.7554\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.64305 to 0.64111, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 65/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12592/12592 [==============================] - 1s 88us/step - loss: 0.6858 - acc: 0.6597 - val_loss: 0.6394 - val_acc: 0.7576\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.64111 to 0.63944, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 66/75\n",
      "12592/12592 [==============================] - 1s 85us/step - loss: 0.6820 - acc: 0.6626 - val_loss: 0.6378 - val_acc: 0.7583\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.63944 to 0.63777, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 67/75\n",
      "12592/12592 [==============================] - 1s 84us/step - loss: 0.6816 - acc: 0.6652 - val_loss: 0.6359 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.63777 to 0.63589, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 68/75\n",
      "12592/12592 [==============================] - 1s 86us/step - loss: 0.6816 - acc: 0.6673 - val_loss: 0.6341 - val_acc: 0.7595\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.63589 to 0.63411, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 69/75\n",
      "12592/12592 [==============================] - 1s 83us/step - loss: 0.6734 - acc: 0.6692 - val_loss: 0.6322 - val_acc: 0.7579\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.63411 to 0.63218, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 70/75\n",
      "12592/12592 [==============================] - 1s 82us/step - loss: 0.6829 - acc: 0.6626 - val_loss: 0.6310 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.63218 to 0.63101, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 71/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.6769 - acc: 0.6568 - val_loss: 0.6292 - val_acc: 0.7586\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.63101 to 0.62916, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 72/75\n",
      "12592/12592 [==============================] - 1s 81us/step - loss: 0.6759 - acc: 0.6636 - val_loss: 0.6276 - val_acc: 0.7589\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.62916 to 0.62756, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 73/75\n",
      "12592/12592 [==============================] - 1s 85us/step - loss: 0.6782 - acc: 0.6661 - val_loss: 0.6261 - val_acc: 0.7602\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.62756 to 0.62606, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 74/75\n",
      "12592/12592 [==============================] - 1s 79us/step - loss: 0.6733 - acc: 0.6745 - val_loss: 0.6243 - val_acc: 0.7598\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.62606 to 0.62429, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 75/75\n",
      "12592/12592 [==============================] - 1s 80us/step - loss: 0.6650 - acc: 0.6730 - val_loss: 0.6219 - val_acc: 0.7605\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.62429 to 0.62193, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b85c17390>"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nonulls.fit(Xtrain_nonulls, Ytrain_nonulls, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nonulls.load_weights('saved_models/weights.best.mlp_nonulls.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 87.8464%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nonulls.evaluate(Xtest_nonulls, Ytest_nonulls, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.5890.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nonulls = mlp_nonulls.predict(Xtest_nonulls)\n",
    "mlp_nonulls_ROC = roc_auc_score(Ytest_nonulls, Ypred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nonulls_ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_nonulls, x_test=Xtest_nonulls,\n",
    "        y_test=Ytest_nonulls,title=\"ROC: MLP No Nulls\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Nulls Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Nulls Only, default learning rate in Stochastic Gradient Loss Optimizer\n",
    "This is a comparison MLP model that uses the default learning rate of 0.01 to descend down the loss gradient in an attempt to find the global minimum (Reference 14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "DEFAULT_stochastic = SGD()\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for Nulls Only.\n",
    "mlp_nullsonly_DEFAULT = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nullsonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the Nulls Only data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nullsonly_DEFAULT.compile(loss='binary_crossentropy',\n",
    "              optimizer= DEFAULT_stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 7s 125us/step - loss: 0.7574 - acc: 0.5874 - val_loss: 0.6973 - val_acc: 0.6956\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.69728, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 73us/step - loss: 0.7235 - acc: 0.6290 - val_loss: 0.6755 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.69728 to 0.67552, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 72us/step - loss: 0.7099 - acc: 0.6392 - val_loss: 0.6660 - val_acc: 0.7005\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67552 to 0.66599, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 72us/step - loss: 0.7008 - acc: 0.6480 - val_loss: 0.6544 - val_acc: 0.7028\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66599 to 0.65442, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 71us/step - loss: 0.6925 - acc: 0.6494 - val_loss: 0.6443 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.65442 to 0.64429, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 4s 72us/step - loss: 0.6831 - acc: 0.6561 - val_loss: 0.6367 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.64429 to 0.63670, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 4s 69us/step - loss: 0.6744 - acc: 0.6638 - val_loss: 0.6275 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.63670 to 0.62754, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 4s 70us/step - loss: 0.6658 - acc: 0.6675 - val_loss: 0.6171 - val_acc: 0.7275\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.62754 to 0.61707, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 4s 69us/step - loss: 0.6597 - acc: 0.6742 - val_loss: 0.6109 - val_acc: 0.7341\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.61707 to 0.61085, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 4s 74us/step - loss: 0.6535 - acc: 0.6825 - val_loss: 0.6029 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.61085 to 0.60288, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.6479 - acc: 0.6860 - val_loss: 0.5979 - val_acc: 0.7476\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.60288 to 0.59789, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.6418 - acc: 0.6910 - val_loss: 0.5896 - val_acc: 0.7407\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.59789 to 0.58961, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6368 - acc: 0.6958 - val_loss: 0.5838 - val_acc: 0.7486\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.58961 to 0.58382, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6342 - acc: 0.7007 - val_loss: 0.5806 - val_acc: 0.7560\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.58382 to 0.58062, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6286 - acc: 0.7039 - val_loss: 0.5786 - val_acc: 0.7541\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.58062 to 0.57860, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6267 - acc: 0.7033 - val_loss: 0.5724 - val_acc: 0.7568\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.57860 to 0.57237, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6234 - acc: 0.7059 - val_loss: 0.5724 - val_acc: 0.7591\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.57237\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6201 - acc: 0.7088 - val_loss: 0.5661 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.57237 to 0.56608, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.6163 - acc: 0.7111 - val_loss: 0.5633 - val_acc: 0.7607\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.56608 to 0.56331, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6102 - acc: 0.7158 - val_loss: 0.5592 - val_acc: 0.7618\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.56331 to 0.55917, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6098 - acc: 0.7167 - val_loss: 0.5576 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.55917 to 0.55758, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6032 - acc: 0.7182 - val_loss: 0.5564 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.55758 to 0.55641, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6034 - acc: 0.7200 - val_loss: 0.5525 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.55641 to 0.55247, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6028 - acc: 0.7192 - val_loss: 0.5491 - val_acc: 0.7643\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.55247 to 0.54914, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6018 - acc: 0.7217 - val_loss: 0.5468 - val_acc: 0.7678\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.54914 to 0.54685, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.5976 - acc: 0.7216 - val_loss: 0.5448 - val_acc: 0.7684\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.54685 to 0.54476, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5987 - acc: 0.7225 - val_loss: 0.5519 - val_acc: 0.7645\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.54476\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.5951 - acc: 0.7246 - val_loss: 0.5415 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.54476 to 0.54147, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5947 - acc: 0.7251 - val_loss: 0.5448 - val_acc: 0.7697\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.54147\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5896 - acc: 0.7279 - val_loss: 0.5378 - val_acc: 0.7745\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.54147 to 0.53783, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5915 - acc: 0.7275 - val_loss: 0.5343 - val_acc: 0.7753\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.53783 to 0.53434, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5896 - acc: 0.7271 - val_loss: 0.5328 - val_acc: 0.7736\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.53434 to 0.53277, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 33/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5855 - acc: 0.7297 - val_loss: 0.5329 - val_acc: 0.7694\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.53277\n",
      "Epoch 34/75\n",
      "52409/52409 [==============================] - 4s 76us/step - loss: 0.5841 - acc: 0.7285 - val_loss: 0.5288 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.53277 to 0.52880, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 4s 76us/step - loss: 0.5797 - acc: 0.7320 - val_loss: 0.5217 - val_acc: 0.7804\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.52880 to 0.52166, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.5815 - acc: 0.7327 - val_loss: 0.5309 - val_acc: 0.7853\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.52166\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.5815 - acc: 0.7325 - val_loss: 0.5260 - val_acc: 0.7867\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.52166\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 4s 76us/step - loss: 0.5788 - acc: 0.7329 - val_loss: 0.5334 - val_acc: 0.7694\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.52166\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 4s 76us/step - loss: 0.5776 - acc: 0.7336 - val_loss: 0.5196 - val_acc: 0.7858\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.52166 to 0.51959, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.5758 - acc: 0.7369 - val_loss: 0.5373 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.51959\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5762 - acc: 0.7336 - val_loss: 0.5167 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.51959 to 0.51668, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.5727 - acc: 0.7380 - val_loss: 0.5182 - val_acc: 0.7679\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.51668\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 4s 76us/step - loss: 0.5716 - acc: 0.7397 - val_loss: 0.5163 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.51668 to 0.51626, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5697 - acc: 0.7394 - val_loss: 0.5380 - val_acc: 0.7603\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.51626\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.5687 - acc: 0.7394 - val_loss: 0.5083 - val_acc: 0.7987\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.51626 to 0.50834, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5674 - acc: 0.7431 - val_loss: 0.5098 - val_acc: 0.7953\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.50834\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5673 - acc: 0.7419 - val_loss: 0.5035 - val_acc: 0.7945\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.50834 to 0.50354, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5663 - acc: 0.7433 - val_loss: 0.5826 - val_acc: 0.6920\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.50354\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5654 - acc: 0.7424 - val_loss: 0.5179 - val_acc: 0.7895\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.50354\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5628 - acc: 0.7436 - val_loss: 0.5162 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.50354\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5619 - acc: 0.7453 - val_loss: 0.4990 - val_acc: 0.7982\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.50354 to 0.49896, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5620 - acc: 0.7466 - val_loss: 0.5009 - val_acc: 0.8067\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.49896\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5594 - acc: 0.7482 - val_loss: 0.5034 - val_acc: 0.7997\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.49896\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5626 - acc: 0.7490 - val_loss: 0.4953 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.49896 to 0.49527, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5569 - acc: 0.7499 - val_loss: 0.5078 - val_acc: 0.7847\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.49527\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5572 - acc: 0.7494 - val_loss: 0.4935 - val_acc: 0.8088\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.49527 to 0.49350, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5577 - acc: 0.7509 - val_loss: 0.4980 - val_acc: 0.8063\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.49350\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5580 - acc: 0.7495 - val_loss: 0.4880 - val_acc: 0.8045\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.49350 to 0.48800, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5576 - acc: 0.7499 - val_loss: 0.4905 - val_acc: 0.8140\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.48800\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5531 - acc: 0.7539 - val_loss: 0.4883 - val_acc: 0.8020\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.48800\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5545 - acc: 0.7525 - val_loss: 0.5243 - val_acc: 0.7498\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.48800\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5529 - acc: 0.7537 - val_loss: 0.4952 - val_acc: 0.7866\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.48800\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5582 - acc: 0.7545 - val_loss: 0.4938 - val_acc: 0.7849\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.48800\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5535 - acc: 0.7540 - val_loss: 0.4948 - val_acc: 0.8118\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.48800\n",
      "Epoch 65/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.5506 - acc: 0.7552 - val_loss: 0.4770 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.48800 to 0.47698, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5506 - acc: 0.7559 - val_loss: 0.5120 - val_acc: 0.7627\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.47698\n",
      "Epoch 67/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.5524 - acc: 0.7569 - val_loss: 0.4850 - val_acc: 0.8111\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.47698\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5504 - acc: 0.7609 - val_loss: 0.4717 - val_acc: 0.8130\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.47698 to 0.47170, saving model to saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5530 - acc: 0.7587 - val_loss: 0.5621 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.47170\n",
      "Epoch 70/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5559 - acc: 0.7525 - val_loss: 0.4819 - val_acc: 0.8015\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.47170\n",
      "Epoch 71/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.5505 - acc: 0.7570 - val_loss: 0.4904 - val_acc: 0.8100\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.47170\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5479 - acc: 0.7579 - val_loss: 0.5192 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.47170\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5473 - acc: 0.7601 - val_loss: 0.4904 - val_acc: 0.8005\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.47170\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5463 - acc: 0.7627 - val_loss: 0.4913 - val_acc: 0.7978\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.47170\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.5526 - acc: 0.7563 - val_loss: 0.4853 - val_acc: 0.8112\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.47170\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b88ef9438>"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nullsonly_DEFAULT.fit(Xtrain_nullsonly, Ytrain_nullsonly, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nullsonly_DEFAULT.load_weights('saved_models/weights.best.mlp_nullsonly_DEFAULT.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 89.7496%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nullsonly_DEFAULT.evaluate(Xtest_nullsonly, Ytest_nullsonly, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.3151.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nullsonly_DEFAULT= mlp_nullsonly_DEFAULT.predict(Xtest_nullsonly)\n",
    "mlp_nullsonly_ROC_DEFAULT = roc_auc_score(Ytest_nullsonly, Ypred_nullsonly_DEFAULT)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nullsonly_ROC_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_nullsonly_DEFAULT, x_test=Xtest_nullsonly,\n",
    "        y_test=Ytest_nullsonly,title=\"ROC: MLP Nulls Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Nulls Only Final Model\n",
    "This is the only model in which the the higher learning rate resulted in a higher AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for Nulls Only.\n",
    "mlp_nullsonly = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nullsonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the Nulls Only data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nullsonly.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nullsonly.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 6s 116us/step - loss: 0.7809 - acc: 0.5059 - val_loss: 0.7655 - val_acc: 0.6433\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76545, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 71us/step - loss: 0.7717 - acc: 0.5361 - val_loss: 0.7609 - val_acc: 0.6576\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76545 to 0.76087, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 73us/step - loss: 0.7646 - acc: 0.5596 - val_loss: 0.7559 - val_acc: 0.6695\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76087 to 0.75586, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 70us/step - loss: 0.7605 - acc: 0.5823 - val_loss: 0.7504 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.75586 to 0.75041, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 71us/step - loss: 0.7565 - acc: 0.5875 - val_loss: 0.7449 - val_acc: 0.6834\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75041 to 0.74489, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 4s 71us/step - loss: 0.7523 - acc: 0.5929 - val_loss: 0.7396 - val_acc: 0.6852\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74489 to 0.73956, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 4s 71us/step - loss: 0.7485 - acc: 0.5997 - val_loss: 0.7341 - val_acc: 0.6854\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73956 to 0.73411, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 4s 72us/step - loss: 0.7451 - acc: 0.6029 - val_loss: 0.7292 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.73411 to 0.72916, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7398 - acc: 0.6080 - val_loss: 0.7240 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.72916 to 0.72401, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7394 - acc: 0.6072 - val_loss: 0.7192 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.72401 to 0.71920, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7360 - acc: 0.6101 - val_loss: 0.7149 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.71920 to 0.71486, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7349 - acc: 0.6109 - val_loss: 0.7107 - val_acc: 0.6876\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71486 to 0.71074, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7305 - acc: 0.6156 - val_loss: 0.7068 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.71074 to 0.70676, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7273 - acc: 0.6165 - val_loss: 0.7029 - val_acc: 0.6888\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.70676 to 0.70295, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7275 - acc: 0.6167 - val_loss: 0.6998 - val_acc: 0.6892\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.70295 to 0.69984, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7233 - acc: 0.6191 - val_loss: 0.6968 - val_acc: 0.6896\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.69984 to 0.69677, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.7235 - acc: 0.6203 - val_loss: 0.6944 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.69677 to 0.69436, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7198 - acc: 0.6270 - val_loss: 0.6916 - val_acc: 0.6905\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.69436 to 0.69159, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7202 - acc: 0.6242 - val_loss: 0.6896 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.69159 to 0.68960, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7180 - acc: 0.6273 - val_loss: 0.6871 - val_acc: 0.6909\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.68960 to 0.68710, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.7179 - acc: 0.6307 - val_loss: 0.6854 - val_acc: 0.6917\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.68710 to 0.68538, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7162 - acc: 0.6332 - val_loss: 0.6841 - val_acc: 0.6925\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68538 to 0.68408, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.7162 - acc: 0.6348 - val_loss: 0.6826 - val_acc: 0.6926\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.68408 to 0.68265, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7132 - acc: 0.6358 - val_loss: 0.6809 - val_acc: 0.6923\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.68265 to 0.68089, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7136 - acc: 0.6353 - val_loss: 0.6798 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.68089 to 0.67980, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 4s 86us/step - loss: 0.7134 - acc: 0.6368 - val_loss: 0.6781 - val_acc: 0.6930\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67980 to 0.67810, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7119 - acc: 0.6403 - val_loss: 0.6768 - val_acc: 0.6934\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.67810 to 0.67678, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.7079 - acc: 0.6416 - val_loss: 0.6750 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.67678 to 0.67499, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7084 - acc: 0.6380 - val_loss: 0.6741 - val_acc: 0.6940\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.67499 to 0.67405, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7072 - acc: 0.6441 - val_loss: 0.6728 - val_acc: 0.6942\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.67405 to 0.67277, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7083 - acc: 0.6454 - val_loss: 0.6719 - val_acc: 0.6943\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.67277 to 0.67191, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7069 - acc: 0.6473 - val_loss: 0.6707 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.67191 to 0.67073, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 33/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7055 - acc: 0.6464 - val_loss: 0.6693 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.67073 to 0.66934, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 34/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7047 - acc: 0.6487 - val_loss: 0.6684 - val_acc: 0.6956\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.66934 to 0.66839, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.7024 - acc: 0.6483 - val_loss: 0.6674 - val_acc: 0.6956\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.66839 to 0.66741, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.7012 - acc: 0.6502 - val_loss: 0.6663 - val_acc: 0.6959\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.66741 to 0.66633, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7027 - acc: 0.6484 - val_loss: 0.6656 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.66633 to 0.66558, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6996 - acc: 0.6507 - val_loss: 0.6646 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.66558 to 0.66459, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6993 - acc: 0.6503 - val_loss: 0.6632 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.66459 to 0.66317, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6970 - acc: 0.6522 - val_loss: 0.6619 - val_acc: 0.6964\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.66317 to 0.66195, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7004 - acc: 0.6506 - val_loss: 0.6616 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.66195 to 0.66155, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6989 - acc: 0.6530 - val_loss: 0.6608 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.66155 to 0.66078, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6975 - acc: 0.6525 - val_loss: 0.6600 - val_acc: 0.6962\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.66078 to 0.66005, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6961 - acc: 0.6542 - val_loss: 0.6591 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.66005 to 0.65911, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6951 - acc: 0.6542 - val_loss: 0.6581 - val_acc: 0.6965\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.65911 to 0.65813, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6947 - acc: 0.6556 - val_loss: 0.6574 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.65813 to 0.65745, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6935 - acc: 0.6566 - val_loss: 0.6565 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.65745 to 0.65652, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6912 - acc: 0.6581 - val_loss: 0.6555 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.65652 to 0.65550, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6925 - acc: 0.6589 - val_loss: 0.6545 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.65550 to 0.65449, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6935 - acc: 0.6553 - val_loss: 0.6540 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.65449 to 0.65400, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6922 - acc: 0.6564 - val_loss: 0.6536 - val_acc: 0.6972\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.65400 to 0.65361, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6886 - acc: 0.6590 - val_loss: 0.6528 - val_acc: 0.6971\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.65361 to 0.65276, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6882 - acc: 0.6557 - val_loss: 0.6519 - val_acc: 0.6974\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.65276 to 0.65187, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6900 - acc: 0.6583 - val_loss: 0.6511 - val_acc: 0.6982\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.65187 to 0.65105, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.6870 - acc: 0.6608 - val_loss: 0.6501 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.65105 to 0.65012, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6869 - acc: 0.6608 - val_loss: 0.6491 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.65012 to 0.64907, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6866 - acc: 0.6616 - val_loss: 0.6483 - val_acc: 0.6990\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.64907 to 0.64825, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6867 - acc: 0.6597 - val_loss: 0.6477 - val_acc: 0.6986\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.64825 to 0.64766, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6863 - acc: 0.6603 - val_loss: 0.6468 - val_acc: 0.6988\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.64766 to 0.64685, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6841 - acc: 0.6634 - val_loss: 0.6458 - val_acc: 0.6995\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.64685 to 0.64582, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6836 - acc: 0.6633 - val_loss: 0.6449 - val_acc: 0.6999\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.64582 to 0.64494, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6839 - acc: 0.6617 - val_loss: 0.6443 - val_acc: 0.6998\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.64494 to 0.64429, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6815 - acc: 0.6636 - val_loss: 0.6430 - val_acc: 0.7005\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.64429 to 0.64295, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6803 - acc: 0.6636 - val_loss: 0.6422 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.64295 to 0.64218, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 65/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6813 - acc: 0.6650 - val_loss: 0.6415 - val_acc: 0.7003\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.64218 to 0.64145, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.6798 - acc: 0.6639 - val_loss: 0.6406 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.64145 to 0.64060, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 67/75\n",
      "52409/52409 [==============================] - 4s 77us/step - loss: 0.6786 - acc: 0.6644 - val_loss: 0.6395 - val_acc: 0.7013\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.64060 to 0.63954, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6759 - acc: 0.6659 - val_loss: 0.6384 - val_acc: 0.7017\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.63954 to 0.63839, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6817 - acc: 0.6655 - val_loss: 0.6382 - val_acc: 0.7019\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.63839 to 0.63822, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 70/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.6765 - acc: 0.6678 - val_loss: 0.6372 - val_acc: 0.7027\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.63822 to 0.63724, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 71/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6746 - acc: 0.6669 - val_loss: 0.6361 - val_acc: 0.7034\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.63724 to 0.63606, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6767 - acc: 0.6660 - val_loss: 0.6356 - val_acc: 0.7039\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.63606 to 0.63563, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.6749 - acc: 0.6684 - val_loss: 0.6345 - val_acc: 0.7040\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.63563 to 0.63455, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6760 - acc: 0.6670 - val_loss: 0.6339 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.63455 to 0.63394, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6742 - acc: 0.6677 - val_loss: 0.6329 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.63394 to 0.63294, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b87762940>"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nullsonly.fit(Xtrain_nullsonly, Ytrain_nullsonly, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nullsonly.load_weights('saved_models/weights.best.mlp_nullsonly.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 62.2371%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nullsonly.evaluate(Xtest_nullsonly, Ytest_nullsonly, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6703.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nullsonly= mlp_nullsonly.predict(Xtest_nullsonly)\n",
    "mlp_nullsonly_ROC = roc_auc_score(Ytest_nullsonly, Ypred_nullsonly)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nullsonly_ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_nullsonly, x_test=Xtest_nullsonly,\n",
    "        y_test=Ytest_nullsonly,title=\"ROC: MLP Nulls Only\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model One Hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model One Hot, default learning rate in Stochastic Gradient Descent Optimizer.\n",
    "This is a comparison MLP model that uses the default learning rate of 0.01 to descend down the loss gradient in an attempt to find the global minimum (Reference 14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "DEFAULT_stochastic = SGD()\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for One Hot.\n",
    "mlp_onehot_DEFAULT = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=64,\n",
    "                             second_dense=32,\n",
    "                             third_dense=16,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the One Hot data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_onehot_DEFAULT.compile(loss='binary_crossentropy',\n",
    "              optimizer= DEFAULT_stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_onehot_DEFAULT.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 7s 126us/step - loss: 0.7457 - acc: 0.6983 - val_loss: 0.5843 - val_acc: 0.8394\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.58428, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.6212 - acc: 0.7979 - val_loss: 0.5187 - val_acc: 0.8484\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.58428 to 0.51874, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5730 - acc: 0.8217 - val_loss: 0.4967 - val_acc: 0.8544\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.51874 to 0.49673, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5448 - acc: 0.8315 - val_loss: 0.4767 - val_acc: 0.8575\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.49673 to 0.47675, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.5212 - acc: 0.8375 - val_loss: 0.4640 - val_acc: 0.8584\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.47675 to 0.46405, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.5049 - acc: 0.8408 - val_loss: 0.4566 - val_acc: 0.8610\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.46405 to 0.45665, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.4948 - acc: 0.8434 - val_loss: 0.4440 - val_acc: 0.8620\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.45665 to 0.44399, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.4861 - acc: 0.8459 - val_loss: 0.4370 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.44399 to 0.43703, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.4751 - acc: 0.8469 - val_loss: 0.4299 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.43703 to 0.42994, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.4669 - acc: 0.8488 - val_loss: 0.4216 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.42994 to 0.42159, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.4599 - acc: 0.8504 - val_loss: 0.4248 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.42159\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.4525 - acc: 0.8520 - val_loss: 0.4115 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.42159 to 0.41151, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.4479 - acc: 0.8533 - val_loss: 0.4091 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.41151 to 0.40911, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.4401 - acc: 0.8550 - val_loss: 0.4029 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.40911 to 0.40287, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.4357 - acc: 0.8550 - val_loss: 0.3968 - val_acc: 0.8687\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.40287 to 0.39677, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.4292 - acc: 0.8551 - val_loss: 0.3930 - val_acc: 0.8696\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.39677 to 0.39303, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.4288 - acc: 0.8555 - val_loss: 0.3895 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.39303 to 0.38954, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 5s 103us/step - loss: 0.4217 - acc: 0.8565 - val_loss: 0.3859 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.38954 to 0.38586, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.4200 - acc: 0.8574 - val_loss: 0.3818 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.38586 to 0.38176, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.4153 - acc: 0.8578 - val_loss: 0.3781 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.38176 to 0.37808, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.4113 - acc: 0.8574 - val_loss: 0.3746 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.37808 to 0.37460, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.4081 - acc: 0.8577 - val_loss: 0.3749 - val_acc: 0.8703\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.37460\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.4045 - acc: 0.8585 - val_loss: 0.3713 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.37460 to 0.37128, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 5s 98us/step - loss: 0.4022 - acc: 0.8581 - val_loss: 0.3688 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.37128 to 0.36884, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3964 - acc: 0.8608 - val_loss: 0.3660 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.36884 to 0.36605, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3964 - acc: 0.8588 - val_loss: 0.3621 - val_acc: 0.8708\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.36605 to 0.36205, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.3937 - acc: 0.8598 - val_loss: 0.3665 - val_acc: 0.8710\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.36205\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3911 - acc: 0.8608 - val_loss: 0.3573 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.36205 to 0.35729, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.3906 - acc: 0.8606 - val_loss: 0.3579 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.35729\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3887 - acc: 0.8613 - val_loss: 0.3537 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.35729 to 0.35373, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3841 - acc: 0.8617 - val_loss: 0.3553 - val_acc: 0.8721\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.35373\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3822 - acc: 0.8605 - val_loss: 0.3513 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.35373 to 0.35125, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 33/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3823 - acc: 0.8604 - val_loss: 0.3514 - val_acc: 0.8718\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.35125\n",
      "Epoch 34/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.3802 - acc: 0.8603 - val_loss: 0.3491 - val_acc: 0.8720\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.35125 to 0.34908, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 4s 86us/step - loss: 0.3786 - acc: 0.8607 - val_loss: 0.3451 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.34908 to 0.34509, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3786 - acc: 0.8610 - val_loss: 0.3426 - val_acc: 0.8753\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.34509 to 0.34264, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.3740 - acc: 0.8615 - val_loss: 0.3440 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34264\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 5s 99us/step - loss: 0.3736 - acc: 0.8619 - val_loss: 0.3442 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34264\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.3760 - acc: 0.8608 - val_loss: 0.3401 - val_acc: 0.8725\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34264 to 0.34007, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.3721 - acc: 0.8628 - val_loss: 0.3383 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34007 to 0.33830, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.3696 - acc: 0.8628 - val_loss: 0.3404 - val_acc: 0.8732\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.33830\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 5s 96us/step - loss: 0.3667 - acc: 0.8621 - val_loss: 0.3418 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00042: val_loss did not improve from 0.33830\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 5s 96us/step - loss: 0.3669 - acc: 0.8633 - val_loss: 0.3345 - val_acc: 0.8741\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.33830 to 0.33451, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.3661 - acc: 0.8613 - val_loss: 0.3345 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.33451 to 0.33449, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 5s 96us/step - loss: 0.3664 - acc: 0.8624 - val_loss: 0.3315 - val_acc: 0.8743\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.33449 to 0.33149, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 5s 100us/step - loss: 0.3636 - acc: 0.8621 - val_loss: 0.3345 - val_acc: 0.8723\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.33149\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 5s 96us/step - loss: 0.3642 - acc: 0.8614 - val_loss: 0.3311 - val_acc: 0.8750\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.33149 to 0.33113, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 5s 97us/step - loss: 0.3594 - acc: 0.8645 - val_loss: 0.3307 - val_acc: 0.8727\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.33113 to 0.33068, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 5s 96us/step - loss: 0.3596 - acc: 0.8641 - val_loss: 0.3336 - val_acc: 0.8719\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.33068\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3627 - acc: 0.8620 - val_loss: 0.3325 - val_acc: 0.8724\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.33068\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3639 - acc: 0.8620 - val_loss: 0.3314 - val_acc: 0.8737\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.33068\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.3604 - acc: 0.8616 - val_loss: 0.3286 - val_acc: 0.8752\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.33068 to 0.32862, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3604 - acc: 0.8623 - val_loss: 0.3312 - val_acc: 0.8713\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.32862\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3568 - acc: 0.8637 - val_loss: 0.3362 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.32862\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3569 - acc: 0.8624 - val_loss: 0.3266 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.32862 to 0.32656, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3537 - acc: 0.8636 - val_loss: 0.3301 - val_acc: 0.8702\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.32656\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.3556 - acc: 0.8642 - val_loss: 0.3275 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.32656\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3556 - acc: 0.8645 - val_loss: 0.3267 - val_acc: 0.8709\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.32656\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3548 - acc: 0.8637 - val_loss: 0.3229 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.32656 to 0.32294, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3558 - acc: 0.8634 - val_loss: 0.3274 - val_acc: 0.8705\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.32294\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3522 - acc: 0.8645 - val_loss: 0.3208 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.32294 to 0.32076, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3548 - acc: 0.8623 - val_loss: 0.3219 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.32076\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3517 - acc: 0.8638 - val_loss: 0.3244 - val_acc: 0.8738\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.32076\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3529 - acc: 0.8633 - val_loss: 0.3205 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.32076 to 0.32051, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 65/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3520 - acc: 0.8640 - val_loss: 0.3219 - val_acc: 0.8745\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.32051\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.3488 - acc: 0.8655 - val_loss: 0.3191 - val_acc: 0.8756\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.32051 to 0.31907, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 67/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.3488 - acc: 0.8642 - val_loss: 0.3200 - val_acc: 0.8731\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.31907\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3465 - acc: 0.8647 - val_loss: 0.3190 - val_acc: 0.8751\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.31907 to 0.31898, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.3484 - acc: 0.8644 - val_loss: 0.3193 - val_acc: 0.8748\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.31898\n",
      "Epoch 70/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.3508 - acc: 0.8636 - val_loss: 0.3183 - val_acc: 0.8754\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.31898 to 0.31832, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 71/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.3473 - acc: 0.8643 - val_loss: 0.3224 - val_acc: 0.8726\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.31832\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3465 - acc: 0.8651 - val_loss: 0.3174 - val_acc: 0.8763\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.31832 to 0.31741, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.3463 - acc: 0.8646 - val_loss: 0.3185 - val_acc: 0.8755\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.31741\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.3466 - acc: 0.8644 - val_loss: 0.3198 - val_acc: 0.8758\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.31741\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.3459 - acc: 0.8645 - val_loss: 0.3141 - val_acc: 0.8779\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.31741 to 0.31410, saving model to saved_models/weights.best.mlp_onehot_DEFAULT.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b8e6ecdd8>"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_onehot_DEFAULT.fit(Xtrain_onehot, Ytrain_onehot, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_onehot_DEFAULT.load_weights('saved_models/weights.best.mlp_onehot_DEFAULT.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 96.3272%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_onehot_DEFAULT.evaluate(Xtest_onehot, Ytest_onehot, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.4917.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_onehot_DEFAULT = mlp_onehot_DEFAULT.predict(Xtest_onehot)\n",
    "ROC_mlp_onehot_DEFAULT = roc_auc_score(Ytest_onehot, Ypred_onehot_DEFAULT)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_onehot_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_onehot_DEFAULT, x_test=Xtest_onehot,\n",
    "        y_test=Ytest_onehot,title=\"ROC: MLP One Hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model One Hot Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for One Hot.\n",
    "mlp_onehot = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=64,\n",
    "                             second_dense=32,\n",
    "                             third_dense=16,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the One Hot data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_onehot.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_onehot.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 7s 128us/step - loss: 0.8980 - acc: 0.5074 - val_loss: 0.7918 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.79181, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.8239 - acc: 0.6052 - val_loss: 0.7734 - val_acc: 0.6786\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.79181 to 0.77342, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.8073 - acc: 0.6518 - val_loss: 0.7634 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.77342 to 0.76344, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 79us/step - loss: 0.7913 - acc: 0.6760 - val_loss: 0.7548 - val_acc: 0.6921\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.76344 to 0.75482, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.7791 - acc: 0.6914 - val_loss: 0.7442 - val_acc: 0.7058\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.75482 to 0.74424, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.7640 - acc: 0.7048 - val_loss: 0.7324 - val_acc: 0.7359\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.74424 to 0.73244, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 5s 103us/step - loss: 0.7597 - acc: 0.7123 - val_loss: 0.7229 - val_acc: 0.7425\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73244 to 0.72295, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 5s 99us/step - loss: 0.7492 - acc: 0.7162 - val_loss: 0.7123 - val_acc: 0.7745\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72295 to 0.71231, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.7396 - acc: 0.7266 - val_loss: 0.7007 - val_acc: 0.7759\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71231 to 0.70072, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 5s 100us/step - loss: 0.7272 - acc: 0.7304 - val_loss: 0.6900 - val_acc: 0.7763\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.70072 to 0.69005, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 6s 111us/step - loss: 0.7202 - acc: 0.7364 - val_loss: 0.6754 - val_acc: 0.7771\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.69005 to 0.67543, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.7083 - acc: 0.7454 - val_loss: 0.6618 - val_acc: 0.7779\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.67543 to 0.66179, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.7051 - acc: 0.7509 - val_loss: 0.6524 - val_acc: 0.7787\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.66179 to 0.65238, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6915 - acc: 0.7541 - val_loss: 0.6411 - val_acc: 0.7829\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.65238 to 0.64111, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6862 - acc: 0.7589 - val_loss: 0.6309 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.64111 to 0.63094, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6807 - acc: 0.7635 - val_loss: 0.6211 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.63094 to 0.62110, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6768 - acc: 0.7656 - val_loss: 0.6119 - val_acc: 0.8252\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.62110 to 0.61191, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6650 - acc: 0.7706 - val_loss: 0.6034 - val_acc: 0.8263\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.61191 to 0.60343, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6645 - acc: 0.7763 - val_loss: 0.5990 - val_acc: 0.8236\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.60343 to 0.59903, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6536 - acc: 0.7782 - val_loss: 0.5910 - val_acc: 0.8220\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.59903 to 0.59100, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6504 - acc: 0.7818 - val_loss: 0.5822 - val_acc: 0.8216\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.59100 to 0.58218, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 5s 100us/step - loss: 0.6435 - acc: 0.7851 - val_loss: 0.5785 - val_acc: 0.8217\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.58218 to 0.57846, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 5s 97us/step - loss: 0.6398 - acc: 0.7840 - val_loss: 0.5716 - val_acc: 0.8219\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.57846 to 0.57162, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6322 - acc: 0.7909 - val_loss: 0.5657 - val_acc: 0.8223\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.57162 to 0.56566, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.6353 - acc: 0.7888 - val_loss: 0.5616 - val_acc: 0.8226\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.56566 to 0.56158, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6290 - acc: 0.7913 - val_loss: 0.5560 - val_acc: 0.8230\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.56158 to 0.55601, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6244 - acc: 0.7930 - val_loss: 0.5519 - val_acc: 0.8232\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.55601 to 0.55190, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6184 - acc: 0.7959 - val_loss: 0.5462 - val_acc: 0.8233\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.55190 to 0.54620, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6146 - acc: 0.7965 - val_loss: 0.5420 - val_acc: 0.8237\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.54620 to 0.54195, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6096 - acc: 0.7987 - val_loss: 0.5384 - val_acc: 0.8242\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.54195 to 0.53840, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6081 - acc: 0.8014 - val_loss: 0.5353 - val_acc: 0.8248\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.53840 to 0.53526, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.6036 - acc: 0.8035 - val_loss: 0.5309 - val_acc: 0.8250\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.53526 to 0.53094, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 33/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6046 - acc: 0.8044 - val_loss: 0.5278 - val_acc: 0.8264\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.53094 to 0.52776, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 34/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.5964 - acc: 0.8044 - val_loss: 0.5233 - val_acc: 0.8335\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.52776 to 0.52325, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.5942 - acc: 0.8079 - val_loss: 0.5202 - val_acc: 0.8416\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.52325 to 0.52024, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.5910 - acc: 0.8077 - val_loss: 0.5173 - val_acc: 0.8461\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.52024 to 0.51732, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5894 - acc: 0.8101 - val_loss: 0.5139 - val_acc: 0.8474\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.51732 to 0.51392, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 5s 98us/step - loss: 0.5858 - acc: 0.8107 - val_loss: 0.5115 - val_acc: 0.8471\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.51392 to 0.51152, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 5s 98us/step - loss: 0.5861 - acc: 0.8105 - val_loss: 0.5091 - val_acc: 0.8469\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.51152 to 0.50906, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.5810 - acc: 0.8140 - val_loss: 0.5057 - val_acc: 0.8473\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.50906 to 0.50575, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5770 - acc: 0.8165 - val_loss: 0.5029 - val_acc: 0.8477\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.50575 to 0.50288, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 5s 103us/step - loss: 0.5773 - acc: 0.8140 - val_loss: 0.5004 - val_acc: 0.8488\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.50288 to 0.50036, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.5707 - acc: 0.8176 - val_loss: 0.4972 - val_acc: 0.8497\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.50036 to 0.49718, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5733 - acc: 0.8171 - val_loss: 0.4960 - val_acc: 0.8500\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.49718 to 0.49604, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5685 - acc: 0.8189 - val_loss: 0.4931 - val_acc: 0.8501\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.49604 to 0.49312, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5683 - acc: 0.8192 - val_loss: 0.4911 - val_acc: 0.8504\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.49312 to 0.49113, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5647 - acc: 0.8193 - val_loss: 0.4890 - val_acc: 0.8506\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.49113 to 0.48902, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5609 - acc: 0.8212 - val_loss: 0.4861 - val_acc: 0.8503\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.48902 to 0.48609, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.5586 - acc: 0.8243 - val_loss: 0.4845 - val_acc: 0.8510\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.48609 to 0.48451, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 5s 97us/step - loss: 0.5578 - acc: 0.8205 - val_loss: 0.4823 - val_acc: 0.8515\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.48451 to 0.48226, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.5527 - acc: 0.8226 - val_loss: 0.4799 - val_acc: 0.8517\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.48226 to 0.47990, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 5s 98us/step - loss: 0.5536 - acc: 0.8233 - val_loss: 0.4774 - val_acc: 0.8518\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.47990 to 0.47741, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5514 - acc: 0.8259 - val_loss: 0.4767 - val_acc: 0.8519\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.47741 to 0.47669, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5488 - acc: 0.8244 - val_loss: 0.4746 - val_acc: 0.8524\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.47669 to 0.47463, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5477 - acc: 0.8267 - val_loss: 0.4727 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.47463 to 0.47273, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5457 - acc: 0.8276 - val_loss: 0.4706 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.47273 to 0.47059, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5426 - acc: 0.8286 - val_loss: 0.4700 - val_acc: 0.8526\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.47059 to 0.47002, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5424 - acc: 0.8283 - val_loss: 0.4688 - val_acc: 0.8528\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.47002 to 0.46880, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5360 - acc: 0.8306 - val_loss: 0.4663 - val_acc: 0.8530\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.46880 to 0.46631, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5344 - acc: 0.8308 - val_loss: 0.4636 - val_acc: 0.8532\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.46631 to 0.46363, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5337 - acc: 0.8311 - val_loss: 0.4636 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.46363 to 0.46361, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5343 - acc: 0.8319 - val_loss: 0.4620 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.46361 to 0.46196, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.5315 - acc: 0.8321 - val_loss: 0.4608 - val_acc: 0.8535\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.46196 to 0.46083, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5306 - acc: 0.8326 - val_loss: 0.4591 - val_acc: 0.8538\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.46083 to 0.45910, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 65/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5268 - acc: 0.8341 - val_loss: 0.4581 - val_acc: 0.8539\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00065: val_loss improved from 0.45910 to 0.45806, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.5304 - acc: 0.8329 - val_loss: 0.4585 - val_acc: 0.8540\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.45806\n",
      "Epoch 67/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.5279 - acc: 0.8339 - val_loss: 0.4558 - val_acc: 0.8545\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.45806 to 0.45576, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.5263 - acc: 0.8344 - val_loss: 0.4550 - val_acc: 0.8548\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.45576 to 0.45498, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5222 - acc: 0.8339 - val_loss: 0.4547 - val_acc: 0.8551\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.45498 to 0.45466, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 70/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5249 - acc: 0.8340 - val_loss: 0.4540 - val_acc: 0.8553\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.45466 to 0.45404, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 71/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.5230 - acc: 0.8369 - val_loss: 0.4526 - val_acc: 0.8558\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.45404 to 0.45257, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5185 - acc: 0.8360 - val_loss: 0.4505 - val_acc: 0.8564\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.45257 to 0.45054, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 5s 95us/step - loss: 0.5174 - acc: 0.8374 - val_loss: 0.4503 - val_acc: 0.8568\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.45054 to 0.45031, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.5147 - acc: 0.8385 - val_loss: 0.4485 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.45031 to 0.44846, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5156 - acc: 0.8383 - val_loss: 0.4473 - val_acc: 0.8571\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.44846 to 0.44726, saving model to saved_models/weights.best.mlp_onehot.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b908060b8>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_onehot.fit(Xtrain_onehot, Ytrain_onehot, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_onehot.load_weights('saved_models/weights.best.mlp_onehot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 65.0083%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_onehot.evaluate(Xtest_onehot, Ytest_onehot, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6327.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_onehot = mlp_onehot.predict(Xtest_onehot)\n",
    "ROC_mlp_onehot = roc_auc_score(Ytest_onehot, Ypred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGDCAYAAADEegxVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzt3Xl4VPXZxvHvQ9hlExDZNwEhCIgg4lI3QAEBq8W6b9XS+tb6trZWWisqbrzWpVpX2lqXuta2liWKoKBWWa0bJCxhD/u+hiXJ8/5xhnSMIZmETM7M5P5cVy5nzvxmznMSmXvOOc/8jrk7IiIiANXCLkBERBKHQkFERAopFEREpJBCQURECikURESkkEJBREQKKRRERKSQQkEqnZmtMLNcM9ttZuvN7AUzq1dkzGlm9oGZ7TKzHWY20czSi4xpYGa/N7NVkdfKjtxvGmMdbmYbzKx61LLqZrbRzDxq2Qwzu7GY57ePvMbuyM8KMxtdwvpqmdmDkXpzzWyJmd1mZhZLvWUVqWdgkWXXmdm/Y3z+C2Z2Xzxqk8SlUJCwDHf3esCJQG/g14ceMLNTgfeAfwEtgQ7Al8AnZtYxMqYm8D7QHRgMNABOA7YA/cpQx3ZgSNT9ocC2Mm5Lo8i2XA6MMbPBhxn3N2BAZB31gauBUcDjZVyfSNwoFCRU7r4emEIQDoc8BLzk7o+7+y533+ruvwVmAXdHxlwDtAUucvdMdy9w943ufq+7Z5ShhJcjr3XINcBL5dyWmcAC4ISij5nZAOA84HvuPt/d89x9FnAV8BMz6xQZN8PM7jWzTyJ7Se9F7/mYWX8z+9TMtpvZl2Z2dnlqjXq9bpF1bjezBWY2IrJ8FHAl8KvIXtDEI1mPJA+FgoTKzFoTfFLPjtyvS/CJ/2/FDH8TGBS5PRB41913l/DaT5vZ06WU8DZwppk1MrNGwHcI9lDKxAKnE+y5fF7MkEHAbHdfHb3Q3WcDOQR7EIdcAVwPNANqAr+MrKMVMBm4D2gcWf53MzumrPVGXq8GMJFgr6wZ8FPgFTM73t3HA68AD7l7PXcfXp51SPKpXvoQkbh4O3Lcvh7wAXBXZHljgg8r64p5zjrg0KfmJsBnJa3A3f8nhjr2EbwxXgoYMCGyrCw2Aw6sB0a7+/vFjGlK8dsE39wugL+4+2IAM3sTGBFZfhWQEbUnNNXM5hEcjnrxMK/9tpnlRd2vCfwncrs/we9/nLsXAB+Y2SSCw2B3H+b1JMVpT0HC8l13rw+cDXTlv2+K24ACoEUxz2lB8AYMwbmD4saUx0sEh43Ke+ioqbsf7e7d3P2Jw4zZzOHrjd4uCMLlkL0Eb9wA7YBLIod6tpvZduCMEl4Xgt9zo0M/QHRQtgRWRwLhkJVAqxJeT1KcQkFC5e4fAi8AD0fu7wFmApcUM/z7BCeXAaYB55vZURVQxscEb6zHAjF15pTDNOAUM2sTvdDM+gFtCPaWSrMaeDn6Td7dj3L3ceWsaS3Qxsyi3wfaAmsitzWFchWkUJBE8HtgkJkdOtk8GrjWzG4xs/pmdnSkNfJU4J7ImJcJ3iT/bmZdzayamTUxs9+Y2dCyrNyD+eOHAyP88HPJVzez2lE/Ncq4jmkEgfZ3M+tuZmlm1p/guP0z7r4khpf5KzDczM6PPL+2mZ0dOS9THrOBPQQnk2tETloPB16PPL4B6FjO15YkpVCQ0Ln7JoLDNndG7v8bOB+4mOB4+0qCttUzDr15uvt+gpPNC4GpwE5gDsFhqNkAZvasmT0bYw0L3H1BCUOeAXKjfv5Stq0E4HvAdOBdYDfBm/yfCU7wxlLjauBC4DfAJoJQvI1y/jt29wME5yuGEBy+ehq4xt0XRob8GUiPHKp6uzzrkORjusiOiIgcoj0FEREppFAQEZFCCgURESmkUBARkUIKBRERKZR001w0bdrU27dvH3YZIiJJ5bPPPtvs7qXOk5V0odC+fXvmzZsXdhkiIknFzFbGMk6Hj0REpJBCQURECikURESkkEJBREQKKRRERKSQQkFERAopFEREpJBCQURECikURESkUNxCwcyeN7ONZjb/MI+bmT1hZtlm9pWZnRSvWkREJDbx3FN4ARhcwuNDgM6Rn1EElzsUEZEQxS0U3P0jYGsJQy4EXvLALKCRmbWIVz0iIsnK3XlvwXp27TsY93WFeU6hFcGFxw/JiSz7FjMbZWbzzGzepk2bKqU4EZFEsGTDLq7+8xxGvfwZf521Ku7rC3OWVCtmmRc30N3HA+MB+vbtW+wYEZFUsmPvQR6btpiXZ63kqJpp3DOiO1ee0jbu6w0zFHKANlH3WwNrQ6pFRCQh5Bc4b8xdzcPvLWL73gNc3q8tvzjveBofVbNS1h9mKEwAbjaz14FTgB3uvi7EekREQjV3xVbunrCABWt30q9DY+4ank73lg0rtYa4hYKZvQacDTQ1sxzgLqAGgLs/C2QAQ4FsYC9wfbxqERFJZOt25PJgxkImfLmWlg1r84fLezOsZwvMijvKHl9xCwV3v7yUxx34SbzWLyKS6PYdzOePHy3j6RlLKXDnlgGduems46hTMy20mpLucpwiIsnO3ZmyYAP3Tc4kZ1suQ05ozm+GdqNN47phl6ZQEBGpTIs37OKeiQv4JHsLxx9bn1dvPIXTOjUNu6xCCgURkUoQ3WJar1b1whbT6mmJNQWdQkFEJI7yC5zX567i4SmL2JF7kCtOacutgyqvxbSsFAoiInEyZ3nQYpq5LmgxvXt4d9JbNgi7rBIpFEREKtja7bk8+M5CJkZaTJ+8ojcX9AinxbSsFAoiIhUkEVtMy0qhICJyhIIW0/XcNzmLnG25DO3RnF8PSYwW07JSKIiIHIFF64MW00+XRlpMf3gKpx2XOC2mZaVQEBEph6ItpmMv7M4V/RKvxbSsFAoiImVQXIvpLwYdz9EJ2mJaVgoFEZEYRbeYntKhMXeP6E63FondYlpWCgURkVKs3Z7LAxlZTPpqHa0a1eGpK05iaI/mSdFiWlYKBRGRw9h3MJ/xHy3j6RnZuMP/DujMj5OsxbSsFAoiIkUUbTG9oEcLfj20K62PTr4W07JSKIiIRIluMe3avD6v/bA/px7XJOyyKo1CQUQE2L73AI9NXcxfZ6+ifu3q3Hthdy5PgRbTslIoiEiVll/gvDZnFY+8F7SYXnlKO24d1CVlWkzLSqEgIlXW7GVbuHtiJlnrdtK/Y2PuGp56LaZlpVAQkSpnTaTFdHKkxfTpK09iyAmp2WJaVgoFEaky9h3M57kPl/HMh0GL6c8GduZHZ6Z2i2lZKRREJOW5O+/MX8/9k7NYs71qtZiWlUJBRFLawvU7uWdCJjOXVc0W07JSKIhIStq+9wCPTl3MX2etpEGdGtz73RO4/OQ2Va7FtKwUCiKSUvILnFcjLaY7cw9yVf+gxbRR3arZYlpWCgURSRmzlm3h7gkLWLh+l1pMy0mhICJJTy2mFUehICJJa9/BfJ79cCnPfrgUgJ8P7MKPzupI7RpqMS0vhYKIJJ1vtZj2bMFvhnajVaM6YZeW9BQKIpJUFq7fyd0TFjBr2Va6Nq/P66P607+jWkwrikJBRJKCWkwrh0JBRBJaXn5BMIvp1MXszD3I1f3b8XO1mMaNQkFEEtbMpVu4Z2LQYnpqxybcNSKdrs3VYhpPCgURSTg52/byYMZCJn8dtJg+c+VJDFaLaaVQKIhIwsg9kM9zHy3lmRlLMVOLaRgUCiISOncn4+v1PJARtJgO69mCX6vFNBQKBREJVda6ndwzMWgx7daiAY98v5daTEOkUBCRUGzbE7SYvjI7aDG977sncHm/tqRV03mDMCkURKRSRbeY7tqXpxbTBKNQEJFKE91ietpxTbhreHeOb14/7LIkikJBROIuZ9teHsjIIuPr9WoxTXAKBRGJm9wD/53F1AxuHdSFUWeqxTSRKRREpMKpxTR5KRREpEJlrQtmMZ29PGgxffT7vThFLaZJQ6EgIhVi254DPDJ1Ea/OXkVDtZgmLYWCiByRvPwCXp2zikfeW8zu/Xlcc2p7fjaws1pMk5RCQUTK7dOlmxk7MVMtpilEoSAiZRbdYtr66Do8e9VJnN9dLaapQKEgIjHLPZDPMx8u5Tm1mKYshYKIlMrdmfz1Oh6YnMXaHfsY3qslvx7SlZZqMU05cQ0FMxsMPA6kAX9y93FFHm8LvAg0iowZ7e4Z8axJRMomc20wi+ns5VtJb9GA31/Wm34dGoddlsRJ3ELBzNKAp4BBQA4w18wmuHtm1LDfAm+6+zNmlg5kAO3jVZOIxG7rngM88t4iXpsTtJg+cFEPLj25jVpMU1w89xT6AdnuvgzAzF4HLgSiQ8GBQxdcbQisjWM9IhKDvPwCXpm9iken/rfF9OcDu9Cwbo2wS5NKEM9QaAWsjrqfA5xSZMzdwHtm9lPgKGBgHOsRkVJ8mr2ZeyZmsmjDLk7vFLSYdjlWLaZVSTxDobh9TC9y/3LgBXd/xMxOBV42sxPcveAbL2Q2ChgF0LZt27gUK1KVrd4atJi+M/9Qi2kfzu9+rFpMq6B4hkIO0Cbqfmu+fXjoBmAwgLvPNLPaQFNgY/Qgdx8PjAfo27dv0WARkXLKPZDPMzOyee6jZVQz45fndeHG76jFtCqLZyjMBTqbWQdgDXAZcEWRMauAAcALZtYNqA1simNNIkLQYjrpq3U8mBG0mI7o1ZJfD+1Ki4ZqMa3q4hYK7p5nZjcDUwjaTZ939wVmNhaY5+4TgF8AfzSznxMcWrrO3bUnIBJHC9bu4J6JmcxRi6kUI67fU4h85yCjyLIxUbczgdPjWYOIBKJbTBvVrakWUymWvtEskuLy8gv466yVPDp1MXsO5HPtae352QC1mErxFAoiKSy6xfSMTk0ZMzxdLaZSIoWCSApavXUv90/O4t0F62nTuA7PXd2H89LVYiqlUyiIpJC9B/J4dsZSnv1oGWlqMZVyUCiIpAB3Z2KkxXTdjn1ceGJLRg9Ri6mUnUJBJMktWLuDeyZkMmfFVrq3bMATl/fm5PZqMZXyUSiIJKmtew7w8HuLeD3SYvrgxT34fl+1mMqRUSiIJBm1mEo8KRREksgn2Zu5Z+ICFm/YzRmdmnLX8HQ6q8VUKpBCQSQJqMVUKotCQSSB7T2QxzMzlvJcpMX0tvOP54YzOqjFVOJGoSCSgNRiKmFRKIgkmPlrdjB2YtBiekKrBvzh8t70VYupVBKFgkiCONRi+tqcVRytFlMJiUJBJGQHIy2mj0VaTK8/rQP/O7AzDeuoxVQqn0JBJET/XhK0mC7ZuJvvdG7KmGFqMZVwKRREQrB6617um5zJlAUbaNu4LuOv7sMgtZhKAlAoiFQitZhKolMoiFQCd2fCl2sZ985C1u3Yx3dPbMnoId1o3rB22KWJfINCQSTO5q/ZwT0TFzB3xTa1mErCUyiIxMmW3ft5+L3FvD53FY3r1mTcxT24RC2mkuAUCiIVLLrFdK9aTCXJKBREKlDRFtO7hqfTqZlaTCV5KBREKsCqLUGL6XuZajGV5KZQEDkCe/bn8fSMbP748XKqV1OLqSQ/hYJIORxqMX0wYyHrd6rFVFKHQkGkjOav2cHdExYwb+U2erRqyFNX9qZPO7WYSmpQKIjEKGgxXcTrc1erxVRSlkJBpBQH8wt4aeZKfj9tMbkH8vnB6R24ZYBaTCU1KRRESvDxkk3cMzGTbLWYShWhUBApxqote7l3ciZTMzfQrkld/nhNXwZ2a6YWU0l5CgWRKIUtph8tp3qa8avBQYtprepqMZWqQaEgQtBi+q8v1vLgO1ls2Lmfi3q3YvSQrhzbQC2mUrUoFKTKK9pi+vSVfejT7uiwyxIJhUJBqqzNu/fz8JRFvDFvNU2OqslD3+vJyD6tqaYWU6nCFApS5RRtMb3h9A7cMrAzDWqrxVREoSBVykeLNzF2UtBiemaXYxgzLJ1OzeqFXZZIwlAoSJWwcsse7pucVdhi+qdr+jJALaYi36JQkJS2Z38eT03P5k8fBy2mtw/uyg/OaK8WU5HDUChISiraYnpx71bcrhZTkVLFFApmVhNo6+7Zca5H5Ih9nbODuycu4LOV2+jZWi2mImVRaiiY2QXAo0BNoIOZnQjc5e4Xxbs4kbJQi6nIkYtlT2EscAowHcDdvzCzTnGtSqQMDuYX8OKnK3j8/SXkHsjnxjM68NMBajEVKY9YQuGgu28v0qXhcapHpEw+WryJeyYuYOmmPZzV5RjuVIupyBGJJRSyzOz7QDUz6wD8LzArvmWJlGzllj3cOymLaVlBi+mfr+3LuV3VYipypGIJhZuBMUAB8A9gCvDreBYlcjjRLaY11GIqUuFiCYXz3f124PZDC8zsYoKAEKkU7s7bX6xh3DsLgxbTk1px+2C1mIpUtFhC4bd8OwDuKGaZSFx8lbOduycs4D+rttOzdUOeuaoPJ7VVi6lIPBw2FMzsfGAw0MrMHo16qAHBoSSRuNq8ez+/e3cRb34WaTEd2ZORJ6nFVCSeStpT2AjMB/YBC6KW7wJGx7MokflrdnD5+FnkHlSLqUhlOmwouPvnwOdm9oq776vEmkSYtWwLu/bnMfmWM+jesmHY5YhUGdViGNPKzF43s6/MbPGhn1he3MwGm9kiM8s2s2L3Lszs+2aWaWYLzOzVMlUvKa9t47phlyBSpcRyovkF4D7gYWAIcD0xnFMwszTgKWAQkAPMNbMJ7p4ZNaYzQXvr6e6+zcyalXkLJKW8Mnslf/xoGTtyD4ZdikiVFMueQl13nwLg7kvd/bfAOTE8rx+Q7e7L3P0A8DpwYZExPwSecvdtkdffGHvpkopmLt3C5t0HOLPLMfzknOOoV0sT+YpUplj+xe234GuiS83sx8AaIJZP9K2A1VH3cwjmUIrWBcDMPgHSgLvd/d2iL2Rmo4BRAG3bto1h1ZLMmjWoxeOX9Q67DJEqKZZQ+DlQD7gFuB9oCPwghucV1zdYdM6k6kBn4GygNfCxmZ3g7tu/8ST38cB4gL59+2repRQxf80OfvLqf9i1L69w2e59ebRpXCfEqkSqtlJDwd1nR27uAq4GMLPWMbx2DtAm6n5rYG0xY2a5+0FguZktIgiJuTG8viSxggLnt2/PZ822XC49uQ3VouYs6t+xSYiViVRtJYaCmZ1McBjo3+6+2cy6E0x3cS7Bm3xJ5gKdI5PorQEuA64oMuZt4HLgBTNrSnA4aVmZt0KSzr++XMMXq7fz8CW9GNknls8YIlIZDnui2cweBF4BrgTeNbM7CK6p8CWRcwElcfc8gsn0pgBZwJvuvsDMxprZiMiwKcAWM8uMvPZt7r7lSDZIEt/eA3n83zuL6NW6IRf3bhV2OSISpaQ9hQuBXu6ea2aNCQ799HL3RbG+uLtnABlFlo2Juu3ArZEfqSKenbGU9Tv38dSVvTVlhUiCKakldZ+75wK4+1ZgYVkCQaQ4Odv28txHyxjRqyV92jUOuxwRKaKkPYWOZnZoJlQD2kfdx90vjmtlkpIefGchZjB6SNewSxGRYpQUCt8rcv/JeBYiqW/O8q1M/mod/zugMy0bqe1UJBGVNCHe+5VZiKS2ggJn7KQFtGhYmx+fdVzY5YjIYcQyzYXIEXvrsxzmr9nJ6CFdqVNTl84USVQKBYm7XfsO8tCURZzUthEjerUMuxwRKUHMoWBmteJZiKSup6YvZfPu/dw1vDtmakEVSWSlhoKZ9TOzr4Elkfu9zOwPca9MUsLKLXt4/t/LufikVvRq0yjsckSkFLHsKTwBDAO2ALj7l8Q2dbYID2RkUT3NuH2wWlBFkkEsoVDN3VcWWZYfj2IktXy6dDNTFmzgf84+jmMb1A67HBGJQSxTZ682s36AR66m9lMgpstxStWVX+CMnZhJq0Z1uPE7HcMuR0RiFMuewk0EcxO1BTYA/SPLRA7r9bmrWLh+F78Z2o3aNdSCKpIsYtlTyHP3y+JeiaSMHbkHeeS9xfRr35ihPZqHXY6IlEEsewpzzSzDzK41s/pxr0iS3h/eX8K2vQcYMzxdLagiSabUUHD344D7gD7A12b2tplpz0GKtWzTbl74dAXf79OGE1o1DLscESmjmL685u6fuvstwEnAToKL74h8y/2Ts6hdI41fnn982KWISDnE8uW1emZ2pZlNBOYAm4DT4l6ZJJ2PFm/i/YUbufncThxTX1+AF0lGsZxong9MBB5y94/jXI8kqbz8Au6dlEm7JnW5/vT2YZcjIuUUSyh0dPeCuFciSe2V2atYsnE346/uQ63qakEVSVaHDQUze8TdfwH83cy86OO68pocsn3vAR6btpjTOzVhUPqxYZcjIkegpD2FNyL/1RXXpES/n7aEnbkHuXOYWlBFkl1JV16bE7nZzd2/EQxmdjOgK7MJSzbs4uVZK7nilLZ0bd4g7HJE5AjF0pL6g2KW3VDRhUjycXfunZzFUTXTuHWQWlBFUkFJ5xQuBS4DOpjZP6Ieqg9sj3dhkvimL9rIR4s3ceewdBofVTPsckSkApR0TmEOwTUUWgNPRS3fBXwez6Ik8R3IK+DeSVl0POYorjm1XdjliEgFKemcwnJgOTCt8sqRZPHSzBUs37yHv1x3MjXSdKlvkVRR0uGjD939LDPbBkS3pBrg7t447tVJQtqyez+Pv7+Es7ocwzldm4VdjohUoJIOHx265GbTyihEkscjUxez90A+dw7rFnYpIlLBDrvfH/Ut5jZAmrvnA6cCPwKOqoTaJAFlrdvJ63NWcXX/dnRqppnURVJNLAeD3ya4FOdxwEtAN+DVuFYlCck9uMRmgzo1+NnAzmGXIyJxEEsoFLj7QeBi4Pfu/lOgVXzLkkQ0ZcEGZi7bwq2DutCorlpQRVJRLKGQZ2aXAFcDkyLLasSvJElE+/PyeSAjiy7H1uOKfm3DLkdE4iTWbzSfQzB19jIz6wC8Ft+yJNE8/+8VrNq6lzuHpVNdLagiKavUqbPdfb6Z3QJ0MrOuQLa73x//0iRRbNy1jyc/WMLAbs34Tudjwi5HROKo1FAws+8ALwNrCL6j0NzMrnb3T+JdnCSGh6cs4kB+AXdckB52KSISZ7FcZOcxYKi7ZwKYWTeCkOgbz8IkMcxfs4O/fZbDjWd0oENTdSKLpLpYDg7XPBQIAO6eBaj1pApwd+6ZuIDGdWvy0wFqQRWpCmLZU/iPmT1HsHcAcCWaEK9KmPz1Ouau2MYDF/WgQW01nIlUBbGEwo+BW4BfEZxT+Aj4QzyLkvDtO5jPgxkL6daiAZee3CbsckSkkpQYCmbWAzgO+Ke7P1Q5JUki+ONHy1izPZeHL+lFWjVdYlOkqjjsOQUz+w3BFBdXAlPNrLgrsEkKWr9jH0/PWMrg7s059bgmYZcjIpWopD2FK4Ge7r7HzI4BMoDnK6csCdND7y4kv8D5zVDNgipS1ZTUfbTf3fcAuPumUsZKivh81Tb+8fkabvhOB9o2qRt2OSJSyUraU+gYdW1mA46Lvlazu18c18qk0rk7Yydlckz9WvzknE5hlyMiISgpFL5X5P6T8SxEwvevL9by+art/G5kT+rViqUxTURSTUnXaH6/MguRcO09kMe4dxbSs3VDvndS67DLEZGQ6DyBAPDsh8tYv3MfY4alU00tqCJVlkJBWLM9l+c+XMrwXi3p275x2OWISIhiDgUzqxXPQiQ8D2ZkYQajh3QNuxQRCVmpoWBm/czsa2BJ5H4vM9M0Fyli7oqtTPpqHaPOPI5WjeqEXY6IhCyWPYUngGHAFgB3/5LgSmylMrPBZrbIzLLNbHQJ40aamZuZpuOuRAUFztiJmTRvUJsfn9Ux7HJEJAHEEgrV3H1lkWX5pT3JzNKAp4AhQDpwuZl96yotZlafYMK92THUIhXorf/k8PWaHYwe0pW6NdWCKiKxhcJqM+sHuJmlmdnPgMUxPK8fwaU7l7n7AeB14MJixt0LPATsi7VoOXK79+fxuymL6N22ERee2DLsckQkQcQSCjcBtwJtgQ1A/8iy0rQCVkfdz4ksK2RmvYE27j6ppBcys1FmNs/M5m3atCmGVUtpnpqezaZd+7lreHfM1IIqIoFSjxm4+0bgsnK8dnHvNF74oFk1gkt9XhdDDeOB8QB9+/b1UoZLKVZt2cufP17Oxb1bcWKbRmGXIyIJpNRQMLM/EvVmfoi7jyrlqTlA9NVZWgNro+7XB04AZkQ+qTYHJpjZCHefV1pdUn4PZGSRVs341WC1oIrIN8VydnFa1O3awEV887DQ4cwFOptZB2ANwd7GFYcedPcdQNND981sBvBLBUJ8zVy6hXcXrOcXg7rQvGHtsMsRkQQTy+GjN6Lvm9nLwNQYnpdnZjcDU4A04Hl3X2BmY4F57j6hnDVLOeUXBLOgtmpUhx+eqRZUEfm28vQhdgDaxTLQ3TMILs4TvWzMYcaeXY5apAzemLuarHU7efKK3tSukRZ2OSKSgGI5p7CN/55TqAZsBQ77RTRJTDv3HeSR9xbRr31jLujRIuxyRCRBlRgKFpwB7kVwTgCgwN3V/ZOE/vD+ErbuPcCLw9PVgioih1Xi9xQiAfBPd8+P/CgQktDyzXt44dMVXNKnNSe0ahh2OSKSwGL58tocMzsp7pVI3Nw/OZNa1dP45fnHh12KiCS4wx4+MrPq7p4HnAH80MyWAnsIvpTm7q6gSAIfL9nEtKyN3D64K83qqwVVREpW0jmFOcBJwHcrqRapYHn5Bdw7KZO2jevygzPah12OiCSBkkLBANx9aSXVIhXs1TmrWLxhN89e1Yda1dWCKiKlKykUjjGzWw/3oLs/God6pIJs33uAR6cu5tSOTTi/+7FhlyMiSaKkUEgD6lH8xHaS4H4/bQk7cw8yRi2oIlIGJYXCOncfW2mVSIXJ3riLl2et5LJ+benWokHY5YhIEimpJVUfL5PUvZOyqFszjV8M6hJ2KSKSZEoKhQGVVoVUmOkLN/Lh4k3874DONKlXK+xyRCTJHDYU3H1rZRYiR+5AXgH3Ts6kY9OjuObU9mGXIyJJKJZvNEuSeGnmCpZt2sNvh3WjZnX9aUWk7PTOkSK27N7P4+8v4cwux3DO8c3CLkdEkpRCIUU8OnUxew/kc+cF3dSCKiLlplBIAVnrdvLanFVc3b8B9avCAAAXD0lEQVQdnY+tH3Y5IpLEFApJzt25d1ImDerU4GcDO4ddjogkOYVCknsvcwOfLt3Czwd2oVHdmmGXIyJJTqGQxPbn5fNARhadm9XjylPahl2OiKQAhUIS+8snK1i5ZS93Dkunepr+lCJy5PROkqQ27drPkx9kM6BrM87sckzY5YhIilAoJKmHpyxif14+d1zQLexSRCSFKBSS0Pw1O3jzs9Vce2p7Oh5TL+xyRCSFKBSSjLszdmImR9etyU8HqAVVRCqWQiHJZHy9njkrtvKL87rQsE6NsMsRkRSjUEgi+w4GLahdm9fnspPVgioiFU+hkET+9PEy1mzPZczwdNKqaX4jEal4CoUksWHnPp6esZTzux/Lacc1DbscEUlRCoUk8X/vLiQv37ljaHrYpYhIClMoJIEvVm/nH/9Zww/O6EDbJnXDLkdEUphCIcEFLagLaFqvFjef2ynsckQkxSkUEtyEL9fyn1Xb+dX5x1OvVvWwyxGRFKdQSGB7D+Qx7p2FnNCqASP7tA67HBGpAhQKCey5D5exbsc+xgzrTjW1oIpIJVAoJKg123N57qOlXNCzBf06NA67HBGpIhQKCWrcOwtxh18P6Rp2KSJShSgUEtC8FVuZ+OVafnRmR1ofrRZUEak8CoUEU1Dg3DMxk+YNavPjs48LuxwRqWIUCgnm7//J4es1O7h9yPHUrakWVBGpXAqFBLJ7fx4PTVnEiW0acWGvVmGXIyJVkEIhgTw9PZtNu/Zz1/B0taCKSCgUCgli9da9/Onfy7modyt6tz067HJEpIpSKCSIBzKySDPj9sFqQRWR8CgUEsCsZVt4Z/56bjr7OJo3rB12OSJShSkUQpYfaUFt1agOo87sGHY5IlLFKRRC9ua81WSt28noIV2pXSMt7HJEpIpTKIRo576DPDxlESe3P5phPVuEXY6ICPp2VIie/CCbrXsP8MKwfpipBVVEwqc9hZAs37yHv3yynJEntaZH64ZhlyMiAsQ5FMxssJktMrNsMxtdzOO3mlmmmX1lZu+bWbt41pNI7p+cRc20atw2+PiwSxERKRS3UDCzNOApYAiQDlxuZulFhn0O9HX3nsBbwEPxqieR/HvJZqZlbeAn53aiWX21oIpI4ojnnkI/INvdl7n7AeB14MLoAe4+3d33Ru7OAlL+mpN5+QWMnbSANo3r8IPTO4RdjojIN8QzFFoBq6Pu50SWHc4NwDtxrCchvDZnFYs37OaOod3UgioiCSee3UfFtdN4sQPNrgL6Amcd5vFRwCiAtm3bVlR9lW7H3oM8OnUx/Ts25vzuzcMuR0TkW+K5p5ADtIm63xpYW3SQmQ0E7gBGuPv+4l7I3ce7e19373vMMcfEpdjK8Pv3F7Mj9yBjhnVXC6qIJKR4hsJcoLOZdTCzmsBlwIToAWbWG3iOIBA2xrGW0GVv3M3LM1dy6cltSW/ZIOxyRESKFbdQcPc84GZgCpAFvOnuC8xsrJmNiAz7HVAP+JuZfWFmEw7zcknvvsmZ1KmRxi/O6xJ2KSIihxXXbzS7ewaQUWTZmKjbA+O5/kQxfdFGZizaxB1Du9G0Xq2wyxEROSx9oznODuYXcO+kTDo0PYprT2sfdjkiIiVSKMTZSzNXsmzTHu4Y2o2a1fXrFpHEpnepONq65wCPT1vMdzo3ZUC3ZmGXIyJSKoVCHD06dRF7DuRz57B0taCKSFJQKMTJwvU7eXX2Kq46pS1djq0fdjkiIjFRKMSBu3PvpEzq167BzwaqBVVEkodCIQ6mZm7gk+wt/HxgZ44+qmbY5YiIxEyhUMH25+Vzf0YWnZrV48r+VebyECKSIhQKFeyFT1awcste7hyWTo00/XpFJLnoXasCbdq1nz98kM25XZtxVpfknbhPRKouhUIFeuS9Rew7mM8dF3QLuxQRkXJRKFSQ+Wt28Ma81Vx7WnuOO6Ze2OWIiJSLQqECuDtjJ2VydN2a3DKgc9jliIiUm0KhArwzfz1zlm/l1kFdaFinRtjliIiUm0LhCO07mM8DGVl0bV6fy05uU/oTREQSmELhCP3538vJ2ZbLmGHpVFcLqogkOb2LHYENO/fx1PRszks/ltM6NQ27HBGRI6ZQOAIPvbuIvHxXC6qIpAyFQjl9uXo7f/9PDtef0Z52TY4KuxwRkQqhUCiHQy2oTevV4uZzOoVdjohIhVEolMOEL9fy2cpt3HZ+F+rXVguqiKQOhUIZ5R7IZ9w7C+nesgEj+6gFVURSi0KhjJ77aCnrduzjruHdSaumS2yKSGpRKJTB2u25PPvhUi7o0YJ+HRqHXY6ISIVTKJTB/727kAKH0UO6hl2KiEhcKBRi9NnKrfzri7WM+k5H2jSuG3Y5IiJxoVCIQUGBc8/ETJrVr8VNZx8XdjkiInGjUIjBPz5fw1c5O7h9cFeOqlU97HJEROJGoVCKPfvzeOjdhfRq04iLercKuxwRkbhSKJTi6RnZbNy1nzHD0qmmFlQRSXEKhRKs3rqXP368nO+e2JI+7Y4OuxwRkbhTKJTgwXeySDPjdrWgikgVoVA4jFnLtpDx9Xp+fNZxtGhYJ+xyREQqhUKhGPkFztiJmbRsWJtRZ3YMuxwRkUqjUCjG3+atJnPdTkYP7UadmmlhlyMiUmkUCkXs2neQh99bRN92RzO8Z4uwyxERqVQKhSKe/CCbzbsPMGZ4OmZqQRWRqkWhEGXF5j08/8lyRvZpTc/WjcIuR0Sk0ikUotyfkUXNtGr86vzjwy5FRCQUCoWIT7I3MzVzA/9zTieaNagddjkiIqFQKAB5+QWMnZhJm8Z1uOGMDmGXIyISGoUC8Nrc1SzasIvfDOlG7RpqQRWRqqvKh8KOvQd59L1FnNKhMYNPaB52OSIioaryofD4+0vYnntQLagiIlTxUMjeuJuXZq7gspPb0L1lw7DLEREJXZUOhfsnZ1KnRhq/OE8tqCIiAFX22pIzFm1k+qJN/GZoV5rWqxV2OSIp5+DBg+Tk5LBv376wS6lSateuTevWralRo0a5nl8lQ+FgfgH3TsqkfZO6XHeaWlBF4iEnJ4f69evTvn17na+rJO7Oli1byMnJoUOH8r23VcnDR3+dtZKlm/ZwxwXp1KxeJX8FInG3b98+mjRpokCoRGZGkyZNjmjvrMq9I27dc4DHpi7mjE5NGditWdjliKQ0BULlO9LfeZULhcemLmb3/jzuHKYWVBE5Mlu3bmXQoEF07tyZQYMGsW3btmLHrVq1ivPOO49u3bqRnp7OihUrALjhhhvo1asXPXv2ZOTIkezevRuARx99lPT0dHr27MmAAQNYuXIlANOnT+fEE08s/KlduzZvv/12hW5TXEPBzAab2SIzyzaz0cU8XsvM3og8PtvM2seznkXrd/HK7JVceUo7jm9eP56rEpEqYNy4cQwYMIAlS5YwYMAAxo0bV+y4a665httuu42srCzmzJlDs2bBUYrHHnuML7/8kq+++oq2bdvy5JNPAtC7d2/mzZvHV199xciRI/nVr34FwDnnnMMXX3zBF198wQcffEDdunU577zzKnSb4hYKZpYGPAUMAdKBy80svciwG4Bt7t4JeAz4v3jV4+7cOymTerWq8/NBXeK1GhFJIN/97nfp06cP3bt3Z/z48YXL69WrV3j7rbfe4rrrrgNgw4YNXHTRRfTq1YtevXrx6aeflvj6//rXv7j22msBuPbaa4v91J6ZmUleXh6DBg0qXHfdunUBaNCgARC8P+Xm5hYevTjnnHMKx/Tv35+cnJxvve5bb73FkCFDCsdVlHh2H/UDst19GYCZvQ5cCGRGjbkQuDty+y3gSTMzd/eKLmZa1kb+nb2ZMcPSaXxUzYp+eREpwT0TF5C5dmeFvmZ6ywbcNbx7iWOef/55GjduTG5uLieffDLf+973aNKkyWHH33LLLZx11ln885//JD8/v/BwztChQ/nTn/5Ey5YtvzF+w4YNtGgRXKGxRYsWbNy48VuvuXjxYho1asTFF1/M8uXLGThwIOPGjSMtLZhn7frrrycjI4P09HQeeeSRbz3/z3/+M0OGDPnW8tdff51bb721xO0vj3gePmoFrI66nxNZVuwYd88DdgDf+ouZ2Sgzm2dm8zZt2lSuYvILCujfsTFXn9quXM8XkeTzxBNP0KtXL/r378/q1atZsmRJieM/+OADbrrpJgDS0tJo2DCY6SAjI+NbgRCrvLw8Pv74Yx5++GHmzp3LsmXLeOGFFwof/8tf/sLatWvp1q0bb7zxxjee+9e//pV58+Zx2223fWP5unXr+Prrrzn//PPLVVNJ4rmnUNxZ3KJ7ALGMwd3HA+MB+vbtW669iMEntGDwCbrmskgYSvtEHw8zZsxg2rRpzJw5k7p163L22WcXtmpGN5kcSfvmsccey7p162jRogXr1q0rPFcQrXXr1vTu3ZuOHTsCwSGtWbNmccMNNxSOSUtL49JLL+V3v/sd119/PQDTpk3j/vvv58MPP6RWrW9+wfbNN9/koosuKvcX1EoSzz2FHKBN1P3WwNrDjTGz6kBDYGscaxKRKmLHjh0cffTR1K1bl4ULFzJr1qzCx4499liysrIoKCjgn//8Z+HyAQMG8MwzzwCQn5/Pzp0lH/IaMWIEL774IgAvvvgiF1544bfGnHzyyWzbto1DRzk++OAD0tPTcXeys7OB4JzCxIkT6dq1KwCff/45P/rRj5gwYUKxQfPaa69x+eWXl+XXEbN4hsJcoLOZdTCzmsBlwIQiYyYA10ZujwQ+iMf5BBGpegYPHkxeXh49e/bkzjvvpH///oWPjRs3jmHDhnHuuecWnhMAePzxx5k+fTo9evSgT58+LFiwAAjOKaxdW/QzLYwePZqpU6fSuXNnpk6dyujRQZPlvHnzuPHGG4FgL+Dhhx9mwIAB9OjRA3fnhz/8Ie7OtddeS48ePejRowfr1q1jzJgxANx2223s3r2bSy65hBNPPJERI0YUrnPFihWsXr2as846q+J/aYDF8z3YzIYCvwfSgOfd/X4zGwvMc/cJZlYbeBnoTbCHcNmhE9OH07dvX583b17cahaRipGVlUW3bt3CLqNKKu53b2afuXvf0p4b17mP3D0DyCiybEzU7X3AJfGsQUREYlflvtEsIiKHp1AQEZFCCgURiRv1jVS+I/2dKxREJC5q167Nli1bFAyV6ND1FGrXrl3u16iSF9kRkfhr3bo1OTk5lHcWAimfQ1deKy+FgojERY0aNcp99S8Jjw4fiYhIIYWCiIgUUiiIiEihuE5zEQ9mtglYWc6nNwU2V2A5yUDbXDVom6uGI9nmdu5+TGmDki4UjoSZzYtl7o9Uom2uGrTNVUNlbLMOH4mISCGFgoiIFKpqoTC+9CEpR9tcNWibq4a4b3OVOqcgIiIlq2p7CiIiUoKUDAUzG2xmi8ws28xGF/N4LTN7I/L4bDNrX/lVVqwYtvlWM8s0s6/M7H0zaxdGnRWptG2OGjfSzNzMkr5TJZZtNrPvR/7WC8zs1cqusaLF8P92WzObbmafR/7/HhpGnRXFzJ43s41mNv8wj5uZPRH5fXxlZidVaAHunlI/BJf+XAp0BGoCXwLpRcb8D/Bs5PZlwBth110J23wOUDdy+6aqsM2RcfWBj4BZQN+w666Ev3Nn4HPg6Mj9ZmHXXQnbPB64KXI7HVgRdt1HuM1nAicB8w/z+FDgHcCA/sDsilx/Ku4p9AOy3X2Zux8AXgcuLDLmQuDFyO23gAFmZpVYY0UrdZvdfbq7743cnQWUfxrFxBDL3xngXuAhYF9lFhcnsWzzD4Gn3H0bgLtvrOQaK1os2+xAg8jthsDaSqyvwrn7RwTXrD+cC4GXPDALaGRmLSpq/akYCq2A1VH3cyLLih3j7nnADqBJpVQXH7Fsc7QbCD5pJLNSt9nMegNt3H1SZRYWR7H8nbsAXczsEzObZWaDK626+Ihlm+8GrjKzHIJrwv+0ckoLTVn/vZdJKk6dXdwn/qItVrGMSSYxb4+ZXQX0Bc6Ka0XxV+I2m1k14DHgusoqqBLE8neuTnAI6WyCvcGPzewEd98e59riJZZtvhx4wd0fMbNTgZcj21wQ//JCEdf3r1TcU8gB2kTdb823dycLx5hZdYJdzpJ21xJdLNuMmQ0E7gBGuPv+SqotXkrb5vrACcAMM1tBcOx1QpKfbI71/+1/uftBd18OLCIIiWQVyzbfALwJ4O4zgdoEcwSlqpj+vZdXKobCXKCzmXUws5oEJ5InFBkzAbg2cnsk8IFHzuAkqVK3OXIo5TmCQEj248xQyja7+w53b+ru7d29PcF5lBHuPi+ccitELP9vv03QVICZNSU4nLSsUqusWLFs8ypgAICZdSMIhVS+3NsE4JpIF1J/YIe7r6uoF0+5w0funmdmNwNTCDoXnnf3BWY2Fpjn7hOAPxPsYmYT7CFcFl7FRy7Gbf4dUA/4W+Sc+ip3HxFa0Ucoxm1OKTFu8xTgPDPLBPKB29x9S3hVH5kYt/kXwB/N7OcEh1GuS+YPeWb2GsHhv6aR8yR3ATUA3P1ZgvMmQ4FsYC9wfYWuP4l/dyIiUsFS8fCRiIiUk0JBREQKKRRERKSQQkFERAopFEREpJBCQRKOmeWb2RdRP+1LGNv+cLNJlnGdMyIzcX4ZmSLi+HK8xo/N7JrI7evMrGXUY38ys/QKrnOumZ0Yw3N+ZmZ1j3TdUjUoFCQR5br7iVE/KyppvVe6ey+CyRJ/V9Ynu/uz7v5S5O51QMuox25098wKqfK/dT5NbHX+DFAoSEwUCpIUInsEH5vZfyI/pxUzpruZzYnsXXxlZp0jy6+KWv6cmaWVsrqPgE6R5w6IzNP/dWSe+1qR5ePsv9eneDiy7G4z+6WZjSSYX+qVyDrrRD7h9zWzm8zsoaiarzOzP5SzzplETYRmZs+Y2TwLrqNwT2TZLQThNN3MpkeWnWdmMyO/x7+ZWb1S1iNViEJBElGdqENH/4ws2wgMcveTgEuBJ4p53o+Bx939RII35ZzItAeXAqdHlucDV5ay/uHA12ZWG3gBuNTdexDMAHCTmTUGLgK6u3tP4L7oJ7v7W8A8gk/0J7p7btTDbwEXR92/FHijnHUOJpjW4pA73L0v0BM4y8x6uvsTBPPinOPu50SmvvgtMDDyu5wH3FrKeqQKSblpLiQl5EbeGKPVAJ6MHEPPJ5jTp6iZwB1m1hr4h7svMbMBQB9gbmR6jzoEAVOcV8wsF1hBMP3y8cByd18cefxF4CfAkwTXZ/iTmU0GYp6a2903mdmyyJw1SyLr+CTyumWp8yiCaR+ir7r1fTMbRfDvugXBBWe+KvLc/pHln0TWU5Pg9yYCKBQkefwc2AD0ItjD/dZFc9z9VTObDVwATDGzGwmmGX7R3X8dwzqujJ4wz8yKvcZGZD6efgSTsF0G3AycW4ZteQP4PrAQ+Ke7uwXv0DHXSXAFsnHAU8DFZtYB+CVwsrtvM7MXCCaGK8qAqe5+eRnqlSpEh48kWTQE1kXmyL+a4FPyN5hZR2BZ5JDJBILDKO8DI82sWWRMY4v9+tQLgfZm1ily/2rgw8gx+IbunkFwEre4DqBdBNN3F+cfwHcJrgPwRmRZmep094MEh4H6Rw49NQD2ADvM7FhgyGFqmQWcfmibzKyumRW31yVVlEJBksXTwLVmNovg0NGeYsZcCsw3sy+ArgSXLMwkePN8z8y+AqYSHFoplbvvI5iB8m9m9jVQADxL8AY7KfJ6HxLsxRT1AvDsoRPNRV53G5AJtHP3OZFlZa4zcq7iEeCX7v4lwbWZFwDPExySOmQ88I6ZTXf3TQSdUa9F1jOL4HclAmiWVBERiaI9BRERKaRQEBGRQgoFEREppFAQEZFCCgURESmkUBARkUIKBRERKaRQEBGRQv8P4kltBuFmmRAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_onehot, x_test=Xtest_onehot,\n",
    "        y_test=Ytest_onehot,title=\"ROC: MLP One Hot\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Sum, default learning rate in Stochastic Gradient Descent Optimizer.\n",
    "This is a comparison MLP model that uses the default learning rate of 0.01 to descend down the loss gradient in an attempt to find the global minimum (Reference 14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "DEFAULT_stochastic = SGD()\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for SUM.\n",
    "mlp_sum_DEFAULT = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the SUM data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_sum_DEFAULT.compile(loss='binary_crossentropy',\n",
    "              optimizer= DEFAULT_stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_sum_DEFAULT.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 6s 121us/step - loss: 0.7281 - acc: 0.6402 - val_loss: 0.6886 - val_acc: 0.6879\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.68862, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 73us/step - loss: 0.7072 - acc: 0.6610 - val_loss: 0.6716 - val_acc: 0.6881\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.68862 to 0.67157, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 74us/step - loss: 0.6987 - acc: 0.6645 - val_loss: 0.6682 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.67157 to 0.66816, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 73us/step - loss: 0.6912 - acc: 0.6681 - val_loss: 0.6613 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.66816 to 0.66134, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 73us/step - loss: 0.6863 - acc: 0.6684 - val_loss: 0.6542 - val_acc: 0.6890\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.66134 to 0.65419, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 4s 74us/step - loss: 0.6813 - acc: 0.6715 - val_loss: 0.6515 - val_acc: 0.6895\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.65419 to 0.65150, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 4s 74us/step - loss: 0.6773 - acc: 0.6732 - val_loss: 0.6468 - val_acc: 0.6908\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.65150 to 0.64682, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 4s 74us/step - loss: 0.6718 - acc: 0.6748 - val_loss: 0.6456 - val_acc: 0.6905\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.64682 to 0.64560, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6680 - acc: 0.6769 - val_loss: 0.6354 - val_acc: 0.6929\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.64560 to 0.63541, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6615 - acc: 0.6794 - val_loss: 0.6322 - val_acc: 0.6929\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.63541 to 0.63223, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6608 - acc: 0.6805 - val_loss: 0.6307 - val_acc: 0.6936\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.63223 to 0.63071, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.6556 - acc: 0.6844 - val_loss: 0.6249 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.63071 to 0.62492, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6500 - acc: 0.6881 - val_loss: 0.6193 - val_acc: 0.6998\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.62492 to 0.61928, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6480 - acc: 0.6881 - val_loss: 0.6135 - val_acc: 0.7012\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.61928 to 0.61350, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6448 - acc: 0.6892 - val_loss: 0.6151 - val_acc: 0.7011\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.61350\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6402 - acc: 0.6920 - val_loss: 0.6054 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.61350 to 0.60536, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6364 - acc: 0.6969 - val_loss: 0.6032 - val_acc: 0.7073\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.60536 to 0.60324, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6328 - acc: 0.6977 - val_loss: 0.5956 - val_acc: 0.7138\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.60324 to 0.59561, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6267 - acc: 0.7006 - val_loss: 0.5936 - val_acc: 0.7127\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.59561 to 0.59361, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6284 - acc: 0.7006 - val_loss: 0.5863 - val_acc: 0.7247\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.59361 to 0.58629, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6266 - acc: 0.7019 - val_loss: 0.5839 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.58629 to 0.58395, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6236 - acc: 0.7055 - val_loss: 0.5774 - val_acc: 0.7381\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.58395 to 0.57742, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6184 - acc: 0.7094 - val_loss: 0.5754 - val_acc: 0.7405\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.57742 to 0.57537, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.6173 - acc: 0.7080 - val_loss: 0.5713 - val_acc: 0.7448\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.57537 to 0.57126, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6100 - acc: 0.7110 - val_loss: 0.5674 - val_acc: 0.7465\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.57126 to 0.56742, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6114 - acc: 0.7132 - val_loss: 0.5646 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.56742 to 0.56457, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6061 - acc: 0.7178 - val_loss: 0.5607 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.56457 to 0.56071, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6049 - acc: 0.7158 - val_loss: 0.5602 - val_acc: 0.7515\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.56071 to 0.56023, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6006 - acc: 0.7186 - val_loss: 0.5531 - val_acc: 0.7627\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.56023 to 0.55305, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6007 - acc: 0.7221 - val_loss: 0.5515 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.55305 to 0.55154, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5954 - acc: 0.7231 - val_loss: 0.5478 - val_acc: 0.7642\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.55154 to 0.54777, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5956 - acc: 0.7217 - val_loss: 0.5462 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.54777 to 0.54622, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 33/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.5947 - acc: 0.7258 - val_loss: 0.5439 - val_acc: 0.7646\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.54622 to 0.54388, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 34/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5931 - acc: 0.7258 - val_loss: 0.5403 - val_acc: 0.7725\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.54388 to 0.54035, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 4s 80us/step - loss: 0.5871 - acc: 0.7295 - val_loss: 0.5445 - val_acc: 0.7651\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.54035\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.5858 - acc: 0.7283 - val_loss: 0.5363 - val_acc: 0.7696\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.54035 to 0.53630, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.5878 - acc: 0.7294 - val_loss: 0.5344 - val_acc: 0.7756\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.53630 to 0.53441, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.5835 - acc: 0.7299 - val_loss: 0.5310 - val_acc: 0.7790\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.53441 to 0.53103, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.5811 - acc: 0.7335 - val_loss: 0.5324 - val_acc: 0.7726\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.53103\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5799 - acc: 0.7334 - val_loss: 0.5276 - val_acc: 0.7839\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.53103 to 0.52761, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5802 - acc: 0.7350 - val_loss: 0.5361 - val_acc: 0.7727\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.52761\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5767 - acc: 0.7365 - val_loss: 0.5255 - val_acc: 0.7820\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.52761 to 0.52549, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.5775 - acc: 0.7348 - val_loss: 0.5250 - val_acc: 0.7890\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.52549 to 0.52499, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5779 - acc: 0.7357 - val_loss: 0.5223 - val_acc: 0.7906\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.52499 to 0.52228, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5750 - acc: 0.7374 - val_loss: 0.5244 - val_acc: 0.7802\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.52228\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.5738 - acc: 0.7414 - val_loss: 0.5190 - val_acc: 0.7923\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.52228 to 0.51900, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5718 - acc: 0.7384 - val_loss: 0.5257 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.51900\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5726 - acc: 0.7386 - val_loss: 0.5169 - val_acc: 0.7926\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.51900 to 0.51691, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.5696 - acc: 0.7393 - val_loss: 0.5172 - val_acc: 0.7949\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.51691\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 5s 94us/step - loss: 0.5718 - acc: 0.7405 - val_loss: 0.5158 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.51691 to 0.51583, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5687 - acc: 0.7434 - val_loss: 0.5187 - val_acc: 0.7886\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.51583\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5688 - acc: 0.7405 - val_loss: 0.5160 - val_acc: 0.7906\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.51583\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.5693 - acc: 0.7441 - val_loss: 0.5198 - val_acc: 0.7844\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.51583\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5691 - acc: 0.7429 - val_loss: 0.5159 - val_acc: 0.7838\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.51583\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5669 - acc: 0.7442 - val_loss: 0.5122 - val_acc: 0.7955\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.51583 to 0.51220, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5643 - acc: 0.7449 - val_loss: 0.5165 - val_acc: 0.7969\n",
      "\n",
      "Epoch 00056: val_loss did not improve from 0.51220\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5651 - acc: 0.7436 - val_loss: 0.5103 - val_acc: 0.7943\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.51220 to 0.51031, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 7s 135us/step - loss: 0.5636 - acc: 0.7472 - val_loss: 0.5127 - val_acc: 0.7851\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.51031\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.5642 - acc: 0.7467 - val_loss: 0.5149 - val_acc: 0.7897\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.51031\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.5656 - acc: 0.7451 - val_loss: 0.5093 - val_acc: 0.7937\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.51031 to 0.50934, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 5s 95us/step - loss: 0.5642 - acc: 0.7472 - val_loss: 0.5099 - val_acc: 0.7887\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.50934\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.5608 - acc: 0.7502 - val_loss: 0.5085 - val_acc: 0.7900\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.50934 to 0.50849, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.5618 - acc: 0.7476 - val_loss: 0.5042 - val_acc: 0.7975\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.50849 to 0.50419, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.5629 - acc: 0.7469 - val_loss: 0.5040 - val_acc: 0.8000\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.50419 to 0.50397, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 65/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5596 - acc: 0.7495 - val_loss: 0.5061 - val_acc: 0.7997\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.50397\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5639 - acc: 0.7466 - val_loss: 0.5060 - val_acc: 0.7950\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.50397\n",
      "Epoch 67/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5604 - acc: 0.7482 - val_loss: 0.5047 - val_acc: 0.7939\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.50397\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.5637 - acc: 0.7488 - val_loss: 0.5071 - val_acc: 0.7878\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.50397\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.5613 - acc: 0.7501 - val_loss: 0.5154 - val_acc: 0.7804\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.50397\n",
      "Epoch 70/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.5579 - acc: 0.7489 - val_loss: 0.5045 - val_acc: 0.7994\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.50397\n",
      "Epoch 71/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5607 - acc: 0.7468 - val_loss: 0.5039 - val_acc: 0.7968\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.50397 to 0.50391, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5594 - acc: 0.7494 - val_loss: 0.5006 - val_acc: 0.8013\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.50391 to 0.50061, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.5589 - acc: 0.7502 - val_loss: 0.5009 - val_acc: 0.8017\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.50061\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.5582 - acc: 0.7507 - val_loss: 0.5038 - val_acc: 0.7956\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.50061\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.5602 - acc: 0.7490 - val_loss: 0.5002 - val_acc: 0.7992\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.50061 to 0.50015, saving model to saved_models/weights.best.mlp_sum_DEFAULT.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b91ef8c50>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_sum_DEFAULT.fit(Xtrain_sum, Ytrain_sum, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_sum_DEFAULT.load_weights('saved_models/weights.best.mlp_sum_DEFAULT.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 96.2270%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_sum_DEFAULT.evaluate(Xtest_sum, Ytest_sum, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.5069.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_sum_DEFAULT = mlp_sum_DEFAULT.predict(Xtest_sum)\n",
    "ROC_mlp_sum_DEFAULT = roc_auc_score(Ytest_sum, Ypred_sum_DEFAULT)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_sum_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_sum_DEFAULT, x_test=Xtest_sum,\n",
    "        y_test=Ytest_sum,title=\"ROC: MLP Sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Sum Final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 75\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the MLP model for SUM.\n",
    "mlp_sum = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the SUM data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_sum.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_sum.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 52409 samples, validate on 13103 samples\n",
      "Epoch 1/75\n",
      "52409/52409 [==============================] - 7s 126us/step - loss: 0.7861 - acc: 0.5324 - val_loss: 0.7148 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.71479, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 2/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7509 - acc: 0.5894 - val_loss: 0.7008 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.71479 to 0.70081, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 3/75\n",
      "52409/52409 [==============================] - 4s 78us/step - loss: 0.7430 - acc: 0.6119 - val_loss: 0.6925 - val_acc: 0.6917\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.70081 to 0.69254, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 4/75\n",
      "52409/52409 [==============================] - 4s 75us/step - loss: 0.7393 - acc: 0.6187 - val_loss: 0.6872 - val_acc: 0.6921\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.69254 to 0.68725, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 5/75\n",
      "52409/52409 [==============================] - 4s 75us/step - loss: 0.7343 - acc: 0.6238 - val_loss: 0.6847 - val_acc: 0.6917\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.68725 to 0.68468, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 6/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.7278 - acc: 0.6271 - val_loss: 0.6820 - val_acc: 0.6922\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.68468 to 0.68198, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 7/75\n",
      "52409/52409 [==============================] - 4s 86us/step - loss: 0.7260 - acc: 0.6284 - val_loss: 0.6804 - val_acc: 0.6921\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.68198 to 0.68037, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 8/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.7255 - acc: 0.6320 - val_loss: 0.6786 - val_acc: 0.6921\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.68037 to 0.67860, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 9/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.7221 - acc: 0.6322 - val_loss: 0.6774 - val_acc: 0.6928\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.67860 to 0.67737, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 10/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.7207 - acc: 0.6358 - val_loss: 0.6757 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.67737 to 0.67569, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 11/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.7197 - acc: 0.6365 - val_loss: 0.6746 - val_acc: 0.6947\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.67569 to 0.67458, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 12/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.7189 - acc: 0.6373 - val_loss: 0.6739 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.67458 to 0.67388, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 13/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.7151 - acc: 0.6406 - val_loss: 0.6724 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.67388 to 0.67238, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 14/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.7155 - acc: 0.6395 - val_loss: 0.6716 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.67238 to 0.67164, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 15/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.7123 - acc: 0.6403 - val_loss: 0.6702 - val_acc: 0.6955\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.67164 to 0.67017, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 16/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.7106 - acc: 0.6436 - val_loss: 0.6681 - val_acc: 0.6951\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.67017 to 0.66810, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 17/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.7088 - acc: 0.6439 - val_loss: 0.6673 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.66810 to 0.66733, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 18/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.7113 - acc: 0.6447 - val_loss: 0.6660 - val_acc: 0.6951\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.66733 to 0.66598, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 19/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.7055 - acc: 0.6472 - val_loss: 0.6649 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.66598 to 0.66486, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 20/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.7056 - acc: 0.6475 - val_loss: 0.6633 - val_acc: 0.6953\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.66486 to 0.66332, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 21/75\n",
      "52409/52409 [==============================] - 6s 111us/step - loss: 0.7059 - acc: 0.6485 - val_loss: 0.6631 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.66332 to 0.66310, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 22/75\n",
      "52409/52409 [==============================] - 6s 107us/step - loss: 0.7033 - acc: 0.6493 - val_loss: 0.6616 - val_acc: 0.6959\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.66310 to 0.66158, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 23/75\n",
      "52409/52409 [==============================] - 6s 106us/step - loss: 0.6992 - acc: 0.6526 - val_loss: 0.6596 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.66158 to 0.65961, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 24/75\n",
      "52409/52409 [==============================] - 5s 103us/step - loss: 0.6998 - acc: 0.6539 - val_loss: 0.6582 - val_acc: 0.6969\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.65961 to 0.65825, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 25/75\n",
      "52409/52409 [==============================] - 6s 108us/step - loss: 0.7006 - acc: 0.6554 - val_loss: 0.6569 - val_acc: 0.6971\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.65825 to 0.65694, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 26/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.7001 - acc: 0.6540 - val_loss: 0.6562 - val_acc: 0.6978\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.65694 to 0.65619, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 27/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6959 - acc: 0.6569 - val_loss: 0.6548 - val_acc: 0.6979\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.65619 to 0.65482, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 28/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6959 - acc: 0.6570 - val_loss: 0.6536 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.65482 to 0.65363, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 29/75\n",
      "52409/52409 [==============================] - 4s 82us/step - loss: 0.6931 - acc: 0.6582 - val_loss: 0.6520 - val_acc: 0.6992\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.65363 to 0.65204, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 30/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6934 - acc: 0.6610 - val_loss: 0.6514 - val_acc: 0.6996\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.65204 to 0.65137, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 31/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.6927 - acc: 0.6630 - val_loss: 0.6502 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.65137 to 0.65023, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 32/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6922 - acc: 0.6642 - val_loss: 0.6490 - val_acc: 0.7041\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.65023 to 0.64902, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 33/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6893 - acc: 0.6649 - val_loss: 0.6475 - val_acc: 0.7048\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.64902 to 0.64747, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 34/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6882 - acc: 0.6628 - val_loss: 0.6464 - val_acc: 0.7062\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.64747 to 0.64638, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 35/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6900 - acc: 0.6660 - val_loss: 0.6455 - val_acc: 0.7060\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.64638 to 0.64554, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 36/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6871 - acc: 0.6647 - val_loss: 0.6442 - val_acc: 0.7069\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.64554 to 0.64425, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 37/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6855 - acc: 0.6644 - val_loss: 0.6429 - val_acc: 0.7087\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.64425 to 0.64293, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 38/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6850 - acc: 0.6678 - val_loss: 0.6415 - val_acc: 0.7092\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.64293 to 0.64146, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 39/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6840 - acc: 0.6683 - val_loss: 0.6396 - val_acc: 0.7105\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.64146 to 0.63963, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 40/75\n",
      "52409/52409 [==============================] - 4s 81us/step - loss: 0.6826 - acc: 0.6715 - val_loss: 0.6384 - val_acc: 0.7114\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.63963 to 0.63841, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 41/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6797 - acc: 0.6716 - val_loss: 0.6368 - val_acc: 0.7133\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.63841 to 0.63675, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 42/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6800 - acc: 0.6746 - val_loss: 0.6355 - val_acc: 0.7139\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.63675 to 0.63546, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 43/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6786 - acc: 0.6749 - val_loss: 0.6342 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.63546 to 0.63423, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 44/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6781 - acc: 0.6737 - val_loss: 0.6328 - val_acc: 0.7165\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.63423 to 0.63283, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 45/75\n",
      "52409/52409 [==============================] - 5s 89us/step - loss: 0.6769 - acc: 0.6731 - val_loss: 0.6317 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.63283 to 0.63167, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 46/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6753 - acc: 0.6770 - val_loss: 0.6308 - val_acc: 0.7193\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.63167 to 0.63078, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 47/75\n",
      "52409/52409 [==============================] - 5s 90us/step - loss: 0.6766 - acc: 0.6776 - val_loss: 0.6297 - val_acc: 0.7220\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.63078 to 0.62971, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 48/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.6775 - acc: 0.6756 - val_loss: 0.6287 - val_acc: 0.7225\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.62971 to 0.62867, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 49/75\n",
      "52409/52409 [==============================] - 5s 86us/step - loss: 0.6719 - acc: 0.6791 - val_loss: 0.6268 - val_acc: 0.7236\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.62867 to 0.62682, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 50/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6728 - acc: 0.6776 - val_loss: 0.6258 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.62682 to 0.62582, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 51/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6712 - acc: 0.6782 - val_loss: 0.6246 - val_acc: 0.7256\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.62582 to 0.62458, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 52/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6729 - acc: 0.6795 - val_loss: 0.6238 - val_acc: 0.7266\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.62458 to 0.62379, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 53/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6675 - acc: 0.6805 - val_loss: 0.6220 - val_acc: 0.7291\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.62379 to 0.62202, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 54/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6663 - acc: 0.6826 - val_loss: 0.6205 - val_acc: 0.7295\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.62202 to 0.62047, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 55/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6698 - acc: 0.6815 - val_loss: 0.6195 - val_acc: 0.7333\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.62047 to 0.61953, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 56/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6662 - acc: 0.6829 - val_loss: 0.6185 - val_acc: 0.7351\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.61953 to 0.61847, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 57/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6664 - acc: 0.6844 - val_loss: 0.6178 - val_acc: 0.7367\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.61847 to 0.61785, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 58/75\n",
      "52409/52409 [==============================] - 5s 92us/step - loss: 0.6637 - acc: 0.6857 - val_loss: 0.6165 - val_acc: 0.7381\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.61785 to 0.61649, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 59/75\n",
      "52409/52409 [==============================] - 4s 86us/step - loss: 0.6640 - acc: 0.6845 - val_loss: 0.6157 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.61649 to 0.61571, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 60/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6626 - acc: 0.6842 - val_loss: 0.6146 - val_acc: 0.7398\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.61571 to 0.61459, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 61/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6638 - acc: 0.6850 - val_loss: 0.6142 - val_acc: 0.7391\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.61459 to 0.61417, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 62/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6622 - acc: 0.6860 - val_loss: 0.6130 - val_acc: 0.7405\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.61417 to 0.61302, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 63/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6583 - acc: 0.6907 - val_loss: 0.6113 - val_acc: 0.7414\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.61302 to 0.61130, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 64/75\n",
      "52409/52409 [==============================] - 5s 88us/step - loss: 0.6592 - acc: 0.6910 - val_loss: 0.6102 - val_acc: 0.7422\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.61130 to 0.61024, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 65/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6599 - acc: 0.6893 - val_loss: 0.6095 - val_acc: 0.7431\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.61024 to 0.60954, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 66/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6593 - acc: 0.6903 - val_loss: 0.6088 - val_acc: 0.7433\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.60954 to 0.60878, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 67/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6592 - acc: 0.6894 - val_loss: 0.6076 - val_acc: 0.7457\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.60878 to 0.60764, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 68/75\n",
      "52409/52409 [==============================] - 4s 84us/step - loss: 0.6567 - acc: 0.6906 - val_loss: 0.6069 - val_acc: 0.7460\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.60764 to 0.60694, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 69/75\n",
      "52409/52409 [==============================] - 5s 87us/step - loss: 0.6555 - acc: 0.6916 - val_loss: 0.6060 - val_acc: 0.7459\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.60694 to 0.60598, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 70/75\n",
      "52409/52409 [==============================] - 5s 93us/step - loss: 0.6540 - acc: 0.6926 - val_loss: 0.6049 - val_acc: 0.7471\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.60598 to 0.60489, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 71/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6565 - acc: 0.6909 - val_loss: 0.6045 - val_acc: 0.7485\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.60489 to 0.60454, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 72/75\n",
      "52409/52409 [==============================] - 4s 86us/step - loss: 0.6538 - acc: 0.6944 - val_loss: 0.6037 - val_acc: 0.7480\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.60454 to 0.60371, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 73/75\n",
      "52409/52409 [==============================] - 5s 91us/step - loss: 0.6522 - acc: 0.6938 - val_loss: 0.6025 - val_acc: 0.7490\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.60371 to 0.60252, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 74/75\n",
      "52409/52409 [==============================] - 4s 83us/step - loss: 0.6538 - acc: 0.6954 - val_loss: 0.6022 - val_acc: 0.7494\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.60252 to 0.60220, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 75/75\n",
      "52409/52409 [==============================] - 4s 85us/step - loss: 0.6509 - acc: 0.6949 - val_loss: 0.6012 - val_acc: 0.7491\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.60220 to 0.60118, saving model to saved_models/weights.best.mlp_sum.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x26b91ee0438>"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_sum.fit(Xtrain_sum, Ytrain_sum, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_sum.load_weights('saved_models/weights.best.mlp_sum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 74.7579%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_sum.evaluate(Xtest_sum, Ytest_sum, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6445.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_sum = mlp_sum.predict(Xtest_sum)\n",
    "ROC_mlp_sum = roc_auc_score(Ytest_sum, Ypred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This plots the ROC curve for the model.\n",
    "roc_plot(model=mlp_sum, x_test=Xtest_sum,\n",
    "        y_test=Ytest_sum,title=\"ROC: MLP Sum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "3. https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "4. https://dziganto.github.io/cross-validation/data%20science/machine%20learning/model%20tuning/python/Model-Tuning-with-Validation-and-Cross-Validation/\n",
    "5. https://keras.io/getting-started/sequential-model-guide/\n",
    "6. Udacity Machine Learning Engineer Nanodegree Program, Semester 2, Brian Campbell - Dog Breed Classifier Project\n",
    "7. https://keras.io/getting-started/sequential-model-guide/\n",
    "8. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ma.size.html\n",
    "9. https://keras.io/models/sequential/\n",
    "10. https://machinelearningmastery.com/reproducible-results-neural-networks-keras/\n",
    "11. https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "12. https://matplotlib.org/3.1.1/api/_as_gen/matplotlib.pyplot.figure.html#matplotlib.pyplot.figure\n",
    "13. https://stackoverflow.com/questions/273192/how-can-i-safely-create-a-nested-directory\n",
    "14. https://keras.io/optimizers/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
