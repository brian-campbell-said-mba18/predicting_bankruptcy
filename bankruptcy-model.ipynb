{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Capstone Project: The Efficacy of Multilayer Perceptron Algorithms in Predicting Bankruptcy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "<li><a href=\"#introduction\">INTRODUCTION</a></li>\n",
    "<li><a href=\"#Benchmark Logistic Regression\">Benchmark Logistic Regression</a></li>\n",
    "<li><a href=\"#MLP Model\">MLP Model</a></li>\n",
    "<li><a href=\"#assess\">Data Assessment</a></li>\n",
    "<li><a href=\"#cleaning\">Data Cleaning</a></li>\n",
    "<li><a href=\"#target\">Separation of Target Variables</a></li>\n",
    "<li><a href=\"#no nulls\">No Nulls Data</a></li>\n",
    "<li><a href=\"#one-hot null\">Creation of One-hot Null Variable</a></li>\n",
    "<li><a href=\"#Creation of Sum Null Variables\">Creation of Sum Null Variables</a></li>\n",
    "<li><a href=\"#PIVOT\">PIVOT</a></li>\n",
    "<li><a href=\"#Data Reorganization\">Data Reorganization</a></li>\n",
    "<li><a href=\"#Data Exploration - Descriptive Statistics\">Data Exploration - Descriptive Statistics</a></li>\n",
    "<li><a href=\"#Exploratory Visualization\">Exploratory Visualization</a></li>\n",
    "<li><a href=\"#Preprocessing\">Preprocessing</a></li>\n",
    "<li><a href=\"#Benchmark: Logistic Regression\">Benchmark: Logistic Regression</a></li>\n",
    "<li><a href=\"#originalMLP\">Origial MLP</a></li>\n",
    "<li><a href=\"#conclusion\">Conclusion</a></li> \n",
    "<li><a href=\"#references\">References</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='introduction'></a>\n",
    "## INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Benchmark Logistic Regression'></a>\n",
    "## Benchmark Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary libraries for the logistic regression models.\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# This imports the AUC score for scoring the models.\n",
    "# This comes from Reference 27 in References.\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# These are libraries that will be needed to organize data,\n",
    "# graph data, and change the working directory.\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the no_nulls X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nonulls = pd.read_csv('no-peaking/Xtrain_nonulls.csv')\n",
    "Xtrain_nonulls = np.array(Xtrain_nonulls)\n",
    "Xtest_nonulls = pd.read_csv('no-peaking/Xtest_nonulls.csv')\n",
    "Xtest_nonulls = np.array(Xtest_nonulls)\n",
    "\n",
    "# This loads the no_nulls Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nonulls = pd.read_csv('no-peaking/Ytrain_nonulls.csv')\n",
    "Ytrain_nonulls = np.array(Ytrain_nonulls)\n",
    "Ytrain_nonulls = Ytrain_nonulls.ravel() \n",
    "Ytest_nonulls = pd.read_csv('no-peaking/Ytest_nonulls.csv')\n",
    "Ytest_nonulls = np.array(Ytest_nonulls)\n",
    "Ytest_nonulls = Ytest_nonulls.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing Hold-out Cross-Validation on just the training set\n",
    "K-fold Cross-Validation is a standard method for preventing a logistic regression model from overfitting. However, because the testing set, the fifth year of the dataset, is arbitrarily chosen (not random), K-fold Cross-Validation cannot be applied to the dataset (Reference 3). K-fold Cross-Validation would corrupt the testing set with data leakage considering that the dataset is a time-series set (Reference 3). To prevent data leakage, Hold-out cross-Validation will only be applied to the training set (References 3 & 4). Hold-out Cross-Validation takes a percentage of the training set as a validation set to test the accuracy of the model during the training stage. This method of cross validation, like all methods, is used to prevent the overfitting of a model and poor accuracy performance when applying the testing data to the fitted model (Reference 3)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No Nulls Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This import train_test_split from sklearn.\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the No Nulls dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nonulls, Xval_nonulls, Ytrain_nonulls, Yval_nonulls = train_test_split(\n",
    "                    Xtrain_nonulls, Ytrain_nonulls, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8506022247116249"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the No Nulls Dataset.\n",
    "log_nonulls = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_nonulls model with the training data.\n",
    "log_nonulls.fit(Xtrain_nonulls,Ytrain_nonulls)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nonulls = log_nonulls.predict(Xval_nonulls)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nonulls = roc_auc_score(Yval_nonulls, yval_pred_nonulls)\n",
    "VAL_auc_nonulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.3163.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nonulls = log_nonulls.predict(Xtest_nonulls)\n",
    "TEST_auc_nonulls = roc_auc_score(Ytest_nonulls, ytest_pred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_nonulls)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Nulls only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This loads the Nulls only training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_nullsonly = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_nullsonly = Xtrain_nullsonly.drop(\n",
    "    Xtrain_nullsonly.columns[64], axis=1)\n",
    "Xtrain_nullsonly = np.array(Xtrain_nullsonly)\n",
    "Xtest_nullsonly = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_nullsonly = Xtest_nullsonly.drop(\n",
    "    Xtest_nullsonly.columns[64], axis=1)\n",
    "Xtest_nullsonly = np.array(Xtest_nullsonly)\n",
    "\n",
    "# This loads the Nulls only Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_nullsonly = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_nullsonly = np.array(Ytrain_nullsonly)\n",
    "Ytrain_nullsonly = Ytrain_nullsonly.ravel() \n",
    "Ytest_nullsonly = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_nullsonly = np.array(Ytest_nullsonly)\n",
    "Ytest_nullsonly = Ytest_nullsonly.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nulls Only Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Sum dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_nullsonly, Xval_nullsonly, Ytrain_nullsonly, Yval_nullsonly = train_test_split(\n",
    "                    Xtrain_nullsonly, Ytrain_nullsonly, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7350826303765834"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the Nulls Only Dataset.\n",
    "log_nullsonly = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_nullsonly.fit(Xtrain_nullsonly,Ytrain_nullsonly)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_nullsonly = log_nullsonly.predict(Xval_nullsonly)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_nullsonly = roc_auc_score(Yval_nullsonly, yval_pred_nullsonly)\n",
    "VAL_auc_nullsonly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 68.29 %\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_nullsonly = log_nullsonly.predict(Xtest_nullsonly)\n",
    "TEST_auc_nullsonly = roc_auc_score(Ytest_nullsonly, ytest_pred_nullsonly)\n",
    "TEST_auc_nullsonly = TEST_auc_nullsonly * 100\n",
    "print(\"The AUC score for the model is %.2f\" % TEST_auc_nullsonly, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the one hot X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_onehot = pd.read_csv('no-peaking/Xtrain_onehot.csv')\n",
    "Xtrain_onehot = np.array(Xtrain_onehot)\n",
    "Xtest_onehot = pd.read_csv('no-peaking/Xtest_onehot.csv')\n",
    "Xtest_onehot = np.array(Xtest_onehot)\n",
    "\n",
    "# This loads the one hot Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_onehot = pd.read_csv('no-peaking/Ytrain_onehot.csv')\n",
    "Ytrain_onehot = np.array(Ytrain_onehot)\n",
    "Ytrain_onehot = Ytrain_onehot.ravel() \n",
    "Ytest_onehot = pd.read_csv('no-peaking/Ytest_onehot.csv')\n",
    "Ytest_onehot = np.array(Ytest_onehot)\n",
    "Ytest_onehot = Ytest_onehot.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the One Hot dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_onehot, Xval_onehot, Ytrain_onehot, Yval_onehot = train_test_split(\n",
    "                    Xtrain_onehot, Ytrain_onehot, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8647068328667264"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the One Hot Dataset.\n",
    "log_onehot = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_onehot.fit(Xtrain_onehot,Ytrain_onehot)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.\n",
    "yval_pred_onehot = log_onehot.predict(Xval_onehot)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_onehot = roc_auc_score(Yval_onehot, yval_pred_onehot)\n",
    "VAL_auc_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6406.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_onehot = log_onehot.predict(Xtest_onehot)\n",
    "TEST_auc_onehot = roc_auc_score(Ytest_onehot, ytest_pred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data: Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This loads the SUM X training and testing data\n",
    "# from the CSVs and converts the data to np.arrays.\n",
    "Xtrain_sum = pd.read_csv('no-peaking/Xtrain_sum.csv')\n",
    "Xtrain_sum = np.array(Xtrain_sum)\n",
    "Xtest_sum = pd.read_csv('no-peaking/Xtest_sum.csv')\n",
    "Xtest_sum = np.array(Xtest_sum)\n",
    "\n",
    "# This loads the no_nulls Y training and tesing data\n",
    "# from the CSVs. It also ravels the y_data, so only \n",
    "# rows are shown, not columns.\n",
    "Ytrain_sum = pd.read_csv('no-peaking/Ytrain_sum.csv')\n",
    "Ytrain_sum = np.array(Ytrain_sum)\n",
    "Ytrain_sum = Ytrain_sum.ravel() \n",
    "Ytest_sum = pd.read_csv('no-peaking/Ytest_sum.csv')\n",
    "Ytest_sum = np.array(Ytest_sum)\n",
    "Ytest_sum = Ytest_sum.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sum Logistic Regression Benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates the hold-out validation set for the logistic regression model\n",
    "# for the Sum dataset.\n",
    "# This comes from Reference 4 in References.\n",
    "Xtrain_sum, Xval_sum, Ytrain_sum, Yval_sum = train_test_split(\n",
    "                    Xtrain_sum, Ytrain_sum, test_size = 0.3, random_state = 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bgcam\\Anaconda3\\envs\\py36\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7437902237728553"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This creates the logistic regression model for the One Hot Dataset.\n",
    "log_sum = LogisticRegression(penalty='l2', max_iter=1000)\n",
    "\n",
    "# This fits the log_onehot model with the training data.\n",
    "log_sum.fit(Xtrain_sum,Ytrain_sum)\n",
    "\n",
    "# This predicts the y values from the Xval dataset.c\n",
    "yval_pred_sum = log_sum.predict(Xval_sum)\n",
    "\n",
    "# This returns the validation AUC score.\n",
    "VAL_auc_sum = roc_auc_score(Yval_sum, yval_pred_sum)\n",
    "VAL_auc_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6606.\n"
     ]
    }
   ],
   "source": [
    "# This tests the model, built on the training data, with the\n",
    "# testing data from year 5.\n",
    "ytest_pred_sum = log_sum.predict(Xtest_sum)\n",
    "TEST_auc_sum = roc_auc_score(Ytest_sum, ytest_pred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % TEST_auc_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MLP Model'></a>\n",
    "## MLP Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MLP Model No Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileExistsError",
     "evalue": "[WinError 183] Cannot create a file when that file already exists: 'saved_models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-0e0cd0986d66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This creates a directory to save the best models for the MLP.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'saved_models'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mFileExistsError\u001b[0m: [WinError 183] Cannot create a file when that file already exists: 'saved_models'"
     ]
    }
   ],
   "source": [
    "# This creates a directory to save the best models for the MLP.\n",
    "os.mkdir('saved_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This imports the necessary libraries for the MLP.\n",
    "\n",
    "# This imports the sequential model, the layers,\n",
    "# the SGD optimizer, the regularizers from keras.\n",
    "# This comes from Reference 5 in Referenes.\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Nadam\n",
    "from keras import regularizers\n",
    "\n",
    "# This imports checkpointer, which records the best weights\n",
    "# for the algorithm.\n",
    "# This comes from Reference 6 in References.\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(drop_rate, l2_factor, first_dense, second_dense,\n",
    "                third_dense, hidden_act, out_act, x):\n",
    "    dim_int = int(np.size(x,1))\n",
    "    # This defines the model as a sequential model.\n",
    "    # This comes from References 1 in References.\n",
    "    model = Sequential()\n",
    "\n",
    "    # This is the input layer.\n",
    "    # This comes from References 1 & 3 in References.\n",
    "    model.add(Dense(first_dense, activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor),\n",
    "        input_dim = dim_int))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the first hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(second_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "    \n",
    "    # This creates the second hidden layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(third_dense,\n",
    "        activation = hidden_act,\n",
    "        kernel_regularizer = regularizers.l2(l2_factor)))\n",
    "    model.add(Dropout(drop_rate))\n",
    "\n",
    "    # This creates the output layer.\n",
    "    # This comes from Reference 7 in References.\n",
    "    model.add(Dense(1, activation=out_act))\n",
    "    # This returns the model.\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_nonulls = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nonulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nonulls.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nonulls.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 11018 samples, validate on 2755 samples\n",
      "Epoch 1/100\n",
      "11018/11018 [==============================] - 4s 345us/step - loss: 0.8264 - acc: 0.5322 - val_loss: 0.7381 - val_acc: 0.6356\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.73808, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 2/100\n",
      "11018/11018 [==============================] - 1s 79us/step - loss: 0.8047 - acc: 0.5318 - val_loss: 0.7342 - val_acc: 0.6417\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.73808 to 0.73423, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 3/100\n",
      "11018/11018 [==============================] - 1s 90us/step - loss: 0.7925 - acc: 0.5381 - val_loss: 0.7316 - val_acc: 0.6472\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.73423 to 0.73160, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 4/100\n",
      "11018/11018 [==============================] - 1s 78us/step - loss: 0.7772 - acc: 0.5510 - val_loss: 0.7291 - val_acc: 0.6548\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73160 to 0.72911, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 5/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7760 - acc: 0.5470 - val_loss: 0.7273 - val_acc: 0.6566\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72911 to 0.72727, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 6/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7778 - acc: 0.5608 - val_loss: 0.7254 - val_acc: 0.6621\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.72727 to 0.72538, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 7/100\n",
      "11018/11018 [==============================] - 1s 84us/step - loss: 0.7642 - acc: 0.5509 - val_loss: 0.7237 - val_acc: 0.6672\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.72538 to 0.72365, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 8/100\n",
      "11018/11018 [==============================] - 1s 86us/step - loss: 0.7608 - acc: 0.5675 - val_loss: 0.7215 - val_acc: 0.6704\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72365 to 0.72154, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 9/100\n",
      "11018/11018 [==============================] - 1s 91us/step - loss: 0.7537 - acc: 0.5632 - val_loss: 0.7199 - val_acc: 0.6740\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.72154 to 0.71995, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 10/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7571 - acc: 0.5712 - val_loss: 0.7185 - val_acc: 0.6766\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.71995 to 0.71851, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 11/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7526 - acc: 0.5819 - val_loss: 0.7167 - val_acc: 0.6820\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.71851 to 0.71675, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 12/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.7483 - acc: 0.5748 - val_loss: 0.7152 - val_acc: 0.6828\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71675 to 0.71521, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 13/100\n",
      "11018/11018 [==============================] - 1s 78us/step - loss: 0.7433 - acc: 0.5850 - val_loss: 0.7134 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.71521 to 0.71335, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 14/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7458 - acc: 0.5766 - val_loss: 0.7119 - val_acc: 0.6933\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.71335 to 0.71189, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 15/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7481 - acc: 0.5791 - val_loss: 0.7105 - val_acc: 0.6984\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.71189 to 0.71046, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 16/100\n",
      "11018/11018 [==============================] - 1s 77us/step - loss: 0.7363 - acc: 0.5887 - val_loss: 0.7085 - val_acc: 0.6998\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.71046 to 0.70850, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 17/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7375 - acc: 0.6017 - val_loss: 0.7068 - val_acc: 0.7009\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.70850 to 0.70679, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 18/100\n",
      "11018/11018 [==============================] - 1s 77us/step - loss: 0.7355 - acc: 0.5931 - val_loss: 0.7050 - val_acc: 0.7045\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70679 to 0.70500, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 19/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7326 - acc: 0.5948 - val_loss: 0.7031 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70500 to 0.70314, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 20/100\n",
      "11018/11018 [==============================] - 1s 77us/step - loss: 0.7381 - acc: 0.5967 - val_loss: 0.7013 - val_acc: 0.7042\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.70314 to 0.70127, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 21/100\n",
      "11018/11018 [==============================] - 1s 79us/step - loss: 0.7325 - acc: 0.5959 - val_loss: 0.6996 - val_acc: 0.7071\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.70127 to 0.69956, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 22/100\n",
      "11018/11018 [==============================] - 1s 77us/step - loss: 0.7301 - acc: 0.5984 - val_loss: 0.6977 - val_acc: 0.7118\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.69956 to 0.69766, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 23/100\n",
      "11018/11018 [==============================] - 1s 78us/step - loss: 0.7239 - acc: 0.6125 - val_loss: 0.6958 - val_acc: 0.7143\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.69766 to 0.69579, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 24/100\n",
      "11018/11018 [==============================] - 1s 98us/step - loss: 0.7260 - acc: 0.5991 - val_loss: 0.6941 - val_acc: 0.7140\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.69579 to 0.69410, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 25/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.7213 - acc: 0.6007 - val_loss: 0.6922 - val_acc: 0.7151\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.69410 to 0.69216, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 26/100\n",
      "11018/11018 [==============================] - 1s 78us/step - loss: 0.7274 - acc: 0.6046 - val_loss: 0.6906 - val_acc: 0.7154\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.69216 to 0.69060, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 27/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.7196 - acc: 0.6105 - val_loss: 0.6885 - val_acc: 0.7158\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.69060 to 0.68847, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 28/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7220 - acc: 0.6110 - val_loss: 0.6865 - val_acc: 0.7172\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.68847 to 0.68650, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 29/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7138 - acc: 0.6149 - val_loss: 0.6843 - val_acc: 0.7187\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.68650 to 0.68429, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 30/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.7195 - acc: 0.6051 - val_loss: 0.6821 - val_acc: 0.7205\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.68429 to 0.68213, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 31/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.7172 - acc: 0.6073 - val_loss: 0.6805 - val_acc: 0.7201\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.68213 to 0.68046, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 32/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7215 - acc: 0.6118 - val_loss: 0.6789 - val_acc: 0.7234\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.68046 to 0.67888, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.7099 - acc: 0.6151 - val_loss: 0.6767 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.67888 to 0.67667, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 34/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7122 - acc: 0.6080 - val_loss: 0.6749 - val_acc: 0.7260\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.67667 to 0.67489, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 35/100\n",
      "11018/11018 [==============================] - 1s 74us/step - loss: 0.7108 - acc: 0.6163 - val_loss: 0.6727 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.67489 to 0.67273, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 36/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7091 - acc: 0.6108 - val_loss: 0.6709 - val_acc: 0.7267\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.67273 to 0.67088, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 37/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.7066 - acc: 0.6273 - val_loss: 0.6689 - val_acc: 0.7281\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.67088 to 0.66889, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 38/100\n",
      "11018/11018 [==============================] - 2s 136us/step - loss: 0.7070 - acc: 0.6271 - val_loss: 0.6672 - val_acc: 0.7289\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.66889 to 0.66720, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 39/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.7045 - acc: 0.6277 - val_loss: 0.6653 - val_acc: 0.7296\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.66720 to 0.66530, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 40/100\n",
      "11018/11018 [==============================] - 1s 77us/step - loss: 0.7053 - acc: 0.6314 - val_loss: 0.6634 - val_acc: 0.7310\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.66530 to 0.66344, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 41/100\n",
      "11018/11018 [==============================] - 1s 74us/step - loss: 0.7024 - acc: 0.6362 - val_loss: 0.6614 - val_acc: 0.7339\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.66344 to 0.66142, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 42/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.7122 - acc: 0.6308 - val_loss: 0.6598 - val_acc: 0.7343\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.66142 to 0.65981, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 43/100\n",
      "11018/11018 [==============================] - 1s 74us/step - loss: 0.7013 - acc: 0.6359 - val_loss: 0.6584 - val_acc: 0.7361\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.65981 to 0.65836, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 44/100\n",
      "11018/11018 [==============================] - 1s 74us/step - loss: 0.6941 - acc: 0.6384 - val_loss: 0.6562 - val_acc: 0.7365\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.65836 to 0.65619, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 45/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.6911 - acc: 0.6443 - val_loss: 0.6541 - val_acc: 0.7390\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.65619 to 0.65411, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 46/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.6960 - acc: 0.6441 - val_loss: 0.6522 - val_acc: 0.7405\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.65411 to 0.65216, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 47/100\n",
      "11018/11018 [==============================] - 1s 74us/step - loss: 0.6906 - acc: 0.6422 - val_loss: 0.6501 - val_acc: 0.7408\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.65216 to 0.65014, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 48/100\n",
      "11018/11018 [==============================] - 1s 76us/step - loss: 0.6914 - acc: 0.6518 - val_loss: 0.6481 - val_acc: 0.7430\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.65014 to 0.64812, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 49/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.6968 - acc: 0.6423 - val_loss: 0.6466 - val_acc: 0.7426\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.64812 to 0.64659, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 50/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.6933 - acc: 0.6400 - val_loss: 0.6452 - val_acc: 0.7470\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.64659 to 0.64525, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 51/100\n",
      "11018/11018 [==============================] - 1s 75us/step - loss: 0.6841 - acc: 0.6394 - val_loss: 0.6434 - val_acc: 0.7474\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.64525 to 0.64336, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 52/100\n",
      "11018/11018 [==============================] - 1s 79us/step - loss: 0.6830 - acc: 0.6462 - val_loss: 0.6415 - val_acc: 0.7503\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.64336 to 0.64152, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 53/100\n",
      "11018/11018 [==============================] - 1s 78us/step - loss: 0.6793 - acc: 0.6586 - val_loss: 0.6395 - val_acc: 0.7506\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.64152 to 0.63948, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 54/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6854 - acc: 0.6537 - val_loss: 0.6377 - val_acc: 0.7514\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.63948 to 0.63774, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 55/100\n",
      "11018/11018 [==============================] - 1s 87us/step - loss: 0.6864 - acc: 0.6526 - val_loss: 0.6361 - val_acc: 0.7521\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.63774 to 0.63606, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 56/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6878 - acc: 0.6478 - val_loss: 0.6347 - val_acc: 0.7528\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.63606 to 0.63474, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 57/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6853 - acc: 0.6486 - val_loss: 0.6334 - val_acc: 0.7539\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.63474 to 0.63339, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 58/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6763 - acc: 0.6584 - val_loss: 0.6314 - val_acc: 0.7572\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.63339 to 0.63143, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 59/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6790 - acc: 0.6567 - val_loss: 0.6297 - val_acc: 0.7583\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.63143 to 0.62973, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 60/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6770 - acc: 0.6619 - val_loss: 0.6281 - val_acc: 0.7590\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.62973 to 0.62806, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 61/100\n",
      "11018/11018 [==============================] - 1s 79us/step - loss: 0.6760 - acc: 0.6606 - val_loss: 0.6261 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.62806 to 0.62610, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 62/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6754 - acc: 0.6609 - val_loss: 0.6246 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.62610 to 0.62455, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 63/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6754 - acc: 0.6620 - val_loss: 0.6231 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.62455 to 0.62309, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 64/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6816 - acc: 0.6645 - val_loss: 0.6218 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.62309 to 0.62178, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 65/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11018/11018 [==============================] - 1s 79us/step - loss: 0.6765 - acc: 0.6641 - val_loss: 0.6205 - val_acc: 0.7597\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.62178 to 0.62047, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 66/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6708 - acc: 0.6656 - val_loss: 0.6190 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.62047 to 0.61903, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 67/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6681 - acc: 0.6704 - val_loss: 0.6173 - val_acc: 0.7608\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.61903 to 0.61727, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 68/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6745 - acc: 0.6606 - val_loss: 0.6162 - val_acc: 0.7601\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.61727 to 0.61624, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 69/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6692 - acc: 0.6654 - val_loss: 0.6149 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.61624 to 0.61494, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 70/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6668 - acc: 0.6678 - val_loss: 0.6135 - val_acc: 0.7604\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.61494 to 0.61351, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 71/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6678 - acc: 0.6669 - val_loss: 0.6123 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.61351 to 0.61232, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 72/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6665 - acc: 0.6660 - val_loss: 0.6111 - val_acc: 0.7615\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.61232 to 0.61106, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 73/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6659 - acc: 0.6695 - val_loss: 0.6099 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.61106 to 0.60991, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 74/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6608 - acc: 0.6757 - val_loss: 0.6083 - val_acc: 0.7626\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.60991 to 0.60831, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 75/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6626 - acc: 0.6693 - val_loss: 0.6069 - val_acc: 0.7630\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.60831 to 0.60694, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 76/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6633 - acc: 0.6749 - val_loss: 0.6059 - val_acc: 0.7633\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.60694 to 0.60594, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 77/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6694 - acc: 0.6734 - val_loss: 0.6049 - val_acc: 0.7648\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.60594 to 0.60486, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 78/100\n",
      "11018/11018 [==============================] - 1s 83us/step - loss: 0.6627 - acc: 0.6737 - val_loss: 0.6035 - val_acc: 0.7644\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.60486 to 0.60350, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 79/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6559 - acc: 0.6781 - val_loss: 0.6019 - val_acc: 0.7652\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.60350 to 0.60193, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 80/100\n",
      "11018/11018 [==============================] - 1s 82us/step - loss: 0.6567 - acc: 0.6701 - val_loss: 0.6005 - val_acc: 0.7655\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.60193 to 0.60046, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 81/100\n",
      "11018/11018 [==============================] - 1s 80us/step - loss: 0.6649 - acc: 0.6741 - val_loss: 0.5999 - val_acc: 0.7662\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.60046 to 0.59992, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 82/100\n",
      "11018/11018 [==============================] - 1s 81us/step - loss: 0.6542 - acc: 0.6783 - val_loss: 0.5983 - val_acc: 0.7673\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.59992 to 0.59834, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 83/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6584 - acc: 0.6744 - val_loss: 0.5972 - val_acc: 0.7688\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.59834 to 0.59721, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 84/100\n",
      "11018/11018 [==============================] - 1s 100us/step - loss: 0.6624 - acc: 0.6715 - val_loss: 0.5964 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.59721 to 0.59637, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 85/100\n",
      "11018/11018 [==============================] - 1s 100us/step - loss: 0.6550 - acc: 0.6773 - val_loss: 0.5953 - val_acc: 0.7702\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.59637 to 0.59533, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 86/100\n",
      "11018/11018 [==============================] - 1s 110us/step - loss: 0.6566 - acc: 0.6684 - val_loss: 0.5944 - val_acc: 0.7699\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.59533 to 0.59440, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 87/100\n",
      "11018/11018 [==============================] - 1s 95us/step - loss: 0.6515 - acc: 0.6844 - val_loss: 0.5932 - val_acc: 0.7706\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.59440 to 0.59320, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 88/100\n",
      "11018/11018 [==============================] - 1s 88us/step - loss: 0.6564 - acc: 0.6825 - val_loss: 0.5920 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.59320 to 0.59204, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 89/100\n",
      "11018/11018 [==============================] - 1s 93us/step - loss: 0.6502 - acc: 0.6798 - val_loss: 0.5909 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.59204 to 0.59089, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 90/100\n",
      "11018/11018 [==============================] - 1s 94us/step - loss: 0.6543 - acc: 0.6824 - val_loss: 0.5898 - val_acc: 0.7721\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.59089 to 0.58979, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 91/100\n",
      "11018/11018 [==============================] - 1s 94us/step - loss: 0.6504 - acc: 0.6854 - val_loss: 0.5886 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.58979 to 0.58865, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 92/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6491 - acc: 0.6803 - val_loss: 0.5875 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.58865 to 0.58752, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 93/100\n",
      "11018/11018 [==============================] - 1s 91us/step - loss: 0.6456 - acc: 0.6880 - val_loss: 0.5862 - val_acc: 0.7728\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.58752 to 0.58624, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 94/100\n",
      "11018/11018 [==============================] - 1s 91us/step - loss: 0.6516 - acc: 0.6793 - val_loss: 0.5854 - val_acc: 0.7717\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.58624 to 0.58538, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 95/100\n",
      "11018/11018 [==============================] - 1s 91us/step - loss: 0.6466 - acc: 0.6845 - val_loss: 0.5843 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.58538 to 0.58425, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 96/100\n",
      "11018/11018 [==============================] - 1s 90us/step - loss: 0.6452 - acc: 0.6878 - val_loss: 0.5829 - val_acc: 0.7728\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.58425 to 0.58291, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 97/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11018/11018 [==============================] - 1s 104us/step - loss: 0.6408 - acc: 0.6884 - val_loss: 0.5817 - val_acc: 0.7731\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.58291 to 0.58167, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 98/100\n",
      "11018/11018 [==============================] - 1s 99us/step - loss: 0.6441 - acc: 0.6893 - val_loss: 0.5804 - val_acc: 0.7739\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.58167 to 0.58042, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 99/100\n",
      "11018/11018 [==============================] - 1s 96us/step - loss: 0.6463 - acc: 0.6838 - val_loss: 0.5796 - val_acc: 0.7742\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.58042 to 0.57961, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n",
      "Epoch 100/100\n",
      "11018/11018 [==============================] - 1s 89us/step - loss: 0.6462 - acc: 0.6819 - val_loss: 0.5788 - val_acc: 0.7746\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.57961 to 0.57879, saving model to saved_models/weights.best.mlp_nonulls.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efc2029a90>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nonulls.fit(Xtrain_nonulls, Ytrain_nonulls, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nonulls.load_weights('saved_models/weights.best.mlp_nonulls.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 96.1937%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nonulls.evaluate(Xtest_nonulls, Ytest_nonulls, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.5130.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nonulls = mlp_nonulls.predict(Xtest_nonulls)\n",
    "mlp_nonulls_ROC = roc_auc_score(Ytest_nonulls, Ypred_nonulls)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nonulls_ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Nulls Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_nullsonly = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_nullsonly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_nullsonly.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_nullsonly.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 9s 188us/step - loss: 0.8213 - acc: 0.5411 - val_loss: 0.7852 - val_acc: 0.6725\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.78523, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 7s 145us/step - loss: 0.8079 - acc: 0.5901 - val_loss: 0.7668 - val_acc: 0.6790\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.78523 to 0.76681, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.7964 - acc: 0.6107 - val_loss: 0.7541 - val_acc: 0.6829\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.76681 to 0.75406, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.7863 - acc: 0.6258 - val_loss: 0.7446 - val_acc: 0.6857\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.75406 to 0.74457, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.7786 - acc: 0.6354 - val_loss: 0.7370 - val_acc: 0.6870\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.74457 to 0.73697, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 6s 125us/step - loss: 0.7756 - acc: 0.6393 - val_loss: 0.7319 - val_acc: 0.6879\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.73697 to 0.73190, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7736 - acc: 0.6426 - val_loss: 0.7279 - val_acc: 0.6878\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.73190 to 0.72787, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.7662 - acc: 0.6456 - val_loss: 0.7243 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.72787 to 0.72434, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.7649 - acc: 0.6474 - val_loss: 0.7217 - val_acc: 0.6886\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.72434 to 0.72166, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.7634 - acc: 0.6497 - val_loss: 0.7196 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.72166 to 0.71963, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 10s 218us/step - loss: 0.7614 - acc: 0.6550 - val_loss: 0.7176 - val_acc: 0.6904\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.71963 to 0.71759, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 16s 351us/step - loss: 0.7591 - acc: 0.6535 - val_loss: 0.7157 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.71759 to 0.71573, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 16s 343us/step - loss: 0.7576 - acc: 0.6550 - val_loss: 0.7143 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.71573 to 0.71433, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 13s 293us/step - loss: 0.7549 - acc: 0.6569 - val_loss: 0.7130 - val_acc: 0.6906\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.71433 to 0.71300, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 16s 344us/step - loss: 0.7534 - acc: 0.6586 - val_loss: 0.7115 - val_acc: 0.6910\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.71300 to 0.71146, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 13s 281us/step - loss: 0.7545 - acc: 0.6590 - val_loss: 0.7101 - val_acc: 0.6915\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.71146 to 0.71014, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 12s 265us/step - loss: 0.7503 - acc: 0.6647 - val_loss: 0.7086 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.71014 to 0.70862, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 14s 302us/step - loss: 0.7533 - acc: 0.6622 - val_loss: 0.7077 - val_acc: 0.6918ss: \n",
      "\n",
      "Epoch 00018: val_loss improved from 0.70862 to 0.70767, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 11s 247us/step - loss: 0.7466 - acc: 0.6655 - val_loss: 0.7060 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.70767 to 0.70601, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 10s 218us/step - loss: 0.7448 - acc: 0.6656 - val_loss: 0.7044 - val_acc: 0.6921\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.70601 to 0.70445, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 13s 280us/step - loss: 0.7440 - acc: 0.6653 - val_loss: 0.7035 - val_acc: 0.6922\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.70445 to 0.70350, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 9s 201us/step - loss: 0.7442 - acc: 0.6657 - val_loss: 0.7023 - val_acc: 0.6929\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.70350 to 0.70232, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 10s 217us/step - loss: 0.7404 - acc: 0.6686 - val_loss: 0.7012 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.70232 to 0.70117, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 10s 225us/step - loss: 0.7386 - acc: 0.6696 - val_loss: 0.7001 - val_acc: 0.6935\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.70117 to 0.70013, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 8s 170us/step - loss: 0.7385 - acc: 0.6712 - val_loss: 0.6989 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.70013 to 0.69894, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 8s 179us/step - loss: 0.7396 - acc: 0.6733 - val_loss: 0.6978 - val_acc: 0.6941\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.69894 to 0.69776, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 10s 211us/step - loss: 0.7361 - acc: 0.6725 - val_loss: 0.6968 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.69776 to 0.69680, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 9s 192us/step - loss: 0.7324 - acc: 0.6736 - val_loss: 0.6958 - val_acc: 0.6951\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.69680 to 0.69582, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 11s 231us/step - loss: 0.7318 - acc: 0.6765 - val_loss: 0.6946 - val_acc: 0.6954\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.69582 to 0.69457, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 8s 176us/step - loss: 0.7339 - acc: 0.6746 - val_loss: 0.6938 - val_acc: 0.6960\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.69457 to 0.69385, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 10s 208us/step - loss: 0.7273 - acc: 0.6775 - val_loss: 0.6928 - val_acc: 0.6963\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.69385 to 0.69282, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 7s 154us/step - loss: 0.7305 - acc: 0.6777 - val_loss: 0.6917 - val_acc: 0.6968\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00032: val_loss improved from 0.69282 to 0.69174, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 33/100\n",
      "45858/45858 [==============================] - 6s 136us/step - loss: 0.7248 - acc: 0.6773 - val_loss: 0.6907 - val_acc: 0.6967\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.69174 to 0.69071, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 7s 146us/step - loss: 0.7271 - acc: 0.6798 - val_loss: 0.6898 - val_acc: 0.6970\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.69071 to 0.68977, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 9s 187us/step - loss: 0.7245 - acc: 0.6782 - val_loss: 0.6888 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.68977 to 0.68881, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 6s 140us/step - loss: 0.7218 - acc: 0.6790 - val_loss: 0.6878 - val_acc: 0.6975\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.68881 to 0.68778, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 6s 133us/step - loss: 0.7246 - acc: 0.6797 - val_loss: 0.6872 - val_acc: 0.6980\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.68778 to 0.68725, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 6s 134us/step - loss: 0.7214 - acc: 0.6820 - val_loss: 0.6865 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.68725 to 0.68652, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 6s 125us/step - loss: 0.7186 - acc: 0.6825 - val_loss: 0.6854 - val_acc: 0.6983\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.68652 to 0.68538, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 40/100\n",
      "45858/45858 [==============================] - 6s 122us/step - loss: 0.7206 - acc: 0.6830 - val_loss: 0.6846 - val_acc: 0.6987\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.68538 to 0.68457, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 6s 126us/step - loss: 0.7185 - acc: 0.6827 - val_loss: 0.6835 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.68457 to 0.68350, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 6s 136us/step - loss: 0.7189 - acc: 0.6833 - val_loss: 0.6827 - val_acc: 0.6993\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.68350 to 0.68265, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 7s 157us/step - loss: 0.7151 - acc: 0.6856 - val_loss: 0.6817 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.68265 to 0.68166, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 7s 160us/step - loss: 0.7160 - acc: 0.6830 - val_loss: 0.6809 - val_acc: 0.6999\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.68166 to 0.68087, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 6s 124us/step - loss: 0.7173 - acc: 0.6842 - val_loss: 0.6804 - val_acc: 0.6998\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.68087 to 0.68041, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 7s 146us/step - loss: 0.7152 - acc: 0.6853 - val_loss: 0.6795 - val_acc: 0.7001\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.68041 to 0.67948, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.7127 - acc: 0.6855 - val_loss: 0.6787 - val_acc: 0.7008\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.67948 to 0.67865, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.7131 - acc: 0.6862 - val_loss: 0.6778 - val_acc: 0.7011\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.67865 to 0.67776, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7105 - acc: 0.6870 - val_loss: 0.6769 - val_acc: 0.7010\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.67776 to 0.67687, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7119 - acc: 0.6881 - val_loss: 0.6759 - val_acc: 0.7018\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.67687 to 0.67587, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.7129 - acc: 0.6868 - val_loss: 0.6749 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.67587 to 0.67486, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.7092 - acc: 0.6881 - val_loss: 0.6739 - val_acc: 0.7025\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.67486 to 0.67391, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 6s 137us/step - loss: 0.7081 - acc: 0.6873 - val_loss: 0.6729 - val_acc: 0.7023\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.67391 to 0.67293, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.7093 - acc: 0.6886 - val_loss: 0.6720 - val_acc: 0.7025\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.67293 to 0.67198, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 6s 120us/step - loss: 0.7057 - acc: 0.6897 - val_loss: 0.6710 - val_acc: 0.7028\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.67198 to 0.67097, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.7040 - acc: 0.6881 - val_loss: 0.6700 - val_acc: 0.7034\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.67097 to 0.67005, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7012 - acc: 0.6909 - val_loss: 0.6689 - val_acc: 0.7037\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.67005 to 0.66893, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.7034 - acc: 0.6905 - val_loss: 0.6679 - val_acc: 0.7033\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.66893 to 0.66793, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.7018 - acc: 0.6938 - val_loss: 0.6669 - val_acc: 0.7036\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.66793 to 0.66689, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.6997 - acc: 0.6911 - val_loss: 0.6659 - val_acc: 0.7047\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.66689 to 0.66593, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.7008 - acc: 0.6933 - val_loss: 0.6650 - val_acc: 0.7056\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.66593 to 0.66502, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.7010 - acc: 0.6940 - val_loss: 0.6641 - val_acc: 0.7055\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.66502 to 0.66409, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6977 - acc: 0.6927 - val_loss: 0.6630 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.66409 to 0.66295, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 64/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6967 - acc: 0.6939 - val_loss: 0.6621 - val_acc: 0.7066\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.66295 to 0.66214, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 65/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.6953 - acc: 0.6953 - val_loss: 0.6610 - val_acc: 0.7075\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.66214 to 0.66098, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 66/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6970 - acc: 0.6953 - val_loss: 0.6602 - val_acc: 0.7082\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.66098 to 0.66024, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6948 - acc: 0.6971 - val_loss: 0.6593 - val_acc: 0.7089\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.66024 to 0.65934, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6945 - acc: 0.6962 - val_loss: 0.6584 - val_acc: 0.7094\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.65934 to 0.65836, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6946 - acc: 0.6977 - val_loss: 0.6574 - val_acc: 0.7100\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.65836 to 0.65739, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6925 - acc: 0.6981 - val_loss: 0.6566 - val_acc: 0.7105\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.65739 to 0.65657, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6904 - acc: 0.7001 - val_loss: 0.6557 - val_acc: 0.7116\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.65657 to 0.65565, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.6890 - acc: 0.6994 - val_loss: 0.6545 - val_acc: 0.7132\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.65565 to 0.65452, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6873 - acc: 0.6997 - val_loss: 0.6535 - val_acc: 0.7137\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.65452 to 0.65352, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.6889 - acc: 0.7011 - val_loss: 0.6528 - val_acc: 0.7144\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.65352 to 0.65276, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6864 - acc: 0.7030 - val_loss: 0.6517 - val_acc: 0.7149\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.65276 to 0.65166, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.6868 - acc: 0.6984 - val_loss: 0.6508 - val_acc: 0.7150\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.65166 to 0.65080, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6841 - acc: 0.7005 - val_loss: 0.6498 - val_acc: 0.7160\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.65080 to 0.64979, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6856 - acc: 0.7035 - val_loss: 0.6491 - val_acc: 0.7154\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.64979 to 0.64913, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.6828 - acc: 0.7006 - val_loss: 0.6480 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.64913 to 0.64802, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.6809 - acc: 0.7048 - val_loss: 0.6470 - val_acc: 0.7159\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.64802 to 0.64696, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6832 - acc: 0.7037 - val_loss: 0.6463 - val_acc: 0.7164\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.64696 to 0.64632, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 82/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.6797 - acc: 0.7054 - val_loss: 0.6452 - val_acc: 0.7170\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.64632 to 0.64522, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6809 - acc: 0.7022 - val_loss: 0.6446 - val_acc: 0.7180\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.64522 to 0.64461, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.6807 - acc: 0.7055 - val_loss: 0.6436 - val_acc: 0.7186\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.64461 to 0.64365, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6803 - acc: 0.7062 - val_loss: 0.6429 - val_acc: 0.7190\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.64365 to 0.64291, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6767 - acc: 0.7062 - val_loss: 0.6419 - val_acc: 0.7200\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.64291 to 0.64195, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6799 - acc: 0.7074 - val_loss: 0.6412 - val_acc: 0.7206\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.64195 to 0.64121, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.6763 - acc: 0.7060 - val_loss: 0.6403 - val_acc: 0.7215\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.64121 to 0.64033, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6756 - acc: 0.7063 - val_loss: 0.6395 - val_acc: 0.7217\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.64033 to 0.63949, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.6740 - acc: 0.7061 - val_loss: 0.6385 - val_acc: 0.7218\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.63949 to 0.63845, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6734 - acc: 0.7085 - val_loss: 0.6377 - val_acc: 0.7230\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.63845 to 0.63769, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6716 - acc: 0.7092 - val_loss: 0.6369 - val_acc: 0.7240\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.63769 to 0.63694, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6741 - acc: 0.7090 - val_loss: 0.6363 - val_acc: 0.7246\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.63694 to 0.63627, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.6727 - acc: 0.7085 - val_loss: 0.6355 - val_acc: 0.7256\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.63627 to 0.63552, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.6713 - acc: 0.7113 - val_loss: 0.6346 - val_acc: 0.7262\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.63552 to 0.63457, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.6711 - acc: 0.7103 - val_loss: 0.6338 - val_acc: 0.7269\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.63457 to 0.63379, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 97/100\n",
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.6694 - acc: 0.7122 - val_loss: 0.6332 - val_acc: 0.7279\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.63379 to 0.63323, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.6674 - acc: 0.7115 - val_loss: 0.6324 - val_acc: 0.7272\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.63323 to 0.63241, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 99/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.6670 - acc: 0.7106 - val_loss: 0.6317 - val_acc: 0.7273\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.63241 to 0.63174, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.6682 - acc: 0.7131 - val_loss: 0.6310 - val_acc: 0.7280\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.63174 to 0.63095, saving model to saved_models/weights.best.mlp_nullsonly.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efbb8c4ba8>"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_nullsonly.fit(Xtrain_nullsonly, Ytrain_nullsonly, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_nullsonly.load_weights('saved_models/weights.best.mlp_nullsonly.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 71.8531%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_nullsonly.evaluate(Xtest_nullsonly, Ytest_nullsonly, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6277.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_nullsonly= mlp_nullsonly.predict(Xtest_nullsonly)\n",
    "mlp_nullsonly_ROC = roc_auc_score(Ytest_nullsonly, Ypred_nullsonly)\n",
    "print(\"The AUC score for the model is %.4f.\" % mlp_nullsonly_ROC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model One Hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_onehot = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=64,\n",
    "                             second_dense=32,\n",
    "                             third_dense=16,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_onehot.compile(loss='binary_crossentropy',\n",
    "              optimizer= RMS,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_onehot.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 7s 161us/step - loss: 0.5588 - acc: 0.8025 - val_loss: 0.3994 - val_acc: 0.8570\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.39939, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.4284 - acc: 0.8539 - val_loss: 0.3750 - val_acc: 0.8645\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.39939 to 0.37504, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.4013 - acc: 0.8565 - val_loss: 0.3689 - val_acc: 0.8634\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.37504 to 0.36887, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 4s 92us/step - loss: 0.3918 - acc: 0.8569 - val_loss: 0.3569 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.36887 to 0.35693, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 4s 88us/step - loss: 0.3864 - acc: 0.8600 - val_loss: 0.3508 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.35693 to 0.35077, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 4s 93us/step - loss: 0.3814 - acc: 0.8601 - val_loss: 0.3498 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.35077 to 0.34978, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3793 - acc: 0.8597 - val_loss: 0.3513 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.34978\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3784 - acc: 0.8588 - val_loss: 0.3578 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.34978\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 4s 89us/step - loss: 0.3738 - acc: 0.8606 - val_loss: 0.3550 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.34978\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3769 - acc: 0.8594 - val_loss: 0.3691 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.34978\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.3774 - acc: 0.8582 - val_loss: 0.3479 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.34978 to 0.34788, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.3775 - acc: 0.8580 - val_loss: 0.3523 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.34788\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3813 - acc: 0.8594 - val_loss: 0.3479 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.34788 to 0.34786, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.3753 - acc: 0.8592 - val_loss: 0.3510 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.34786\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3790 - acc: 0.8581 - val_loss: 0.3571 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.34786\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3747 - acc: 0.8589 - val_loss: 0.3480 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.34786\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.3787 - acc: 0.8590 - val_loss: 0.3516 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.34786\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.3752 - acc: 0.8583 - val_loss: 0.3457 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.34786 to 0.34569, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3800 - acc: 0.8570 - val_loss: 0.3564 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.34569\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3775 - acc: 0.8581 - val_loss: 0.3543 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.34569\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3755 - acc: 0.8588 - val_loss: 0.3516 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.34569\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.3755 - acc: 0.8593 - val_loss: 0.3471 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.34569\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3753 - acc: 0.8584 - val_loss: 0.3551 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.34569\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 4s 95us/step - loss: 0.3779 - acc: 0.8575 - val_loss: 0.3572 - val_acc: 0.8595\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.34569\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3812 - acc: 0.8588 - val_loss: 0.3464 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.34569\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.3760 - acc: 0.8598 - val_loss: 0.3493 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.34569\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.3732 - acc: 0.8604 - val_loss: 0.3480 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.34569\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3758 - acc: 0.8594 - val_loss: 0.3510 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.34569\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3784 - acc: 0.8586 - val_loss: 0.3574 - val_acc: 0.8574\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.34569\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3771 - acc: 0.8592 - val_loss: 0.3575 - val_acc: 0.8661\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.34569\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3761 - acc: 0.8592 - val_loss: 0.3519 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.34569\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3755 - acc: 0.8602 - val_loss: 0.3486 - val_acc: 0.8648\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.34569\n",
      "Epoch 33/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3764 - acc: 0.8586 - val_loss: 0.3512 - val_acc: 0.8650\n",
      "\n",
      "Epoch 00033: val_loss did not improve from 0.34569\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3771 - acc: 0.8583 - val_loss: 0.3508 - val_acc: 0.8654\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.34569\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3783 - acc: 0.8581 - val_loss: 0.3525 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.34569\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3758 - acc: 0.8587 - val_loss: 0.3593 - val_acc: 0.8613\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.34569\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3777 - acc: 0.8585 - val_loss: 0.3546 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.34569\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.3756 - acc: 0.8588 - val_loss: 0.3527 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.34569\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.3730 - acc: 0.8585 - val_loss: 0.3446 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.34569 to 0.34459, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 40/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3749 - acc: 0.8591 - val_loss: 0.3435 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.34459 to 0.34348, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3753 - acc: 0.8581 - val_loss: 0.3479 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.34348\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3760 - acc: 0.8584 - val_loss: 0.3413 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.34348 to 0.34133, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3750 - acc: 0.8578 - val_loss: 0.3474 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00043: val_loss did not improve from 0.34133\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3723 - acc: 0.8606 - val_loss: 0.3472 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.34133\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.3763 - acc: 0.8578 - val_loss: 0.3551 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00045: val_loss did not improve from 0.34133\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3803 - acc: 0.8585 - val_loss: 0.3515 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00046: val_loss did not improve from 0.34133\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3755 - acc: 0.8570 - val_loss: 0.3460 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00047: val_loss did not improve from 0.34133\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3725 - acc: 0.8570 - val_loss: 0.3490 - val_acc: 0.8672\n",
      "\n",
      "Epoch 00048: val_loss did not improve from 0.34133\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3779 - acc: 0.8577 - val_loss: 0.3418 - val_acc: 0.8676\n",
      "\n",
      "Epoch 00049: val_loss did not improve from 0.34133\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 4s 94us/step - loss: 0.3781 - acc: 0.8586 - val_loss: 0.3447 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00050: val_loss did not improve from 0.34133\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3776 - acc: 0.8580 - val_loss: 0.3453 - val_acc: 0.8664\n",
      "\n",
      "Epoch 00051: val_loss did not improve from 0.34133\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3774 - acc: 0.8577 - val_loss: 0.3482 - val_acc: 0.8700\n",
      "\n",
      "Epoch 00052: val_loss did not improve from 0.34133\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3765 - acc: 0.8584 - val_loss: 0.3528 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00053: val_loss did not improve from 0.34133\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.3721 - acc: 0.8586 - val_loss: 0.3487 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00054: val_loss did not improve from 0.34133\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3718 - acc: 0.8588 - val_loss: 0.3483 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00055: val_loss did not improve from 0.34133\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.3755 - acc: 0.8584 - val_loss: 0.3398 - val_acc: 0.8669\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.34133 to 0.33980, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3767 - acc: 0.8576 - val_loss: 0.3445 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.33980\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3776 - acc: 0.8575 - val_loss: 0.3431 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00058: val_loss did not improve from 0.33980\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3741 - acc: 0.8583 - val_loss: 0.3505 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00059: val_loss did not improve from 0.33980\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3728 - acc: 0.8595 - val_loss: 0.3415 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.33980\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3770 - acc: 0.8585 - val_loss: 0.3593 - val_acc: 0.8652\n",
      "\n",
      "Epoch 00061: val_loss did not improve from 0.33980\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.3761 - acc: 0.8590 - val_loss: 0.3406 - val_acc: 0.8680\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.33980\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.3833 - acc: 0.8577 - val_loss: 0.3486 - val_acc: 0.8597\n",
      "\n",
      "Epoch 00063: val_loss did not improve from 0.33980\n",
      "Epoch 64/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3780 - acc: 0.8575 - val_loss: 0.3595 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00064: val_loss did not improve from 0.33980\n",
      "Epoch 65/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.3780 - acc: 0.8588 - val_loss: 0.3480 - val_acc: 0.8685\n",
      "\n",
      "Epoch 00065: val_loss did not improve from 0.33980\n",
      "Epoch 66/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3776 - acc: 0.8596 - val_loss: 0.3429 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.33980\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3762 - acc: 0.8587 - val_loss: 0.3445 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.33980\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.3770 - acc: 0.8600 - val_loss: 0.3463 - val_acc: 0.8660\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.33980\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.3771 - acc: 0.8585 - val_loss: 0.3436 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00069: val_loss did not improve from 0.33980\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3741 - acc: 0.8578 - val_loss: 0.3545 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.33980\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3776 - acc: 0.8581 - val_loss: 0.3432 - val_acc: 0.8666\n",
      "\n",
      "Epoch 00071: val_loss did not improve from 0.33980\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.3760 - acc: 0.8593 - val_loss: 0.3433 - val_acc: 0.8649\n",
      "\n",
      "Epoch 00072: val_loss did not improve from 0.33980\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3787 - acc: 0.8599 - val_loss: 0.3403 - val_acc: 0.8655\n",
      "\n",
      "Epoch 00073: val_loss did not improve from 0.33980\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3773 - acc: 0.8574 - val_loss: 0.3423 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.33980\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.3736 - acc: 0.8588 - val_loss: 0.3537 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.33980\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.3746 - acc: 0.8581 - val_loss: 0.3428 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00076: val_loss did not improve from 0.33980\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.3725 - acc: 0.8594 - val_loss: 0.3449 - val_acc: 0.8659\n",
      "\n",
      "Epoch 00077: val_loss did not improve from 0.33980\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.3758 - acc: 0.8585 - val_loss: 0.3415 - val_acc: 0.8671\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.33980\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.3727 - acc: 0.8588 - val_loss: 0.3505 - val_acc: 0.8658\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.33980\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3750 - acc: 0.8583 - val_loss: 0.3460 - val_acc: 0.8677\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.33980\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.3758 - acc: 0.8588 - val_loss: 0.3413 - val_acc: 0.8674\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.33980\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3735 - acc: 0.8577 - val_loss: 0.3441 - val_acc: 0.8656\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.33980\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3800 - acc: 0.8580 - val_loss: 0.3479 - val_acc: 0.8641\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.33980\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3733 - acc: 0.8592 - val_loss: 0.3413 - val_acc: 0.8675\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.33980\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.3754 - acc: 0.8592 - val_loss: 0.3488 - val_acc: 0.8681\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.33980\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.3766 - acc: 0.8578 - val_loss: 0.3459 - val_acc: 0.8646\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.33980\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.3726 - acc: 0.8595 - val_loss: 0.3403 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.33980\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3762 - acc: 0.8593 - val_loss: 0.3393 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.33980 to 0.33933, saving model to saved_models/weights.best.mlp_onehot.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.3780 - acc: 0.8583 - val_loss: 0.3474 - val_acc: 0.8653\n",
      "\n",
      "Epoch 00089: val_loss did not improve from 0.33933\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.3738 - acc: 0.8572 - val_loss: 0.3435 - val_acc: 0.8668\n",
      "\n",
      "Epoch 00090: val_loss did not improve from 0.33933\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.3755 - acc: 0.8586 - val_loss: 0.3398 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00091: val_loss did not improve from 0.33933\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.3748 - acc: 0.8578 - val_loss: 0.3578 - val_acc: 0.8629\n",
      "\n",
      "Epoch 00092: val_loss did not improve from 0.33933\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.3802 - acc: 0.8594 - val_loss: 0.3472 - val_acc: 0.8665\n",
      "\n",
      "Epoch 00093: val_loss did not improve from 0.33933\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3736 - acc: 0.8608 - val_loss: 0.3517 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00094: val_loss did not improve from 0.33933\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.3769 - acc: 0.8591 - val_loss: 0.3465 - val_acc: 0.8686\n",
      "\n",
      "Epoch 00095: val_loss did not improve from 0.33933\n",
      "Epoch 96/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.3761 - acc: 0.8574 - val_loss: 0.3410 - val_acc: 0.8673\n",
      "\n",
      "Epoch 00096: val_loss did not improve from 0.33933\n",
      "Epoch 97/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.3716 - acc: 0.8573 - val_loss: 0.3457 - val_acc: 0.8683\n",
      "\n",
      "Epoch 00097: val_loss did not improve from 0.33933\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3776 - acc: 0.8584 - val_loss: 0.3422 - val_acc: 0.8679\n",
      "\n",
      "Epoch 00098: val_loss did not improve from 0.33933\n",
      "Epoch 99/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.3785 - acc: 0.8591 - val_loss: 0.3464 - val_acc: 0.8693\n",
      "\n",
      "Epoch 00099: val_loss did not improve from 0.33933\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 5s 106us/step - loss: 0.3805 - acc: 0.8582 - val_loss: 0.3404 - val_acc: 0.8662\n",
      "\n",
      "Epoch 00100: val_loss did not improve from 0.33933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efb9539630>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_onehot.fit(Xtrain_onehot, Ytrain_onehot, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_onehot.load_weights('saved_models/weights.best.mlp_onehot.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 81.1686%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_onehot.evaluate(Xtest_onehot, Ytest_onehot, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.7063.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_onehot = mlp_onehot.predict(Xtest_onehot)\n",
    "ROC_mlp_onehot = roc_auc_score(Ytest_onehot, Ypred_onehot)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_onehot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Model Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This comes from Reference 7 in References.\n",
    "n_epochs = 100\n",
    "size_of_batch = 50\n",
    "stochastic = SGD(lr=0.001)\n",
    "nad = Nadam()\n",
    "RMS = RMSprop()\n",
    "\n",
    "# This builds the original MLP model for year 1.\n",
    "# using Mattson and Steinart's original hyperparameters.\n",
    "mlp_sum = build_model(drop_rate=0.5,\n",
    "                            l2_factor=0.001,\n",
    "                             first_dense=32,\n",
    "                             second_dense=16,\n",
    "                             third_dense=8,\n",
    "                            hidden_act='relu',\n",
    "                            out_act='sigmoid',\n",
    "                            x=Xtrain_sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This compiles the MLP model for the No Null data.\n",
    "# This comes from Reference 13 in References.\n",
    "mlp_sum.compile(loss='binary_crossentropy',\n",
    "              optimizer= stochastic,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This creates checkpointer, which uses ModelCheckpoint to store the\n",
    "# best weights of the model.\n",
    "# This comes from References 6 in References.\n",
    "checkpoint = ModelCheckpoint(filepath='saved_models/weights.best.mlp_sum.hdf5',\n",
    "                             verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45858 samples, validate on 11465 samples\n",
      "Epoch 1/100\n",
      "45858/45858 [==============================] - 7s 152us/step - loss: 0.8069 - acc: 0.4823 - val_loss: 0.7623 - val_acc: 0.6215\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.76227, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 2/100\n",
      "45858/45858 [==============================] - 4s 84us/step - loss: 0.7784 - acc: 0.5271 - val_loss: 0.7423 - val_acc: 0.6768\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.76227 to 0.74232, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 3/100\n",
      "45858/45858 [==============================] - 4s 87us/step - loss: 0.7714 - acc: 0.5539 - val_loss: 0.7345 - val_acc: 0.6823\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.74232 to 0.73451, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 4/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.7627 - acc: 0.5707 - val_loss: 0.7277 - val_acc: 0.6830\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.73451 to 0.72772, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 5/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.7559 - acc: 0.5778 - val_loss: 0.7219 - val_acc: 0.6829\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.72772 to 0.72186, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 6/100\n",
      "45858/45858 [==============================] - 6s 128us/step - loss: 0.7499 - acc: 0.5884 - val_loss: 0.7179 - val_acc: 0.6836\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.72186 to 0.71789, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 7/100\n",
      "45858/45858 [==============================] - 7s 154us/step - loss: 0.7471 - acc: 0.5962 - val_loss: 0.7136 - val_acc: 0.6837\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.71789 to 0.71362, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 8/100\n",
      "45858/45858 [==============================] - 7s 144us/step - loss: 0.7450 - acc: 0.6032 - val_loss: 0.7110 - val_acc: 0.6838\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.71362 to 0.71099, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 9/100\n",
      "45858/45858 [==============================] - 9s 201us/step - loss: 0.7440 - acc: 0.6050 - val_loss: 0.7083 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.71099 to 0.70833, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 10/100\n",
      "45858/45858 [==============================] - 5s 112us/step - loss: 0.7401 - acc: 0.6170 - val_loss: 0.7053 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.70833 to 0.70525, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 11/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.7355 - acc: 0.6214 - val_loss: 0.7030 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.70525 to 0.70301, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 12/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.7323 - acc: 0.6255 - val_loss: 0.7004 - val_acc: 0.6846\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.70301 to 0.70038, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 13/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.7323 - acc: 0.6293 - val_loss: 0.6981 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.70038 to 0.69809, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 14/100\n",
      "45858/45858 [==============================] - 4s 96us/step - loss: 0.7287 - acc: 0.6330 - val_loss: 0.6959 - val_acc: 0.6840\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.69809 to 0.69593, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 15/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.7285 - acc: 0.6383 - val_loss: 0.6938 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00015: val_loss improved from 0.69593 to 0.69385, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 16/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.7254 - acc: 0.6416 - val_loss: 0.6911 - val_acc: 0.6842\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.69385 to 0.69112, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 17/100\n",
      "45858/45858 [==============================] - 4s 98us/step - loss: 0.7227 - acc: 0.6447 - val_loss: 0.6896 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00017: val_loss improved from 0.69112 to 0.68961, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 18/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.7210 - acc: 0.6464 - val_loss: 0.6887 - val_acc: 0.6843\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.68961 to 0.68869, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 19/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.7182 - acc: 0.6474 - val_loss: 0.6869 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.68869 to 0.68694, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 20/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.7173 - acc: 0.6489 - val_loss: 0.6849 - val_acc: 0.6844\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.68694 to 0.68490, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 21/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7169 - acc: 0.6512 - val_loss: 0.6830 - val_acc: 0.6847\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.68490 to 0.68304, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 22/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.7126 - acc: 0.6506 - val_loss: 0.6811 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.68304 to 0.68111, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 23/100\n",
      "45858/45858 [==============================] - 4s 97us/step - loss: 0.7097 - acc: 0.6542 - val_loss: 0.6790 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00023: val_loss improved from 0.68111 to 0.67900, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 24/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.7089 - acc: 0.6567 - val_loss: 0.6774 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.67900 to 0.67738, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 25/100\n",
      "45858/45858 [==============================] - 6s 132us/step - loss: 0.7099 - acc: 0.6564 - val_loss: 0.6760 - val_acc: 0.6851\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.67738 to 0.67603, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 26/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.7074 - acc: 0.6571 - val_loss: 0.6747 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.67603 to 0.67469, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 27/100\n",
      "45858/45858 [==============================] - 5s 117us/step - loss: 0.7054 - acc: 0.6581 - val_loss: 0.6733 - val_acc: 0.6851\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.67469 to 0.67334, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 28/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.7065 - acc: 0.6593 - val_loss: 0.6724 - val_acc: 0.6854\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.67334 to 0.67244, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 29/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.7070 - acc: 0.6598 - val_loss: 0.6711 - val_acc: 0.6851\n",
      "\n",
      "Epoch 00029: val_loss improved from 0.67244 to 0.67111, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 30/100\n",
      "45858/45858 [==============================] - 9s 206us/step - loss: 0.7018 - acc: 0.6611 - val_loss: 0.6699 - val_acc: 0.6850\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.67111 to 0.66987, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 31/100\n",
      "45858/45858 [==============================] - 5s 114us/step - loss: 0.7044 - acc: 0.6618 - val_loss: 0.6691 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.66987 to 0.66906, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 32/100\n",
      "45858/45858 [==============================] - 6s 127us/step - loss: 0.7007 - acc: 0.6617 - val_loss: 0.6679 - val_acc: 0.6849\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.66906 to 0.66789, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 33/100\n",
      "45858/45858 [==============================] - 5s 109us/step - loss: 0.6998 - acc: 0.6613 - val_loss: 0.6673 - val_acc: 0.6854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00033: val_loss improved from 0.66789 to 0.66726, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 34/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6983 - acc: 0.6648 - val_loss: 0.6658 - val_acc: 0.6855\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.66726 to 0.66580, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 35/100\n",
      "45858/45858 [==============================] - 5s 98us/step - loss: 0.6977 - acc: 0.6642 - val_loss: 0.6648 - val_acc: 0.6858\n",
      "\n",
      "Epoch 00035: val_loss improved from 0.66580 to 0.66482, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 36/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6952 - acc: 0.6664 - val_loss: 0.6641 - val_acc: 0.6859\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.66482 to 0.66409, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 37/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.6968 - acc: 0.6660 - val_loss: 0.6634 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.66409 to 0.66336, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 38/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6936 - acc: 0.6659 - val_loss: 0.6621 - val_acc: 0.6857\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.66336 to 0.66209, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 39/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6946 - acc: 0.6680 - val_loss: 0.6611 - val_acc: 0.6862\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.66209 to 0.66107, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 40/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6931 - acc: 0.6672 - val_loss: 0.6603 - val_acc: 0.6860\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.66107 to 0.66034, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 41/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6901 - acc: 0.6687 - val_loss: 0.6587 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.66034 to 0.65872, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 42/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6920 - acc: 0.6699 - val_loss: 0.6580 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.65872 to 0.65805, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 43/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6938 - acc: 0.6664 - val_loss: 0.6572 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.65805 to 0.65723, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 44/100\n",
      "45858/45858 [==============================] - 5s 118us/step - loss: 0.6909 - acc: 0.6686 - val_loss: 0.6564 - val_acc: 0.6863\n",
      "\n",
      "Epoch 00044: val_loss improved from 0.65723 to 0.65641, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 45/100\n",
      "45858/45858 [==============================] - 5s 111us/step - loss: 0.6881 - acc: 0.6680 - val_loss: 0.6555 - val_acc: 0.6865\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.65641 to 0.65554, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 46/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6891 - acc: 0.6717 - val_loss: 0.6550 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.65554 to 0.65497, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 47/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6866 - acc: 0.6700 - val_loss: 0.6537 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.65497 to 0.65372, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 48/100\n",
      "45858/45858 [==============================] - 6s 124us/step - loss: 0.6845 - acc: 0.6708 - val_loss: 0.6528 - val_acc: 0.6866\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.65372 to 0.65277, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 49/100\n",
      "45858/45858 [==============================] - 5s 116us/step - loss: 0.6826 - acc: 0.6697 - val_loss: 0.6516 - val_acc: 0.6867\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.65277 to 0.65162, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 50/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6863 - acc: 0.6698 - val_loss: 0.6509 - val_acc: 0.6868\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.65162 to 0.65094, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 51/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6846 - acc: 0.6704 - val_loss: 0.6500 - val_acc: 0.6869\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.65094 to 0.65000, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 52/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6836 - acc: 0.6711 - val_loss: 0.6491 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.65000 to 0.64910, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 53/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6859 - acc: 0.6706 - val_loss: 0.6486 - val_acc: 0.6872\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.64910 to 0.64859, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 54/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6826 - acc: 0.6717 - val_loss: 0.6476 - val_acc: 0.6877\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.64859 to 0.64755, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 55/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6808 - acc: 0.6737 - val_loss: 0.6465 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.64755 to 0.64650, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 56/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6782 - acc: 0.6738 - val_loss: 0.6452 - val_acc: 0.6879\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.64650 to 0.64524, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 57/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6789 - acc: 0.6739 - val_loss: 0.6441 - val_acc: 0.6877\n",
      "\n",
      "Epoch 00057: val_loss improved from 0.64524 to 0.64407, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 58/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6771 - acc: 0.6737 - val_loss: 0.6428 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.64407 to 0.64279, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 59/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6788 - acc: 0.6754 - val_loss: 0.6421 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.64279 to 0.64207, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 60/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6784 - acc: 0.6751 - val_loss: 0.6414 - val_acc: 0.6880\n",
      "\n",
      "Epoch 00060: val_loss improved from 0.64207 to 0.64137, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 61/100\n",
      "45858/45858 [==============================] - 5s 110us/step - loss: 0.6763 - acc: 0.6772 - val_loss: 0.6405 - val_acc: 0.6883\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.64137 to 0.64047, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 62/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6759 - acc: 0.6758 - val_loss: 0.6394 - val_acc: 0.6884\n",
      "\n",
      "Epoch 00062: val_loss improved from 0.64047 to 0.63940, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 63/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.6741 - acc: 0.6772 - val_loss: 0.6386 - val_acc: 0.6887\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.63940 to 0.63856, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 64/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6740 - acc: 0.6777 - val_loss: 0.6377 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.63856 to 0.63769, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 65/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6755 - acc: 0.6767 - val_loss: 0.6371 - val_acc: 0.6894\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.63769 to 0.63706, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 66/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6738 - acc: 0.6775 - val_loss: 0.6361 - val_acc: 0.6891\n",
      "\n",
      "Epoch 00066: val_loss improved from 0.63706 to 0.63613, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 67/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6714 - acc: 0.6778 - val_loss: 0.6353 - val_acc: 0.6898\n",
      "\n",
      "Epoch 00067: val_loss improved from 0.63613 to 0.63529, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 68/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6734 - acc: 0.6754 - val_loss: 0.6346 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00068: val_loss improved from 0.63529 to 0.63457, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 69/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6693 - acc: 0.6787 - val_loss: 0.6332 - val_acc: 0.6897\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.63457 to 0.63324, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 70/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6688 - acc: 0.6786 - val_loss: 0.6322 - val_acc: 0.6896\n",
      "\n",
      "Epoch 00070: val_loss improved from 0.63324 to 0.63220, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 71/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6700 - acc: 0.6817 - val_loss: 0.6312 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.63220 to 0.63124, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 72/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6688 - acc: 0.6815 - val_loss: 0.6306 - val_acc: 0.6901\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.63124 to 0.63060, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 73/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6702 - acc: 0.6795 - val_loss: 0.6302 - val_acc: 0.6900\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.63060 to 0.63017, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 74/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6678 - acc: 0.6804 - val_loss: 0.6291 - val_acc: 0.6907\n",
      "\n",
      "Epoch 00074: val_loss improved from 0.63017 to 0.62908, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 75/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6669 - acc: 0.6819 - val_loss: 0.6285 - val_acc: 0.6909\n",
      "\n",
      "Epoch 00075: val_loss improved from 0.62908 to 0.62851, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 76/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6674 - acc: 0.6818 - val_loss: 0.6277 - val_acc: 0.6918\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.62851 to 0.62773, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 77/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6648 - acc: 0.6830 - val_loss: 0.6264 - val_acc: 0.6932\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.62773 to 0.62642, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 78/100\n",
      "45858/45858 [==============================] - 5s 99us/step - loss: 0.6666 - acc: 0.6834 - val_loss: 0.6257 - val_acc: 0.6929\n",
      "\n",
      "Epoch 00078: val_loss improved from 0.62642 to 0.62570, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 79/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6614 - acc: 0.6846 - val_loss: 0.6246 - val_acc: 0.6939\n",
      "\n",
      "Epoch 00079: val_loss improved from 0.62570 to 0.62465, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 80/100\n",
      "45858/45858 [==============================] - 5s 100us/step - loss: 0.6611 - acc: 0.6839 - val_loss: 0.6235 - val_acc: 0.6945\n",
      "\n",
      "Epoch 00080: val_loss improved from 0.62465 to 0.62349, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 81/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6628 - acc: 0.6844 - val_loss: 0.6225 - val_acc: 0.6949\n",
      "\n",
      "Epoch 00081: val_loss improved from 0.62349 to 0.62255, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 82/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.6620 - acc: 0.6862 - val_loss: 0.6219 - val_acc: 0.6950\n",
      "\n",
      "Epoch 00082: val_loss improved from 0.62255 to 0.62193, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 83/100\n",
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.6621 - acc: 0.6863 - val_loss: 0.6213 - val_acc: 0.6952\n",
      "\n",
      "Epoch 00083: val_loss improved from 0.62193 to 0.62133, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 84/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6601 - acc: 0.6872 - val_loss: 0.6203 - val_acc: 0.6966\n",
      "\n",
      "Epoch 00084: val_loss improved from 0.62133 to 0.62026, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 85/100\n",
      "45858/45858 [==============================] - 5s 101us/step - loss: 0.6608 - acc: 0.6864 - val_loss: 0.6194 - val_acc: 0.6973\n",
      "\n",
      "Epoch 00085: val_loss improved from 0.62026 to 0.61937, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 86/100\n",
      "45858/45858 [==============================] - 5s 119us/step - loss: 0.6588 - acc: 0.6862 - val_loss: 0.6188 - val_acc: 0.6985\n",
      "\n",
      "Epoch 00086: val_loss improved from 0.61937 to 0.61878, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 87/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6584 - acc: 0.6891 - val_loss: 0.6179 - val_acc: 0.6991\n",
      "\n",
      "Epoch 00087: val_loss improved from 0.61878 to 0.61786, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 88/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6569 - acc: 0.6884 - val_loss: 0.6170 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00088: val_loss improved from 0.61786 to 0.61704, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 89/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6563 - acc: 0.6876 - val_loss: 0.6161 - val_acc: 0.7003\n",
      "\n",
      "Epoch 00089: val_loss improved from 0.61704 to 0.61615, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 90/100\n",
      "45858/45858 [==============================] - 5s 113us/step - loss: 0.6584 - acc: 0.6901 - val_loss: 0.6159 - val_acc: 0.7000\n",
      "\n",
      "Epoch 00090: val_loss improved from 0.61615 to 0.61588, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 91/100\n",
      "45858/45858 [==============================] - 5s 103us/step - loss: 0.6588 - acc: 0.6878 - val_loss: 0.6157 - val_acc: 0.6997\n",
      "\n",
      "Epoch 00091: val_loss improved from 0.61588 to 0.61572, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 92/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6562 - acc: 0.6910 - val_loss: 0.6149 - val_acc: 0.7013\n",
      "\n",
      "Epoch 00092: val_loss improved from 0.61572 to 0.61494, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 93/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6588 - acc: 0.6906 - val_loss: 0.6141 - val_acc: 0.7020\n",
      "\n",
      "Epoch 00093: val_loss improved from 0.61494 to 0.61413, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 94/100\n",
      "45858/45858 [==============================] - 5s 108us/step - loss: 0.6529 - acc: 0.6897 - val_loss: 0.6132 - val_acc: 0.7029\n",
      "\n",
      "Epoch 00094: val_loss improved from 0.61413 to 0.61320, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 95/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6549 - acc: 0.6909 - val_loss: 0.6124 - val_acc: 0.7036\n",
      "\n",
      "Epoch 00095: val_loss improved from 0.61320 to 0.61239, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 96/100\n",
      "45858/45858 [==============================] - 5s 105us/step - loss: 0.6533 - acc: 0.6936 - val_loss: 0.6118 - val_acc: 0.7038\n",
      "\n",
      "Epoch 00096: val_loss improved from 0.61239 to 0.61182, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 97/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6545 - acc: 0.6930 - val_loss: 0.6110 - val_acc: 0.7061\n",
      "\n",
      "Epoch 00097: val_loss improved from 0.61182 to 0.61099, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 98/100\n",
      "45858/45858 [==============================] - 5s 107us/step - loss: 0.6525 - acc: 0.6928 - val_loss: 0.6101 - val_acc: 0.7063\n",
      "\n",
      "Epoch 00098: val_loss improved from 0.61099 to 0.61005, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 99/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45858/45858 [==============================] - 5s 102us/step - loss: 0.6516 - acc: 0.6936 - val_loss: 0.6089 - val_acc: 0.7067\n",
      "\n",
      "Epoch 00099: val_loss improved from 0.61005 to 0.60893, saving model to saved_models/weights.best.mlp_sum.hdf5\n",
      "Epoch 100/100\n",
      "45858/45858 [==============================] - 5s 104us/step - loss: 0.6497 - acc: 0.6948 - val_loss: 0.6081 - val_acc: 0.7081\n",
      "\n",
      "Epoch 00100: val_loss improved from 0.60893 to 0.60807, saving model to saved_models/weights.best.mlp_sum.hdf5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1efc981c5c0>"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This fits the model and runs it for 100 epochs.\n",
    "mlp_sum.fit(Xtrain_sum, Ytrain_sum, validation_split=0.20,\n",
    "                epochs=n_epochs, batch_size=size_of_batch, \n",
    "                callbacks = [checkpoint], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This loads the best weights from the model.\n",
    "# This comes from Reference 6 in References.\n",
    "mlp_sum.load_weights('saved_models/weights.best.mlp_sum.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test acuracy: 61.6694%\n"
     ]
    }
   ],
   "source": [
    "# This prints the accuracy of the model.\n",
    "# This comes from Reference 9 in References.\n",
    "score = mlp_sum.evaluate(Xtest_sum, Ytest_sum, verbose=0)\n",
    "accuracy = 100*score[1]\n",
    "print('Test acuracy: %.4f%%' %accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score for the model is 0.6096.\n"
     ]
    }
   ],
   "source": [
    "# This prints the AUC score for the model.\n",
    "Ypred_sum = mlp_sum.predict(Xtest_sum)\n",
    "ROC_mlp_sum = roc_auc_score(Ytest_sum, Ypred_sum)\n",
    "print(\"The AUC score for the model is %.4f.\" % ROC_mlp_sum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='references'></a>\n",
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. https://stackoverflow.com/questions/41032551/how-to-compute-receiving-operating-characteristic-roc-and-auc-in-keras\n",
    "2. https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegressionCV.html\n",
    "3. https://towardsdatascience.com/time-series-nested-cross-validation-76adba623eb9\n",
    "4. https://dziganto.github.io/cross-validation/data%20science/machine%20learning/model%20tuning/python/Model-Tuning-with-Validation-and-Cross-Validation/\n",
    "5. https://keras.io/getting-started/sequential-model-guide/\n",
    "6. Udacity Machine Learning Engineer Nanodegree Program, Semester 2, Brian Campbell - Dog Breed Classifier Project\n",
    "7. https://keras.io/getting-started/sequential-model-guide/\n",
    "8. https://docs.scipy.org/doc/numpy/reference/generated/numpy.ma.size.html\n",
    "9. https://keras.io/models/sequential/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
